{"config":{"lang":["es"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Bienvenidos al curso!","text":""},{"location":"#secciones","title":"Secciones","text":"<p>Computaci\u00f3n Cient\u00edfica</p><p>Numpy, scipy, sympy</p> <p>Manipulaci\u00f3n de Datos</p><p>Pandas (b\u00e1sico y avanzado)</p> <p>Visualizaci\u00f3n de Datos</p><p>Matplotlib, Seaborn, Altair</p>"},{"location":"__init__/","title":"init","text":"In\u00a0[\u00a0]: Copied! <pre>__version__ = \"0.1.0\"\n</pre> __version__ = \"0.1.0\""},{"location":"numpy/01_intro/","title":"Introducci\u00f3n","text":"<ul> <li><p>Los array NumPy ocupan menos espacio. Esto significa que una matriz entera arbitraria de longitud n en necesidades numpy se calcula por:</p> <pre><code>                  96 + n * 8 bytes</code></pre> </li> </ul> <p></p> <p>Veamos un ejemplo:</p> In\u00a0[13]: Copied! <pre>import numpy as np \nimport time\nimport sys\n\ndef arreglo_python(n):\n    t1 = time.time()\n    X = range(n)\n    Y = range(n)\n    Z = [X[i] + Y[i] for i in range(len(X)) ]\n    return (time.time() - t1,sys.getsizeof(Z) )\n\ndef arreglo_numpy(n):\n    t1 = time.time()\n    X = np.arange(n)\n    Y = np.arange(n)\n    Z = X + Y\n    return (time.time() - t1,sys.getsizeof(Z) )\n</pre> import numpy as np  import time import sys  def arreglo_python(n):     t1 = time.time()     X = range(n)     Y = range(n)     Z = [X[i] + Y[i] for i in range(len(X)) ]     return (time.time() - t1,sys.getsizeof(Z) )  def arreglo_numpy(n):     t1 = time.time()     X = np.arange(n)     Y = np.arange(n)     Z = X + Y     return (time.time() - t1,sys.getsizeof(Z) ) In\u00a0[14]: Copied! <pre># parametros\nsize_of_vec = 1000000\n\nt1, size1 = arreglo_python(size_of_vec)\nt2, size2 = arreglo_numpy(size_of_vec)\n</pre> # parametros size_of_vec = 1000000  t1, size1 = arreglo_python(size_of_vec) t2, size2 = arreglo_numpy(size_of_vec) In\u00a0[22]: Copied! <pre># generar varios casos\nfor size_of_vec in [10,100,1000,10000,100000,1000000]:\n    print(f\"size of vector: {size_of_vec}\")\n    \n    #list vs numpy\n    t1, size1 = arreglo_python(size_of_vec)\n    t2, size2 = arreglo_numpy(size_of_vec)\n    \n    # resultados\n    print(f\"python list -- time: {round(t1,8)} seg, size: {size1} bytes\")\n    print(f\"numpy array -- time: {round(t2,8)} seg, size: {size2} bytes\\n\")\n</pre> # generar varios casos for size_of_vec in [10,100,1000,10000,100000,1000000]:     print(f\"size of vector: {size_of_vec}\")          #list vs numpy     t1, size1 = arreglo_python(size_of_vec)     t2, size2 = arreglo_numpy(size_of_vec)          # resultados     print(f\"python list -- time: {round(t1,8)} seg, size: {size1} bytes\")     print(f\"numpy array -- time: {round(t2,8)} seg, size: {size2} bytes\\n\") <pre>size of vector: 10\npython list -- time: 0.0 seg, size: 184 bytes\nnumpy array -- time: 0.0 seg, size: 152 bytes\n\nsize of vector: 100\npython list -- time: 0.0 seg, size: 904 bytes\nnumpy array -- time: 0.0 seg, size: 512 bytes\n\nsize of vector: 1000\npython list -- time: 0.0 seg, size: 9016 bytes\nnumpy array -- time: 0.0 seg, size: 4112 bytes\n\nsize of vector: 10000\npython list -- time: 0.0 seg, size: 87616 bytes\nnumpy array -- time: 0.00452495 seg, size: 40112 bytes\n\nsize of vector: 100000\npython list -- time: 0.01462412 seg, size: 824456 bytes\nnumpy array -- time: 0.00096154 seg, size: 400112 bytes\n\nsize of vector: 1000000\npython list -- time: 0.1639111 seg, size: 8697456 bytes\nnumpy array -- time: 0.00457025 seg, size: 4000112 bytes\n\n</pre>"},{"location":"numpy/01_intro/#introduccion","title":"Introducci\u00f3n\u00b6","text":""},{"location":"numpy/01_intro/#acerca-de-numpy","title":"Acerca de Numpy\u00b6","text":"<p>Numpy s una biblioteca de Python que se utiliza para trabajar con matrices y vectores de datos num\u00e9ricos. Proporciona un conjunto de funciones y m\u00e9todos eficientes y optimizados para el procesamiento de datos num\u00e9ricos, incluyendo operaciones matriciales, estad\u00edsticas, \u00e1lgebra lineal, entre otras.</p> <p>NumPy es ampliamente utilizado en \u00e1reas como la ciencia de datos, el aprendizaje autom\u00e1tico, la ingenier\u00eda y la f\u00edsica, entre otras. Es una herramienta fundamental en el ecosistema de Python para el procesamiento y an\u00e1lisis de datos num\u00e9ricos.</p> <p>Algunas de las caracter\u00edsticas principales de NumPy son:</p> <ul> <li>Arrays multidimensionales eficientes y optimizados para operaciones num\u00e9ricas.</li> <li>Funciones y m\u00e9todos para operaciones matem\u00e1ticas y estad\u00edsticas.</li> <li>Integraci\u00f3n con otras bibliotecas de Python para el procesamiento de datos, como Pandas y Matplotlib.</li> <li>Capacidad de procesar grandes conjuntos de datos num\u00e9ricos de manera eficiente y escalable.</li> </ul>"},{"location":"numpy/01_intro/#python-lists-vs-numpy-arrays","title":"Python Lists vs Numpy Arrays\u00b6","text":"<p>Las listas de Python y los arrays de NumPy son dos estructuras de datos diferentes que se utilizan para almacenar y manipular conjuntos de datos en Python.</p> <ul> <li><p>Las listas de Python son una colecci\u00f3n de elementos que pueden ser de diferentes tipos de datos, como enteros, flotantes, cadenas, etc. Pueden ser de longitud variable y se pueden modificar en tiempo de ejecuci\u00f3n. Las listas de Python son m\u00e1s flexibles y vers\u00e1tiles que los arrays de NumPy, pero pueden ser m\u00e1s lentas para operaciones matem\u00e1ticas y num\u00e9ricas.</p> </li> <li><p>Los arrays de NumPy son una estructura de datos m\u00e1s especializada que se utiliza para trabajar con datos num\u00e9ricos, como matrices y vectores. Son m\u00e1s r\u00e1pidos y eficientes que las listas de Python para operaciones num\u00e9ricas y matem\u00e1ticas, y proporcionan muchas funciones y m\u00e9todos \u00fatiles para el procesamiento de datos, como operaciones matriciales y de \u00e1lgebra lineal. Los arrays de NumPy tienen una longitud fija y no se pueden modificar una vez creados.</p> </li> </ul> <p>Una pregunta com\u00fan para principiantes es cu\u00e1l es la verdadera diferencia aqu\u00ed. La respuesta es el rendimiento. Las estructuras de datos de Numpy funcionan mejor en:</p> <ul> <li>Tama\u00f1o: las estructuras de datos de Numpy ocupan menos espacio</li> <li>Rendimiento: necesitan velocidad y son m\u00e1s r\u00e1pidos que las listas</li> <li>Funcionalidad: SciPy y NumPy tienen funciones optimizadas, como las operaciones de \u00e1lgebra lineal integradas.</li> </ul>"},{"location":"numpy/01_intro/#diferencias-tiempo-memoria","title":"Diferencias Tiempo - Memoria\u00b6","text":"<p>Los principales beneficios del uso de matrices NumPy deber\u00edan ser un menor consumo de memoria y un mejor comportamiento en tiempo de ejecuci\u00f3n.</p> <ul> <li><p>Para las listas de Python podemos concluir de esto que para cada elemento nuevo, necesitamos otros ocho bytes para la referencia al nuevo objeto. El nuevo objeto entero en s\u00ed consume 28 bytes. El tama\u00f1o de una lista lst sin el tama\u00f1o de los elementos se puede calcular con:</p> <pre><code>                  64 + 8 * len (lst) + + len (lst) * 28</code></pre> </li> </ul>"},{"location":"numpy/021_objetos/","title":"Objetos en Numpy","text":"In\u00a0[1]: Copied! <pre>import numpy as np\n\n# Crear un array 1D de longitud 3\narr_1d = np.array([1, 2, 3])\nprint(arr_1d)\n</pre> import numpy as np  # Crear un array 1D de longitud 3 arr_1d = np.array([1, 2, 3]) print(arr_1d) <pre>[1 2 3]\n</pre> In\u00a0[2]: Copied! <pre># Crear un array 2D de tama\u00f1o 2x3\narr_2d = np.array([\n    [1, 2, 3], \n    [4, 5, 6]\n])\nprint(arr_2d)\n</pre> # Crear un array 2D de tama\u00f1o 2x3 arr_2d = np.array([     [1, 2, 3],      [4, 5, 6] ]) print(arr_2d) <pre>[[1 2 3]\n [4 5 6]]\n</pre> In\u00a0[5]: Copied! <pre># Crear un array 3D de tama\u00f1o 2x2x3\narr_3d = np.array([\n    [\n        [1, 2, 3], \n        [4, 5, 6]\n    ], \n    [\n        [7, 8, 9],\n        [10, 11, 12]\n    ]\n])\nprint(arr_3d)\n</pre> # Crear un array 3D de tama\u00f1o 2x2x3 arr_3d = np.array([     [         [1, 2, 3],          [4, 5, 6]     ],      [         [7, 8, 9],         [10, 11, 12]     ] ]) print(arr_3d) <pre>[[[ 1  2  3]\n  [ 4  5  6]]\n\n [[ 7  8  9]\n  [10 11 12]]]\n</pre> <p>Veamos algunos atributos de los arreglos en Numpy:</p> <ul> <li><code>ndarray.shape</code>: devuelve la forma (dimensiones) del array.</li> <li><code>ndarray.ndim</code>: devuelve el n\u00famero de dimensiones del array.</li> <li><code>ndarray.size</code>: devuelve el n\u00famero total de elementos en el array.</li> <li><code>ndarray.dtype</code>: devuelve el tipo de datos de los elementos del array.</li> </ul> In\u00a0[7]: Copied! <pre># crear objeto\nobj_numpy =np.array(\n    [1, 2, 3, 4, 5, 6, 7, 8, 9])\n</pre> # crear objeto obj_numpy =np.array(     [1, 2, 3, 4, 5, 6, 7, 8, 9]) In\u00a0[8]: Copied! <pre># shape\nobj_numpy.shape\n</pre> # shape obj_numpy.shape Out[8]: <pre>(9,)</pre> In\u00a0[9]: Copied! <pre># ndim\nobj_numpy.ndim\n</pre> # ndim obj_numpy.ndim Out[9]: <pre>1</pre> In\u00a0[\u00a0]: Copied! <pre># size\nobj_numpy.size\n</pre> # size obj_numpy.size In\u00a0[10]: Copied! <pre># dtype\nobj_numpy.dtype\n</pre> # dtype obj_numpy.dtype Out[10]: <pre>dtype('int32')</pre>"},{"location":"numpy/021_objetos/#objetos-en-numpy","title":"Objetos en Numpy\u00b6","text":"<p>En NumPy, el objeto principal es el array multidimensional (llamado <code>ndarray</code>), que es una estructura de datos eficiente para el procesamiento de datos num\u00e9ricos. Los arrays en NumPy son objetos homog\u00e9neos y de tama\u00f1o fijo que contienen elementos del mismo tipo de datos.</p> <p>Aqu\u00ed hay algunos ejemplos de objetos en NumPy:</p>"},{"location":"numpy/022_operaciones/","title":"Operaciones","text":"In\u00a0[3]: Copied! <pre>import numpy as np\n\n# Crear dos arrays\na = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\n</pre> import numpy as np  # Crear dos arrays a = np.array([1, 2, 3]) b = np.array([4, 5, 6]) In\u00a0[4]: Copied! <pre># Suma de arrays\nc = a + b\nprint(c)\n</pre> # Suma de arrays c = a + b print(c) <pre>[5 7 9]\n</pre> In\u00a0[5]: Copied! <pre># Resta de arrays\nc = a - b\nprint(c)\n</pre> # Resta de arrays c = a - b print(c) <pre>[-3 -3 -3]\n</pre> In\u00a0[6]: Copied! <pre># Multiplicaci\u00f3n de arrays\nc = a * b\nprint(c)\n</pre> # Multiplicaci\u00f3n de arrays c = a * b print(c) <pre>[ 4 10 18]\n</pre> In\u00a0[7]: Copied! <pre># Divisi\u00f3n de arrays\nc = a / b\nprint(c)\n</pre> # Divisi\u00f3n de arrays c = a / b print(c) <pre>[0.25 0.4  0.5 ]\n</pre> In\u00a0[8]: Copied! <pre># Crear dos arrays\na = np.array([1, 2, 3])\nb = np.array([2, 2, 4])\n</pre> # Crear dos arrays a = np.array([1, 2, 3]) b = np.array([2, 2, 4]) In\u00a0[9]: Copied! <pre># Comparaci\u00f3n de arrays\nc = a == b\nprint(c)\n</pre> # Comparaci\u00f3n de arrays c = a == b print(c) <pre>[False  True False]\n</pre> In\u00a0[10]: Copied! <pre># Comparaci\u00f3n de arrays\nc = a &gt; b\nprint(c)\n</pre> # Comparaci\u00f3n de arrays c = a &gt; b print(c) <pre>[False False False]\n</pre> In\u00a0[11]: Copied! <pre># Comparaci\u00f3n de arrays\nc = a &lt;= b\nprint(c)\n</pre> # Comparaci\u00f3n de arrays c = a &lt;= b print(c) <pre>[ True  True  True]\n</pre> In\u00a0[16]: Copied! <pre># Crear un array\na = np.array([1, 2, 3, 4, 5])\n\n# Suma de los elementos en un array\nsum_a = np.sum(a)\nprint(f\"Suma de elementos: {sum_a}\")\n</pre> # Crear un array a = np.array([1, 2, 3, 4, 5])  # Suma de los elementos en un array sum_a = np.sum(a) print(f\"Suma de elementos: {sum_a}\") <pre>Suma de elementos: 15\n</pre> In\u00a0[17]: Copied! <pre># M\u00ednimo y m\u00e1ximo de los elementos en un array\nmin_a = np.min(a)\nmax_a = np.max(a)\n\nprint(f\"minimo: {min_a}\")\nprint(f\"maximo: {max_a}\")\n</pre> # M\u00ednimo y m\u00e1ximo de los elementos en un array min_a = np.min(a) max_a = np.max(a)  print(f\"minimo: {min_a}\") print(f\"maximo: {max_a}\") <pre>minimo: 1\nmaximo: 5\n</pre> In\u00a0[18]: Copied! <pre># Promedio y desviaci\u00f3n est\u00e1ndar de los elementos en un array\nmean_a = np.mean(a)\nstd_a = np.std(a)\n\nprint(f\"promedio: {mean_a}\")\nprint(f\"desviacion estandar: {std_a}\")\n</pre> # Promedio y desviaci\u00f3n est\u00e1ndar de los elementos en un array mean_a = np.mean(a) std_a = np.std(a)  print(f\"promedio: {mean_a}\") print(f\"desviacion estandar: {std_a}\") <pre>promedio: 3.0\ndesviacion estandar: 1.4142135623730951\n</pre>"},{"location":"numpy/022_operaciones/#operaciones","title":"Operaciones\u00b6","text":"<p>NumPy proporciona una variedad de operaciones b\u00e1sicas que se pueden realizar en los arrays, como operaciones aritm\u00e9ticas, operaciones de comparaci\u00f3n y operaciones de agregaci\u00f3n. Aqu\u00ed hay algunos ejemplos de operaciones b\u00e1sicas en NumPy:</p>"},{"location":"numpy/022_operaciones/#operaciones-aritmeticas","title":"Operaciones aritm\u00e9ticas\u00b6","text":""},{"location":"numpy/022_operaciones/#operaciones-de-comparacion","title":"Operaciones de comparaci\u00f3n\u00b6","text":""},{"location":"numpy/022_operaciones/#operaciones-de-estadisticas","title":"Operaciones de estad\u00edsticas\u00b6","text":""},{"location":"numpy/023_index/","title":"Indexaci\u00f3n","text":"<ul> <li>Acceder a elementos individuales de un array unidimensional:</li> </ul> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\n# Crear un array unidimensional\na = np.array([1, 2, 3, 4, 5])\n</pre> import numpy as np  # Crear un array unidimensional a = np.array([1, 2, 3, 4, 5]) In\u00a0[\u00a0]: Copied! <pre># Acceder al primer elemento\nprint(a[0])\n</pre> # Acceder al primer elemento print(a[0]) In\u00a0[\u00a0]: Copied! <pre># Acceder al \u00faltimo elemento\nprint(a[-1])\n</pre> # Acceder al \u00faltimo elemento print(a[-1]) In\u00a0[1]: Copied! <pre># Acceder al tercer elemento\nprint(a[2])\n</pre> # Acceder al tercer elemento print(a[2]) <pre>1\n5\n3\n</pre> <ul> <li>Acceder a elementos individuales de un array multidimensional:</li> </ul> In\u00a0[14]: Copied! <pre># Crear un array bidimensional\nb = np.array([\n    [1, 2, 3],\n    [4, 5, 6],\n    [7, 8, 9]]\n)\n</pre> # Crear un array bidimensional b = np.array([     [1, 2, 3],     [4, 5, 6],     [7, 8, 9]] ) In\u00a0[3]: Copied! <pre># Acceder al primer elemento\nprint(b[0, 0])\n</pre> # Acceder al primer elemento print(b[0, 0]) <pre>1\n</pre> In\u00a0[4]: Copied! <pre># Acceder al \u00faltimo elemento\nprint(b[-1, -1])\n</pre> # Acceder al \u00faltimo elemento print(b[-1, -1]) <pre>9\n</pre> In\u00a0[5]: Copied! <pre># Acceder al elemento en la segunda fila y tercer columna\nprint(b[1, 2])\n</pre> # Acceder al elemento en la segunda fila y tercer columna print(b[1, 2]) <pre>6\n</pre> <ul> <li>Rebanar un array unidimensional:</li> </ul> In\u00a0[6]: Copied! <pre># Rebanar un array unidimensional\na = np.array([1, 2, 3, 4, 5])\n</pre> # Rebanar un array unidimensional a = np.array([1, 2, 3, 4, 5]) In\u00a0[7]: Copied! <pre># Rebanar los primeros tres elementos\nprint(a[:3])\n</pre> # Rebanar los primeros tres elementos print(a[:3]) <pre>[1 2 3]\n</pre> In\u00a0[8]: Copied! <pre># Rebanar los \u00faltimos dos elementos\nprint(a[-2:])\n</pre> # Rebanar los \u00faltimos dos elementos print(a[-2:]) <pre>[4 5]\n</pre> In\u00a0[9]: Copied! <pre># Rebanar todos los elementos saltando de dos en dos\nprint(a[::2])\n</pre> # Rebanar todos los elementos saltando de dos en dos print(a[::2]) <pre>[1 3 5]\n</pre> <ul> <li>Rebanar un array multidimensional:</li> </ul> In\u00a0[15]: Copied! <pre># Rebanar un array bidimensional\nb = np.array([\n    [1, 2, 3], \n    [4, 5, 6], \n    [7, 8, 9]]\n)\n</pre> # Rebanar un array bidimensional b = np.array([     [1, 2, 3],      [4, 5, 6],      [7, 8, 9]] ) In\u00a0[11]: Copied! <pre># Rebanar la primera y segunda fila\nprint(b[:2, :])\n</pre> # Rebanar la primera y segunda fila print(b[:2, :]) <pre>[[1 2 3]\n [4 5 6]]\n</pre> In\u00a0[12]: Copied! <pre># Rebanar la segunda y tercera columna\nprint(b[:, 1:])\n</pre> # Rebanar la segunda y tercera columna print(b[:, 1:]) <pre>[[2 3]\n [5 6]\n [8 9]]\n</pre> In\u00a0[13]: Copied! <pre># Rebanar la diagonal principal\nprint(b.diagonal())\n</pre> # Rebanar la diagonal principal print(b.diagonal()) <pre>[1 5 9]\n</pre>"},{"location":"numpy/023_index/#indexacion","title":"Indexaci\u00f3n\u00b6","text":"<p>La indexaci\u00f3n en NumPy es similar a la indexaci\u00f3n en listas de Python, pero se extiende a m\u00faltiples dimensiones. En NumPy, los arrays se pueden indexar y rebanar para acceder a elementos y subarrays espec\u00edficos. Aqu\u00ed hay algunos ejemplos de indexaci\u00f3n en NumPy:</p>"},{"location":"numpy/024_algebra_lineal/","title":"Algebra Lineal","text":"<ul> <li>Vectores/Matrices especializadas</li> </ul> In\u00a0[1]: Copied! <pre>import numpy as np\n</pre> import numpy as np In\u00a0[2]: Copied! <pre># Arreglo de ceros: np.zeros(shape)\nprint(\"Zeros:\")\nprint( np.zeros((3,3)) )\n</pre> # Arreglo de ceros: np.zeros(shape) print(\"Zeros:\") print( np.zeros((3,3)) ) <pre>Zeros:\n[[0. 0. 0.]\n [0. 0. 0.]\n [0. 0. 0.]]\n</pre> In\u00a0[3]: Copied! <pre># Arreglos de uno: np.ones(shape)\nprint(\"\\nOnes:\")\nprint( np.ones((3,3)) )\n</pre> # Arreglos de uno: np.ones(shape) print(\"\\nOnes:\") print( np.ones((3,3)) ) <pre>\nOnes:\n[[1. 1. 1.]\n [1. 1. 1.]\n [1. 1. 1.]]\n</pre> In\u00a0[4]: Copied! <pre># Arreglo vacio: np.empty(shape)\nprint(\"\\nEmpty:\")\nprint( np.empty([2, 2]) )\n</pre> # Arreglo vacio: np.empty(shape) print(\"\\nEmpty:\") print( np.empty([2, 2]) ) <pre>\nEmpty:\n[[2.12199579e-314 4.67296746e-307]\n [7.43074731e-321 3.79442416e-321]]\n</pre> In\u00a0[5]: Copied! <pre># Rango de valores: np.range(start, stop, step)\nprint(\"\\nRange:\")\nnp.arange(0., 10., 1.)\n</pre> # Rango de valores: np.range(start, stop, step) print(\"\\nRange:\") np.arange(0., 10., 1.)  <pre>\nRange:\n</pre> Out[5]: <pre>array([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])</pre> In\u00a0[6]: Copied! <pre># Grilla de valores: np.linspace(start, end, n_values)\nprint(\"\\nRegular grid:\")\nprint( np.linspace(0., 1., 9) )\n</pre> # Grilla de valores: np.linspace(start, end, n_values) print(\"\\nRegular grid:\") print( np.linspace(0., 1., 9) ) <pre>\nRegular grid:\n[0.    0.125 0.25  0.375 0.5   0.625 0.75  0.875 1.   ]\n</pre> In\u00a0[7]: Copied! <pre># fijar semilla\nnp.random.seed(42)\n\n# Sequencia de valores aleatorios: np.random\nprint(\"\\nRandom sequences:\")\nprint( np.random.uniform(10, size=6) )\n</pre> # fijar semilla np.random.seed(42)  # Sequencia de valores aleatorios: np.random print(\"\\nRandom sequences:\") print( np.random.uniform(10, size=6) ) <pre>\nRandom sequences:\n[6.62913893 1.44357124 3.41205452 4.61207364 8.59583224 8.59604932]\n</pre> <ul> <li>Operaciones con Matrices</li> </ul> In\u00a0[8]: Copied! <pre># crear matrices\n\nA = np.array([\n    [1,2,3],\n    [4,5,6],\n    [7,8,9]\n])\n\nB = np.array([\n    [9,8,7],\n    [6,5,4],\n    [3,2,1]]\n)\n\nprint(f\"Matrix A: \\n {A}\\n\")\nprint(f\"Matrix B: \\n {B}\")\n</pre> # crear matrices  A = np.array([     [1,2,3],     [4,5,6],     [7,8,9] ])  B = np.array([     [9,8,7],     [6,5,4],     [3,2,1]] )  print(f\"Matrix A: \\n {A}\\n\") print(f\"Matrix B: \\n {B}\") <pre>Matrix A: \n [[1 2 3]\n [4 5 6]\n [7 8 9]]\n\nMatrix B: \n [[9 8 7]\n [6 5 4]\n [3 2 1]]\n</pre> In\u00a0[9]: Copied! <pre># sumar dos matrices\nprint(\"Sum:\")\nprint( A+B )\n</pre> # sumar dos matrices print(\"Sum:\") print( A+B ) <pre>Sum:\n[[10 10 10]\n [10 10 10]\n [10 10 10]]\n</pre> In\u00a0[10]: Copied! <pre># restar dos matrices\nprint(\"\\nSubtraction\")\nprint( A-B )\n</pre> # restar dos matrices print(\"\\nSubtraction\") print( A-B ) <pre>\nSubtraction\n[[-8 -6 -4]\n [-2  0  2]\n [ 4  6  8]]\n</pre> In\u00a0[11]: Copied! <pre># producto uno a uno\nprint(\"\\nProduct\")\nprint( A*B )\n</pre> # producto uno a uno print(\"\\nProduct\") print( A*B ) <pre>\nProduct\n[[ 9 16 21]\n [24 25 24]\n [21 16  9]]\n</pre> In\u00a0[12]: Copied! <pre># producto matricial\nprint(\"\\nMatricial Product\")\nprint( np.dot(A,B) )\n</pre> # producto matricial print(\"\\nMatricial Product\") print( np.dot(A,B) ) <pre>\nMatricial Product\n[[ 30  24  18]\n [ 84  69  54]\n [138 114  90]]\n</pre> In\u00a0[13]: Copied! <pre># potencia\nprint(\"\\n Power\")\nprint( A**2 )\n</pre> # potencia print(\"\\n Power\") print( A**2 ) <pre>\n Power\n[[ 1  4  9]\n [16 25 36]\n [49 64 81]]\n</pre> <ul> <li>Algunas funciones especiales:</li> </ul> In\u00a0[14]: Copied! <pre># crear matriz\nA = np.array([\n    [1,2,3],\n    [4,5,6],\n    [7,8,9]\n])\n</pre> # crear matriz A = np.array([     [1,2,3],     [4,5,6],     [7,8,9] ]) In\u00a0[15]: Copied! <pre>print(\"funcion exponencial\")\nprint( np.exp(A) )\n</pre> print(\"funcion exponencial\") print( np.exp(A) ) <pre>funcion exponencial\n[[2.71828183e+00 7.38905610e+00 2.00855369e+01]\n [5.45981500e+01 1.48413159e+02 4.03428793e+02]\n [1.09663316e+03 2.98095799e+03 8.10308393e+03]]\n</pre> In\u00a0[16]: Copied! <pre>print(\"funcion seno\")\nprint( np.sin(A) )\n</pre> print(\"funcion seno\") print( np.sin(A) ) <pre>funcion seno\n[[ 0.84147098  0.90929743  0.14112001]\n [-0.7568025  -0.95892427 -0.2794155 ]\n [ 0.6569866   0.98935825  0.41211849]]\n</pre> In\u00a0[17]: Copied! <pre>print(\"funcion coseno\")\nprint( np.cos(A))\n</pre> print(\"funcion coseno\") print( np.cos(A)) <pre>funcion coseno\n[[ 0.54030231 -0.41614684 -0.9899925 ]\n [-0.65364362  0.28366219  0.96017029]\n [ 0.75390225 -0.14550003 -0.91113026]]\n</pre> In\u00a0[18]: Copied! <pre>print(\"funcion tangente\")\nprint( np.tan(A) )\n</pre> print(\"funcion tangente\") print( np.tan(A) ) <pre>funcion tangente\n[[ 1.55740772 -2.18503986 -0.14254654]\n [ 1.15782128 -3.38051501 -0.29100619]\n [ 0.87144798 -6.79971146 -0.45231566]]\n</pre> <ul> <li>Operaciones \u00e1lgebra l\u00edneal:</li> </ul> In\u00a0[19]: Copied! <pre># crear matriz\nA = np.array([[1,2],\n              [3,4]])\n</pre> # crear matriz A = np.array([[1,2],               [3,4]]) In\u00a0[20]: Copied! <pre># matriz transpuesta\nprint(\"Transpose: \")\nprint( A.T )\n</pre> # matriz transpuesta print(\"Transpose: \") print( A.T ) <pre>Transpose: \n[[1 3]\n [2 4]]\n</pre> In\u00a0[21]: Copied! <pre># determinante\nprint(\"determinant\")\nprint( round(np.linalg.det(A) ,2))\n</pre> # determinante print(\"determinant\") print( round(np.linalg.det(A) ,2)) <pre>determinant\n-2.0\n</pre> In\u00a0[22]: Copied! <pre># Matriz Inversa\nprint(\"Inverse\")\nprint( np.linalg.inv(A) )\n</pre> # Matriz Inversa print(\"Inverse\") print( np.linalg.inv(A) ) <pre>Inverse\n[[-2.   1. ]\n [ 1.5 -0.5]]\n</pre> In\u00a0[23]: Copied! <pre># traza\nprint(\"Trace\")\nprint( np.trace(A))\n</pre> # traza print(\"Trace\") print( np.trace(A)) <pre>Trace\n5\n</pre> In\u00a0[24]: Copied! <pre># Valores y vectores propios\neigenvalues, eigenvectors = np.linalg.eig(A) \n\nprint(\"eigenvalues\")\nprint( eigenvalues )\nprint(\"\\neigenvectors\")\nprint( eigenvectors )\n</pre> # Valores y vectores propios eigenvalues, eigenvectors = np.linalg.eig(A)   print(\"eigenvalues\") print( eigenvalues ) print(\"\\neigenvectors\") print( eigenvectors )  <pre>eigenvalues\n[-0.37228132  5.37228132]\n\neigenvectors\n[[-0.82456484 -0.41597356]\n [ 0.56576746 -0.90937671]]\n</pre> In\u00a0[25]: Copied! <pre># descomposicion QR\nQ,R = np.linalg.qr(A)\n\nprint(\"QR decomposition:\")\nprint(\"\\nQ\")\nprint( Q )\nprint(\"\\nR\")\nprint( R )\n</pre> # descomposicion QR Q,R = np.linalg.qr(A)  print(\"QR decomposition:\") print(\"\\nQ\") print( Q ) print(\"\\nR\") print( R ) <pre>QR decomposition:\n\nQ\n[[-0.31622777 -0.9486833 ]\n [-0.9486833   0.31622777]]\n\nR\n[[-3.16227766 -4.42718872]\n [ 0.         -0.63245553]]\n</pre> <ul> <li>Resolver sitema de ecuaciones:</li> </ul> In\u00a0[26]: Copied! <pre># crear matriz\nA = np.array([[1,2],\n              [3,4]])\n\n# sistemas lineales: Ax = b\nb = np.array([[5.], [7.]])\n</pre> # crear matriz A = np.array([[1,2],               [3,4]])  # sistemas lineales: Ax = b b = np.array([[5.], [7.]]) In\u00a0[27]: Copied! <pre>print(\"linear system: Ax=b\")\nprint(\"\\nx = \")\nprint( np.linalg.solve(A, b) )\n</pre> print(\"linear system: Ax=b\") print(\"\\nx = \") print( np.linalg.solve(A, b) ) <pre>linear system: Ax=b\n\nx = \n[[-3.]\n [ 4.]]\n</pre>"},{"location":"numpy/024_algebra_lineal/#algebra-lineal","title":"Algebra Lineal\u00b6","text":"<p>NumPy es una biblioteca popular en Python para el \u00e1lgebra lineal, que es una rama de las matem\u00e1ticas que se enfoca en el estudio de vectores, matrices y sistemas de ecuaciones lineales. NumPy proporciona una gran cantidad de funciones y m\u00e9todos para realizar operaciones de \u00e1lgebra lineal de manera eficiente en Python.</p> <p>Aqu\u00ed hay algunos ejemplos de operaciones de \u00e1lgebra lineal que se pueden realizar con NumPy:</p>"},{"location":"numpy/025_broadcasting/","title":"Broadcasting","text":"In\u00a0[2]: Copied! <pre>import numpy as np\n</pre> import numpy as np In\u00a0[3]: Copied! <pre># example 01\na = np.arange(3)+ 5\nprint(f\"np.arange(3) + 5:\\n{a}\" )\n</pre> # example 01 a = np.arange(3)+ 5 print(f\"np.arange(3) + 5:\\n{a}\" ) <pre>np.arange(3)+ 5:\n[5 6 7]\n</pre> In\u00a0[4]: Copied! <pre># example 02\nb = np.ones((3,3))+np.arange(3)\nprint(f\"np.ones((3,3)) + np.arange(3):\\n{b}\" )\n</pre> # example 02 b = np.ones((3,3))+np.arange(3) print(f\"np.ones((3,3)) + np.arange(3):\\n{b}\" ) <pre>np.ones((3,3))+np.arange(3):\n[[1. 2. 3.]\n [1. 2. 3.]\n [1. 2. 3.]]\n</pre> In\u00a0[5]: Copied! <pre># example 03\nc = np.arange(3).reshape((3,1)) +  np.arange(3)\nprint(f\"np.arange(3).reshape((3,1)) + np.arange(3):\\n{c }\" )\n</pre> # example 03 c = np.arange(3).reshape((3,1)) +  np.arange(3) print(f\"np.arange(3).reshape((3,1)) + np.arange(3):\\n{c }\" ) <pre>np.arange(3).reshape((3,1)) + np.arange(3):\n[[0 1 2]\n [1 2 3]\n [2 3 4]]\n</pre>"},{"location":"numpy/025_broadcasting/#broadcasting","title":"Broadcasting\u00b6","text":"<p>Broadcasting es un t\u00e9rmino utilizado en NumPy para describir la forma en que las operaciones entre arrays con diferentes formas se manejan autom\u00e1ticamente por NumPy. En otras palabras, cuando se realizan operaciones aritm\u00e9ticas entre dos arrays de diferentes formas, NumPy ajusta autom\u00e1ticamente la forma del array m\u00e1s peque\u00f1o para que coincida con la forma del array m\u00e1s grande antes de realizar la operaci\u00f3n. Esto permite que las operaciones se realicen de manera eficiente sin la necesidad de crear copias adicionales de los datos.</p> <p>Las reglas de broadcasting en NumPy son las siguientes:</p> <ul> <li><p>Si los dos arrays tienen el mismo n\u00famero de dimensiones, pero las formas no son iguales, NumPy agrega 1 a la forma del array m\u00e1s peque\u00f1o para que coincida con la forma del array m\u00e1s grande.</p> </li> <li><p>Si la forma de los dos arrays no es la misma y no tienen el mismo n\u00famero de dimensiones, NumPy agrega 1 a las dimensiones menos y expande las formas de los arrays para que sean iguales en la dimensi\u00f3n m\u00e1s alta.</p> </li> <li><p>Si la forma de los dos arrays no es la misma y alguna dimensi\u00f3n no coincide, NumPy genera un error.</p> </li> </ul>"},{"location":"numpy/ejercicios/","title":"Ejercicios","text":"In\u00a0[1]: Copied! <pre>import numpy as np\n</pre> import numpy as np <p>Ejercicio 1: Crear un arreglo NumPy 1D de 5 elementos con valores enteros del 0 al 4.</p> In\u00a0[2]: Copied! <pre>arr = np.array([0, 1, 2, 3, 4])\nprint(arr)\n</pre> arr = np.array([0, 1, 2, 3, 4]) print(arr) <pre>[0 1 2 3 4]\n</pre> <p>Ejercicio 2: Crear un arreglo NumPy 2D de 3x3 con todos los elementos igual a 1.ual a 1.</p> In\u00a0[3]: Copied! <pre>arr = np.ones((3, 3))\nprint(arr)\n</pre> arr = np.ones((3, 3)) print(arr) <pre>[[1. 1. 1.]\n [1. 1. 1.]\n [1. 1. 1.]]\n</pre> <p>Ejercicio 3: Crear un arreglo NumPy 1D de 10 elementos con valores equidistantes entre 0 y 1.</p> In\u00a0[4]: Copied! <pre>arr = np.linspace(0, 1, 10)\nprint(arr)\n</pre> arr = np.linspace(0, 1, 10) print(arr) <pre>[0.         0.11111111 0.22222222 0.33333333 0.44444444 0.55555556\n 0.66666667 0.77777778 0.88888889 1.        ]\n</pre> <p>Ejercicio 4: Crear un arreglo NumPy 2D de 3x3 con valores aleatorios entre 0 y 1.</p> In\u00a0[5]: Copied! <pre>arr = np.random.rand(3, 3)\nprint(arr)\n</pre> arr = np.random.rand(3, 3) print(arr) <pre>[[0.41951944 0.06979298 0.18179434]\n [0.62465905 0.77333522 0.6738003 ]\n [0.35120366 0.02928759 0.84761288]]\n</pre> <p>Ejercicio 5: Crear un arreglo NumPy 1D con n\u00fameros enteros pares del 0 al 10.</p> In\u00a0[6]: Copied! <pre>arr = np.arange(0, 11, 2)\nprint(arr)\n</pre> arr = np.arange(0, 11, 2) print(arr) <pre>[ 0  2  4  6  8 10]\n</pre> <p>Ejercicio 6: Crear un arreglo NumPy 2D de 4x4 con n\u00fameros enteros aleatorios en el rango de 1 a 10.</p> In\u00a0[7]: Copied! <pre>arr = np.random.randint(1, 11, (4, 4))\nprint(arr)\n</pre> arr = np.random.randint(1, 11, (4, 4)) print(arr) <pre>[[ 8  4  9  5]\n [ 8 10  6 10]\n [ 7  6  7  8]\n [ 3  9  6  7]]\n</pre> <p>Ejercicio 7: Crear un arreglo NumPy 1D con los primeros 5 n\u00fameros primos.</p> In\u00a0[8]: Copied! <pre>primes = np.array([2, 3, 5, 7, 11])\nprint(primes)\n</pre> primes = np.array([2, 3, 5, 7, 11]) print(primes) <pre>[ 2  3  5  7 11]\n</pre> <p>Ejercicio 8: Crear un arreglo NumPy 1D con valores de 0 a 9 y luego invertir el orden de los elementos.</p> In\u00a0[9]: Copied! <pre>arr = np.arange(10)\narr_inverted = arr[::-1]\nprint(arr_inverted)\n</pre> arr = np.arange(10) arr_inverted = arr[::-1] print(arr_inverted) <pre>[9 8 7 6 5 4 3 2 1 0]\n</pre> <p>Ejercicio 9: Dado un arreglo NumPy 1D, calcular la suma de sus elementos.</p> In\u00a0[10]: Copied! <pre>arr = np.array([1, 2, 3, 4, 5])\nsuma = np.sum(arr)\nprint(suma)\n</pre> arr = np.array([1, 2, 3, 4, 5]) suma = np.sum(arr) print(suma) <pre>15\n</pre> <p>Ejercicio 10: Dado un arreglo NumPy 2D, calcular la suma de cada columna por separado.</p> In\u00a0[11]: Copied! <pre>arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\nsuma_columnas = np.sum(arr, axis=0)\nprint(suma_columnas)\n</pre> arr = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) suma_columnas = np.sum(arr, axis=0) print(suma_columnas) <pre>[12 15 18]\n</pre> In\u00a0[12]: Copied! <pre>a = np.array([1, 2, 3, 4])\nb = np.array([5, 6, 7, 8])\n</pre> a = np.array([1, 2, 3, 4]) b = np.array([5, 6, 7, 8]) In\u00a0[13]: Copied! <pre>suma = a + b\nresta = a - b\nmultiplicacion = a * b\ndivision = a / b\n\nprint(\"Suma:\", suma)\nprint(\"Resta:\", resta)\nprint(\"Multiplicaci\u00f3n:\", multiplicacion)\nprint(\"Divisi\u00f3n:\", division)\n</pre> suma = a + b resta = a - b multiplicacion = a * b division = a / b  print(\"Suma:\", suma) print(\"Resta:\", resta) print(\"Multiplicaci\u00f3n:\", multiplicacion) print(\"Divisi\u00f3n:\", division) <pre>Suma: [ 6  8 10 12]\nResta: [-4 -4 -4 -4]\nMultiplicaci\u00f3n: [ 5 12 21 32]\nDivisi\u00f3n: [0.2        0.33333333 0.42857143 0.5       ]\n</pre> <p>Ejercicio 2: Calcula el promedio, la mediana y la desviaci\u00f3n est\u00e1ndar de un arreglo NumPy 1D <code>datos</code>.</p> In\u00a0[14]: Copied! <pre>datos = np.array([10, 15, 20, 25, 30, 35, 40])\n</pre> datos = np.array([10, 15, 20, 25, 30, 35, 40]) In\u00a0[15]: Copied! <pre>promedio = np.mean(datos)\nmediana = np.median(datos)\ndesviacion_estandar = np.std(datos)\n\nprint(\"Promedio:\", promedio)\nprint(\"Mediana:\", mediana)\nprint(\"Desviaci\u00f3n Est\u00e1ndar:\", desviacion_estandar)\n</pre> promedio = np.mean(datos) mediana = np.median(datos) desviacion_estandar = np.std(datos)  print(\"Promedio:\", promedio) print(\"Mediana:\", mediana) print(\"Desviaci\u00f3n Est\u00e1ndar:\", desviacion_estandar) <pre>Promedio: 25.0\nMediana: 25.0\nDesviaci\u00f3n Est\u00e1ndar: 10.0\n</pre> <p>Ejercicio 3: Calcula el producto punto de dos arreglos NumPy 1D <code>a</code> y <code>b</code>.</p> In\u00a0[16]: Copied! <pre>a = np.array([1, 2, 3])\nb = np.array([4, 5, 6])\n</pre> a = np.array([1, 2, 3]) b = np.array([4, 5, 6]) In\u00a0[17]: Copied! <pre>producto_punto = np.dot(a, b)\n\nprint(\"Producto Punto:\", producto_punto)\n</pre> producto_punto = np.dot(a, b)  print(\"Producto Punto:\", producto_punto) <pre>Producto Punto: 32\n</pre> <p>Ejercicio 4: Encuentra el valor m\u00ednimo y m\u00e1ximo en un arreglo NumPy 1D <code>valores</code>.</p> In\u00a0[18]: Copied! <pre>valores = np.array([5, 8, 2, 10, 3])\n</pre> valores = np.array([5, 8, 2, 10, 3]) In\u00a0[19]: Copied! <pre>minimo = np.min(valores)\nmaximo = np.max(valores)\n\nprint(\"Valor M\u00ednimo:\", minimo)\nprint(\"Valor M\u00e1ximo:\", maximo)\n</pre> minimo = np.min(valores) maximo = np.max(valores)  print(\"Valor M\u00ednimo:\", minimo) print(\"Valor M\u00e1ximo:\", maximo) <pre>Valor M\u00ednimo: 2\nValor M\u00e1ximo: 10\n</pre> <p>Ejercicio 5: Calcula la suma acumulativa de un arreglo NumPy 1D <code>serie</code>.</p> In\u00a0[20]: Copied! <pre>serie = np.array([1, 2, 3, 4, 5])\n</pre> serie = np.array([1, 2, 3, 4, 5]) In\u00a0[21]: Copied! <pre>suma_acumulativa = np.cumsum(serie)\n\nprint(\"Suma Acumulativa:\", suma_acumulativa)\n</pre> suma_acumulativa = np.cumsum(serie)  print(\"Suma Acumulativa:\", suma_acumulativa) <pre>Suma Acumulativa: [ 1  3  6 10 15]\n</pre> <p>Ejercicio 6: Calcula el promedio de cada fila y cada columna en un arreglo NumPy 2D <code>matriz</code>.</p> In\u00a0[22]: Copied! <pre>matriz = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n</pre> matriz = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]) In\u00a0[23]: Copied! <pre>promedio_filas = np.mean(matriz, axis=1)\npromedio_columnas = np.mean(matriz, axis=0)\n\nprint(\"Promedio por Filas:\", promedio_filas)\nprint(\"Promedio por Columnas:\", promedio_columnas)\n</pre> promedio_filas = np.mean(matriz, axis=1) promedio_columnas = np.mean(matriz, axis=0)  print(\"Promedio por Filas:\", promedio_filas) print(\"Promedio por Columnas:\", promedio_columnas) <pre>Promedio por Filas: [2. 5. 8.]\nPromedio por Columnas: [4. 5. 6.]\n</pre> <p>Ejercicio 7: Calcula la potencia de un arreglo NumPy 1D <code>numeros</code> al cuadrado.</p> In\u00a0[24]: Copied! <pre>numeros = np.array([2, 3, 4, 5, 6])\n</pre> numeros = np.array([2, 3, 4, 5, 6]) In\u00a0[25]: Copied! <pre>cuadrado = np.power(numeros, 2)\n\nprint(\"Cuadrado:\", cuadrado)\n</pre> cuadrado = np.power(numeros, 2)  print(\"Cuadrado:\", cuadrado) <pre>Cuadrado: [ 4  9 16 25 36]\n</pre> <p>Ejercicio 8: Encuentra el valor absoluto de un arreglo NumPy 1D <code>valores</code></p> In\u00a0[26]: Copied! <pre>valores = np.array([-3, 5, -7, 8, -2])\n</pre> valores = np.array([-3, 5, -7, 8, -2]) In\u00a0[27]: Copied! <pre>valor_absoluto = np.abs(valores)\n\nprint(\"Valor Absoluto:\", valor_absoluto)\n</pre> valor_absoluto = np.abs(valores)  print(\"Valor Absoluto:\", valor_absoluto) <pre>Valor Absoluto: [3 5 7 8 2]\n</pre> <p>Ejercicio 9: Calcula la media ponderada de un arreglo NumPy 1D <code>datos</code> con pesos correspondientes en el arreglo <code>pesos</code>.</p> In\u00a0[28]: Copied! <pre>datos = np.array([10, 15, 20, 25, 30])\npesos = np.array([0.1, 0.2, 0.3, 0.2, 0.2])\n</pre> datos = np.array([10, 15, 20, 25, 30]) pesos = np.array([0.1, 0.2, 0.3, 0.2, 0.2]) In\u00a0[29]: Copied! <pre>media_ponderada = np.average(datos, weights=pesos)\n\nprint(\"Media Ponderada:\", media_ponderada)\n</pre> media_ponderada = np.average(datos, weights=pesos)  print(\"Media Ponderada:\", media_ponderada) <pre>Media Ponderada: 21.0\n</pre> <p>Ejercicio 10: Calcula el producto de matrices de dos arreglos NumPy 2D <code>matriz_a</code> y <code>matriz_b</code>.</p> In\u00a0[30]: Copied! <pre>matriz_a = np.array([[1, 2], [3, 4]])\nmatriz_b = np.array([[5, 6], [7, 8]])\n</pre> matriz_a = np.array([[1, 2], [3, 4]]) matriz_b = np.array([[5, 6], [7, 8]]) In\u00a0[31]: Copied! <pre>producto_matrices = np.dot(matriz_a, matriz_b)\n\nprint(\"Producto de Matrices:\")\nprint(producto_matrices)\n</pre> producto_matrices = np.dot(matriz_a, matriz_b)  print(\"Producto de Matrices:\") print(producto_matrices) <pre>Producto de Matrices:\n[[19 22]\n [43 50]]\n</pre> <p>Ejercicio 2: Extraer una subserie de un arreglo NumPy 1D <code>arr</code> que contenga elementos desde el segundo al cuarto (inclusive).</p> <p>Ejercicio 3: Extraer los elementos pares de un arreglo NumPy 1D <code>numeros</code>.</p> <p>Ejercicio 4: En un arreglo NumPy 2D <code>matriz</code>, extraer la segunda fila y la tercera columna.</p> <p>Ejercicio 5: En un arreglo NumPy 2D <code>matriz</code>, extraer todos los elementos que sean mayores que 5.</p> <p>Ejercicio 6: Crear una vista de un arreglo NumPy 1D <code>original</code> que contenga solo los elementos desde el segundo al quinto (inclusive).</p> <p>Ejercicio 7: En un arreglo NumPy 2D <code>matriz</code>, extraer los elementos de la segunda fila que sean mayores que 3.</p> <p>Ejercicio 8: Crear una vista de un arreglo NumPy 2D <code>original</code> que contenga solo la primera y la \u00faltima fila.</p> <p>Ejercicio 9: En un arreglo NumPy 2D <code>matriz</code>, extraer las filas pares.</p> <p>Ejercicio 10: En un arreglo NumPy 2D <code>matriz</code>, reemplazar todos los elementos mayores que 5 por el valor 0.</p>"},{"location":"numpy/ejercicios/#ejercicios","title":"Ejercicios\u00b6","text":""},{"location":"numpy/ejercicios/#numpy-arrays","title":"Numpy Arrays\u00b6","text":""},{"location":"numpy/ejercicios/#operaciones-matematicas","title":"Operaciones Matem\u00e1ticas\u00b6","text":"<p>Ejercicio 1: Encuentra la suma, resta, multiplicaci\u00f3n y divisi\u00f3n de dos arreglos NumPy de 1D <code>a</code> y <code>b</code>.</p>"},{"location":"numpy/ejercicios/#indexacion","title":"Indexaci\u00f3n\u00b6","text":"<p>Ejercicio 1: Extraer el tercer elemento de un arreglo NumPy 1D <code>arr</code>.</p>"},{"location":"numpy/intro/","title":"Computaci\u00f3n Cient\u00edfica\ud83d\udcda Table of Contents:","text":""},{"location":"numpy/scipy/","title":"SciPy","text":"<p><code>SciPy</code> se basa en el marco <code>NumPy</code> de bajo nivel para matrices multidimensionales y proporciona una gran cantidad de algoritmos cient\u00edficos de alto nivel. Algunos de los temas que cubre SciPy son:</p> <ul> <li>Special functions (scipy.special)</li> <li>Integration (scipy.integrate)</li> <li>Optimization (scipy.optimize)</li> <li>Interpolation (scipy.interpolate)</li> <li>Fourier Transforms (scipy.fftpack)</li> <li>Signal Processing (scipy.signal)</li> <li>Sparse Eigenvalue Problems (scipy.sparse)</li> <li>Statistics (scipy.stats)</li> </ul> <p>Cada uno de estos subm\u00f3dulos proporciona una serie de funciones y clases que se pueden utilizar para resolver problemas en sus respectivos temas.</p> <p>En esta lecci\u00f3n veremos c\u00f3mo usar algunos de estos subpaquetes.</p> <p>Para acceder al paquete SciPy en un programa Python, comenzamos importando todo desde el m\u00f3dulo <code>scipy</code>.</p> In\u00a0[1]: Copied! <pre>from scipy import *\n</pre> from scipy import * <p>Si solo necesitamos usar parte del marco SciPy, podemos incluir selectivamente solo aquellos m\u00f3dulos que nos interesan. Por ejemplo, para incluir el paquete de \u00e1lgebra lineal bajo el nombre <code>la</code>, podemos hacer:</p> In\u00a0[2]: Copied! <pre>import scipy.linalg as la\n</pre> import scipy.linalg as la <p>Un gran n\u00famero de funciones matem\u00e1ticas especiales son importantes para muchos problemas de f\u00edsica computacional. SciPy proporciona implementaciones de un conjunto muy extenso de funciones especiales. Para obtener m\u00e1s detalles, consulte la lista de funciones en el documento de referencia en http://docs.scipy.org/doc/scipy/reference/special.html#module-scipy.special.</p> <p>Para demostrar el uso t\u00edpico de funciones especiales, veremos con m\u00e1s detalle las funciones de Bessel:</p> In\u00a0[3]: Copied! <pre>#\n# The scipy.special module includes a large number of Bessel-functions\n# Here we will use the functions jn and yn, which are the Bessel functions \n# of the first and second kind and real-valued order. We also include the \n# function jn_zeros and yn_zeros that gives the zeroes of the functions jn\n# and yn.\n#\nfrom scipy.special import jn, yn, jn_zeros, yn_zeros\nimport numpy as np\nimport matplotlib.pyplot as plt\n</pre> # # The scipy.special module includes a large number of Bessel-functions # Here we will use the functions jn and yn, which are the Bessel functions  # of the first and second kind and real-valued order. We also include the  # function jn_zeros and yn_zeros that gives the zeroes of the functions jn # and yn. # from scipy.special import jn, yn, jn_zeros, yn_zeros import numpy as np import matplotlib.pyplot as plt In\u00a0[4]: Copied! <pre>n = 0    # order\nx = 0.0\n\n# Bessel function of first kind\nprint( f\"J_{n}({x}) = {jn(n, x)}\")\n</pre> n = 0    # order x = 0.0  # Bessel function of first kind print( f\"J_{n}({x}) = {jn(n, x)}\") <pre>J_0(0.0) = 1.0\n</pre> In\u00a0[5]: Copied! <pre>x = 1.0\n# Bessel function of second kind\nprint( f\"Y_{n}({x}) = {yn(n, x)}\")\n</pre> x = 1.0 # Bessel function of second kind print( f\"Y_{n}({x}) = {yn(n, x)}\") <pre>Y_0(1.0) = 0.08825696421567697\n</pre> In\u00a0[6]: Copied! <pre>x = np.linspace(0, 10, 100)\n\nfig, ax = plt.subplots()\nfor n in range(4):\n    ax.plot(x, jn(n, x), label=r\"$J_%d(x)$\" % n)\nax.legend();\nplt.show()\n</pre> x = np.linspace(0, 10, 100)  fig, ax = plt.subplots() for n in range(4):     ax.plot(x, jn(n, x), label=r\"$J_%d(x)$\" % n) ax.legend(); plt.show() In\u00a0[7]: Copied! <pre># zeros of Bessel functions\nn = 0 # order\nm = 4 # number of roots to compute\njn_zeros(n, m)\n</pre> # zeros of Bessel functions n = 0 # order m = 4 # number of roots to compute jn_zeros(n, m) Out[7]: <pre>array([ 2.40482556,  5.52007811,  8.65372791, 11.79153444])</pre> <p>Evaluaci\u00f3n num\u00e9rica de una funci\u00f3n del tipo $\\displaystyle \\int_a^b f(x) dx$</p> <p>se llama cuadratura num\u00e9rica, o simplemente cuadratura. SciPy proporciona una serie de funciones para diferentes tipos de cuadratura, por ejemplo, <code>quad</code>,<code> dblquad</code> y <code>tplquad</code> para integrales simples, dobles y triples, respectivamente.</p> In\u00a0[8]: Copied! <pre>from scipy.integrate import quad, dblquad, tplquad\n</pre> from scipy.integrate import quad, dblquad, tplquad <p>La funci\u00f3n <code>quad</code> toma una gran cantidad de argumentos opcionales, que se pueden usar para ajustar el comportamiento de la funci\u00f3n (prueba con<code>help (quad)</code>para obtener m\u00e1s detalles).</p> <p>El uso b\u00e1sico es el siguiente:</p> In\u00a0[9]: Copied! <pre># define a simple function for the integrand\ndef f(x):\n    return x\n</pre> # define a simple function for the integrand def f(x):     return x In\u00a0[10]: Copied! <pre>x_lower = 0 # the lower limit of x\nx_upper = 1 # the upper limit of x\n\nval, abserr = quad(f, x_lower, x_upper)\n\nprint(f\"integral value = {val} absolute error = {abserr}\" )\n</pre> x_lower = 0 # the lower limit of x x_upper = 1 # the upper limit of x  val, abserr = quad(f, x_lower, x_upper)  print(f\"integral value = {val} absolute error = {abserr}\" ) <pre>integral value = 0.5 absolute error = 5.551115123125783e-15\n</pre> <p>Si necesitamos pasar argumentos adicionales a la funci\u00f3n integrando, podemos usar el argumento de palabra clave <code>args</code>:</p> In\u00a0[11]: Copied! <pre>def integrand(x, n):\n    \"\"\"\n    Bessel function of first kind and order n. \n    \"\"\"\n    return jn(n, x)\n\n\nx_lower = 0  # the lower limit of x\nx_upper = 10 # the upper limit of x\n\nval, abserr = quad(integrand, x_lower, x_upper, args=(3,))\n\nprint(val, abserr )\n</pre> def integrand(x, n):     \"\"\"     Bessel function of first kind and order n.      \"\"\"     return jn(n, x)   x_lower = 0  # the lower limit of x x_upper = 10 # the upper limit of x  val, abserr = quad(integrand, x_lower, x_upper, args=(3,))  print(val, abserr ) <pre>0.7366751370811073 9.389126882496403e-13\n</pre> <p>Para funciones simples, podemos usar una funci\u00f3n lambda (funci\u00f3n sin nombre) en lugar de definir expl\u00edcitamente una funci\u00f3n para el integrando:</p> In\u00a0[12]: Copied! <pre>val, abserr = quad(lambda x: np.exp(-x ** 2), -Inf, Inf)\n\nprint( f\"numerical  = {val} {abserr}\")\n</pre> val, abserr = quad(lambda x: np.exp(-x ** 2), -Inf, Inf)  print( f\"numerical  = {val} {abserr}\") <pre>numerical  = 1.7724538509055159 1.4202636780944923e-08\n</pre> In\u00a0[13]: Copied! <pre>analytical = np.lib.scimath.sqrt(pi)\nprint(f\"analytical = {analytical}\")\n</pre> analytical = np.lib.scimath.sqrt(pi) print(f\"analytical = {analytical}\") <pre>analytical = 1.7724538509055159\n</pre> <p>Como se muestra en el ejemplo anterior, tambi\u00e9n podemos usar <code>Inf</code> o <code>-Inf</code> como l\u00edmites integrales.</p> <p>La integraci\u00f3n de dimensiones superiores funciona de la misma manera:</p> In\u00a0[14]: Copied! <pre>def integrand(x, y):\n    return np.exp(-x**2-y**2)\n\nx_lower = 0  \nx_upper = 10\ny_lower = 0\ny_upper = 10\n\nval, abserr = dblquad(integrand, x_lower, x_upper, lambda x : y_lower, lambda x: y_upper)\n\nprint( val, abserr )\n</pre> def integrand(x, y):     return np.exp(-x**2-y**2)  x_lower = 0   x_upper = 10 y_lower = 0 y_upper = 10  val, abserr = dblquad(integrand, x_lower, x_upper, lambda x : y_lower, lambda x: y_upper)  print( val, abserr ) <pre>0.7853981633974476 1.3753098510218528e-08\n</pre> <p>Observe c\u00f3mo tuvimos que pasar funciones lambda para los l\u00edmites de la integraci\u00f3n $y$, ya que estas en general pueden ser funciones de $x$.</p> In\u00a0[15]: Copied! <pre>from scipy.integrate import odeint, ode\n</pre> from scipy.integrate import odeint, ode <p>Un sistema de EDO se suele formular en forma est\u00e1ndar antes de ser atacado num\u00e9ricamente. La forma est\u00e1ndar es:</p> <p>$y' = f(y, t)$, donde:   $y = [y_1(t), y_2(t), ..., y_n(t)]$</p> <p>y $ f $ es alguna funci\u00f3n que da las derivadas de la funci\u00f3n $ y_i (t) $. Para resolver una EDO necesitamos conocer la funci\u00f3n $ f $ y una condici\u00f3n inicial, $ y (0) $.</p> <p>Tenga en cuenta que las EDO de orden superior siempre se pueden escribir de esta forma introduciendo nuevas variables para las derivadas intermedias.</p> <p>Una vez que hemos definido la funci\u00f3n de Python <code>f</code> y la matriz<code> y_0</code> (que es $ f $ y $ y (0) $ en la formulaci\u00f3n matem\u00e1tica), podemos usar la funci\u00f3n <code>odeint</code> como:</p> <pre>y_t = odeint(f, y_0, t)\n</pre> <p>donde <code>t</code> es una matriz con coordenadas de tiempo para resolver el problema de ODE. <code>y_t</code> es una matriz con una fila para cada punto en el tiempo en<code> t</code>, donde cada columna corresponde a una soluci\u00f3n <code>y_i (t)</code> en ese momento.</p> <p>Veremos c\u00f3mo podemos implementar <code>f</code> e<code> y_0</code> en c\u00f3digo Python en los ejemplos siguientes.</p> <p></p> <p>Las ecuaciones de movimiento del p\u00e9ndulo se dan en la p\u00e1gina wiki:</p> <p>${\\dot \\theta_1} = \\frac{6}{m\\ell^2} \\frac{ 2 p_{\\theta_1} - 3 \\cos(\\theta_1-\\theta_2) p_{\\theta_2}}{16 - 9 \\cos^2(\\theta_1-\\theta_2)}$</p> <p>${\\dot \\theta_2} = \\frac{6}{m\\ell^2} \\frac{ 8 p_{\\theta_2} - 3 \\cos(\\theta_1-\\theta_2) p_{\\theta_1}}{16 - 9 \\cos^2(\\theta_1-\\theta_2)}.$</p> <p>${\\dot p_{\\theta_1}} = -\\frac{1}{2} m \\ell^2 \\left [ {\\dot \\theta_1} {\\dot \\theta_2} \\sin (\\theta_1-\\theta_2) + 3 \\frac{g}{\\ell} \\sin \\theta_1 \\right ]$</p> <p>${\\dot p_{\\theta_2}} = -\\frac{1}{2} m \\ell^2 \\left [ -{\\dot \\theta_1} {\\dot \\theta_2} \\sin (\\theta_1-\\theta_2) +  \\frac{g}{\\ell} \\sin \\theta_2 \\right]$</p> <p>Para simplificar el seguimiento del c\u00f3digo Python, introduzcamos nuevos nombres de variables y la notaci\u00f3n vectorial: $x = [\\theta_1, \\theta_2, p_{\\theta_1}, p_{\\theta_2}]$</p> <p>${\\dot x_1} = \\frac{6}{m\\ell^2} \\frac{ 2 x_3 - 3 \\cos(x_1-x_2) x_4}{16 - 9 \\cos^2(x_1-x_2)}$</p> <p>${\\dot x_2} = \\frac{6}{m\\ell^2} \\frac{ 8 x_4 - 3 \\cos(x_1-x_2) x_3}{16 - 9 \\cos^2(x_1-x_2)}$</p> <p>${\\dot x_3} = -\\frac{1}{2} m \\ell^2 \\left [ {\\dot x_1} {\\dot x_2} \\sin (x_1-x_2) + 3 \\frac{g}{\\ell} \\sin x_1 \\right ]$</p> <p>${\\dot x_4} = -\\frac{1}{2} m \\ell^2 \\left [ -{\\dot x_1} {\\dot x_2} \\sin (x_1-x_2) +  \\frac{g}{\\ell} \\sin x_2 \\right]$</p> In\u00a0[16]: Copied! <pre>g = 9.82\nL = 0.5\nm = 0.1\n\ndef dx(x, t):\n    \"\"\"\n    The right-hand side of the pendulum ODE\n    \"\"\"\n    x1, x2, x3, x4 = x[0], x[1], x[2], x[3]\n    \n    dx1 = 6.0/(m*L**2) * (2 * x3 - 3 * np.cos(x1-x2) * x4)/(16 - 9 *  np.cos(x1-x2)**2)\n    dx2 = 6.0/(m*L**2) * (8 * x4 - 3 *  np.cos(x1-x2) * x3)/(16 - 9 *  np.cos(x1-x2)**2)\n    dx3 = -0.5 * m * L**2 * ( dx1 * dx2 *  np.sin(x1-x2) + 3 * (g/L) *  np.sin(x1))\n    dx4 = -0.5 * m * L**2 * (-dx1 * dx2 *  np.sin(x1-x2) + (g/L) *  np.sin(x2))\n    \n    return [dx1, dx2, dx3, dx4]\n</pre> g = 9.82 L = 0.5 m = 0.1  def dx(x, t):     \"\"\"     The right-hand side of the pendulum ODE     \"\"\"     x1, x2, x3, x4 = x[0], x[1], x[2], x[3]          dx1 = 6.0/(m*L**2) * (2 * x3 - 3 * np.cos(x1-x2) * x4)/(16 - 9 *  np.cos(x1-x2)**2)     dx2 = 6.0/(m*L**2) * (8 * x4 - 3 *  np.cos(x1-x2) * x3)/(16 - 9 *  np.cos(x1-x2)**2)     dx3 = -0.5 * m * L**2 * ( dx1 * dx2 *  np.sin(x1-x2) + 3 * (g/L) *  np.sin(x1))     dx4 = -0.5 * m * L**2 * (-dx1 * dx2 *  np.sin(x1-x2) + (g/L) *  np.sin(x2))          return [dx1, dx2, dx3, dx4] In\u00a0[17]: Copied! <pre># choose an initial state\nx0 = [pi/4, pi/2, 0, 0]\n</pre> # choose an initial state x0 = [pi/4, pi/2, 0, 0] In\u00a0[18]: Copied! <pre># time coodinate to solve the ODE for: from 0 to 10 seconds\nt = np.linspace(0, 10, 250)\n</pre> # time coodinate to solve the ODE for: from 0 to 10 seconds t = np.linspace(0, 10, 250) In\u00a0[19]: Copied! <pre># solve the ODE problem\nx = odeint(dx, x0, t)\n</pre> # solve the ODE problem x = odeint(dx, x0, t) In\u00a0[20]: Copied! <pre># plot the angles as a function of time\n\nfig, axes = plt.subplots(1,2, figsize=(12,4))\naxes[0].plot(t, x[:, 0], 'r', label=\"theta1\")\naxes[0].plot(t, x[:, 1], 'b', label=\"theta2\")\n\n\nx1 = + L *  np.sin(x[:, 0])\ny1 = - L *  np.cos(x[:, 0])\n\nx2 = x1 + L *  np.sin(x[:, 1])\ny2 = y1 - L *  np.cos(x[:, 1])\n    \naxes[1].plot(x1, y1, 'r', label=\"pendulum1\")\naxes[1].plot(x2, y2, 'b', label=\"pendulum2\")\naxes[1].set_ylim([-1, 0])\naxes[1].set_xlim([1, -1]);\n</pre> # plot the angles as a function of time  fig, axes = plt.subplots(1,2, figsize=(12,4)) axes[0].plot(t, x[:, 0], 'r', label=\"theta1\") axes[0].plot(t, x[:, 1], 'b', label=\"theta2\")   x1 = + L *  np.sin(x[:, 0]) y1 = - L *  np.cos(x[:, 0])  x2 = x1 + L *  np.sin(x[:, 1]) y2 = y1 - L *  np.cos(x[:, 1])      axes[1].plot(x1, y1, 'r', label=\"pendulum1\") axes[1].plot(x2, y2, 'b', label=\"pendulum2\") axes[1].set_ylim([-1, 0]) axes[1].set_xlim([1, -1]); In\u00a0[21]: Copied! <pre>def dy(y, t, zeta, w0):\n    \"\"\"\n    The right-hand side of the damped oscillator ODE\n    \"\"\"\n    x, p = y[0], y[1]\n    \n    dx = p\n    dp = -2 * zeta * w0 * p - w0**2 * x\n\n    return [dx, dp]\n</pre> def dy(y, t, zeta, w0):     \"\"\"     The right-hand side of the damped oscillator ODE     \"\"\"     x, p = y[0], y[1]          dx = p     dp = -2 * zeta * w0 * p - w0**2 * x      return [dx, dp] In\u00a0[22]: Copied! <pre># initial state: \ny0 = [1.0, 0.0]\n</pre> # initial state:  y0 = [1.0, 0.0] In\u00a0[23]: Copied! <pre># time coodinate to solve the ODE for\nt =  np.linspace(0, 10, 1000)\nw0 = 2*pi*1.0\n</pre> # time coodinate to solve the ODE for t =  np.linspace(0, 10, 1000) w0 = 2*pi*1.0 In\u00a0[24]: Copied! <pre># solve the ODE problem for three different values of the damping ratio\n\ny1 = odeint(dy, y0, t, args=(0.0, w0)) # undamped\ny2 = odeint(dy, y0, t, args=(0.2, w0)) # under damped\ny3 = odeint(dy, y0, t, args=(1.0, w0)) # critial damping\ny4 = odeint(dy, y0, t, args=(5.0, w0)) # over damped\n</pre> # solve the ODE problem for three different values of the damping ratio  y1 = odeint(dy, y0, t, args=(0.0, w0)) # undamped y2 = odeint(dy, y0, t, args=(0.2, w0)) # under damped y3 = odeint(dy, y0, t, args=(1.0, w0)) # critial damping y4 = odeint(dy, y0, t, args=(5.0, w0)) # over damped In\u00a0[25]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(t, y1[:,0], 'k', label=\"undamped\", linewidth=0.25)\nax.plot(t, y2[:,0], 'r', label=\"under damped\")\nax.plot(t, y3[:,0], 'b', label=r\"critical damping\")\nax.plot(t, y4[:,0], 'g', label=\"over damped\")\nax.legend();\n</pre> fig, ax = plt.subplots() ax.plot(t, y1[:,0], 'k', label=\"undamped\", linewidth=0.25) ax.plot(t, y2[:,0], 'r', label=\"under damped\") ax.plot(t, y3[:,0], 'b', label=r\"critical damping\") ax.plot(t, y4[:,0], 'g', label=\"over damped\") ax.legend(); In\u00a0[26]: Copied! <pre>from numpy.fft import fftfreq\nfrom scipy.fftpack import *\n</pre> from numpy.fft import fftfreq from scipy.fftpack import * <p>Para demostrar c\u00f3mo hacer una transformada r\u00e1pida de Fourier con SciPy, veamos la FFT de la soluci\u00f3n al oscilador amortiguado de la secci\u00f3n anterior:</p> In\u00a0[27]: Copied! <pre>N = len(t)\ndt = t[1]-t[0]\n\n# calculate the fast fourier transform\n# y2 is the solution to the under-damped oscillator from the previous section\nF = fft(y2[:,0]) \n\n# calculate the frequencies for the components in F\nw = fftfreq(N, dt)\n</pre> N = len(t) dt = t[1]-t[0]  # calculate the fast fourier transform # y2 is the solution to the under-damped oscillator from the previous section F = fft(y2[:,0])   # calculate the frequencies for the components in F w = fftfreq(N, dt) In\u00a0[28]: Copied! <pre>fig, ax = plt.subplots(figsize=(9,3))\nax.plot(w, abs(F));\n</pre> fig, ax = plt.subplots(figsize=(9,3)) ax.plot(w, abs(F)); <p>Dado que la se\u00f1al es real, el espectro es sim\u00e9trico. Por lo tanto, solo necesitamos trazar la parte que corresponde a las frecuencias positivas. Para extraer esa parte de <code>w</code> y<code> F</code> podemos usar algunos de los trucos de indexaci\u00f3n para matrices NumPy que vimos en la lecci\u00f3n 2:</p> In\u00a0[29]: Copied! <pre>indices =  np.where(w &gt; 0) # select only indices for elements that corresponds to positive frequencies\nw_pos = w[indices]\nF_pos = F[indices]\n</pre> indices =  np.where(w &gt; 0) # select only indices for elements that corresponds to positive frequencies w_pos = w[indices] F_pos = F[indices] In\u00a0[30]: Copied! <pre>fig, ax = plt.subplots(figsize=(9,3))\nax.plot(w_pos, abs(F_pos))\nax.set_xlim(0, 5);\n</pre> fig, ax = plt.subplots(figsize=(9,3)) ax.plot(w_pos, abs(F_pos)) ax.set_xlim(0, 5); <p>Como era de esperar, ahora vemos un pico en el espectro que se centra alrededor de 1, que es la frecuencia que usamos en el ejemplo del oscilador amortiguado.</p> <p>Las matrices dispersas suelen ser \u00fatiles en simulaciones num\u00e9ricas que tratan con sistemas grandes, si el problema se puede describir en forma de matriz donde las matrices o vectores contienen en su mayor\u00eda ceros. Scipy tiene un buen soporte para matrices dispersas, con operaciones b\u00e1sicas de \u00e1lgebra lineal (como resoluci\u00f3n de ecuaciones, c\u00e1lculos de valores propios, etc.).</p> <p>Hay muchas estrategias posibles para almacenar matrices dispersas de manera eficiente. Algunos de los m\u00e1s comunes son el llamado formulario de coordenadas (COO), formulario de lista de lista (LIL) y CSC de columna comprimida y dispersa (y fila, CSR). Cada formato tiene algunas ventajas y desventajas. La mayor\u00eda de los algoritmos computacionales (resoluci\u00f3n de ecuaciones, multiplicaci\u00f3n de matriz-matriz, etc.) se pueden implementar de manera eficiente usando formatos CSR o CSC, pero no son tan intuitivos ni tan f\u00e1ciles de inicializar. Muy a menudo, una matriz dispersa se crea inicialmente en formato COO o LIL (donde podemos agregar elementos de manera eficiente a los datos de la matriz dispersa), y luego se convierte a CSC o CSR antes de usarse en c\u00e1lculos reales.</p> <p>Para obtener m\u00e1s informaci\u00f3n sobre estos formatos dispersos, consulte p. Ej. http://en.wikipedia.org/wiki/Sparse_matrix</p> <p>Cuando creamos una matriz dispersa, tenemos que elegir en qu\u00e9 formato se debe almacenar. Por ejemplo,</p> In\u00a0[31]: Copied! <pre>from scipy.sparse import *\n</pre> from scipy.sparse import * In\u00a0[32]: Copied! <pre># dense matrix\nM = np.array([[1,0,0,0], [0,3,0,0], [0,1,1,0], [1,0,0,1]]); M\n</pre> # dense matrix M = np.array([[1,0,0,0], [0,3,0,0], [0,1,1,0], [1,0,0,1]]); M Out[32]: <pre>array([[1, 0, 0, 0],\n       [0, 3, 0, 0],\n       [0, 1, 1, 0],\n       [1, 0, 0, 1]])</pre> In\u00a0[33]: Copied! <pre># convert from dense to sparse\nA = csr_matrix(M); A\n</pre> # convert from dense to sparse A = csr_matrix(M); A Out[33]: <pre>&lt;4x4 sparse matrix of type '&lt;class 'numpy.int64'&gt;'\n\twith 6 stored elements in Compressed Sparse Row format&gt;</pre> In\u00a0[34]: Copied! <pre># convert from sparse to dense\nA.todense()\n</pre> # convert from sparse to dense A.todense() Out[34]: <pre>matrix([[1, 0, 0, 0],\n        [0, 3, 0, 0],\n        [0, 1, 1, 0],\n        [1, 0, 0, 1]])</pre> <p>Una forma m\u00e1s eficiente de crear matrices dispersas: cree una matriz vac\u00eda y complete con el uso de indexaci\u00f3n matricial (evita crear una matriz densa potencialmente grande)</p> In\u00a0[35]: Copied! <pre>A = lil_matrix((4,4)) # empty 4x4 sparse matrix\nA[0,0] = 1\nA[1,1] = 3\nA[2,2] = A[2,1] = 1\nA[3,3] = A[3,0] = 1\nA\n</pre> A = lil_matrix((4,4)) # empty 4x4 sparse matrix A[0,0] = 1 A[1,1] = 3 A[2,2] = A[2,1] = 1 A[3,3] = A[3,0] = 1 A Out[35]: <pre>&lt;4x4 sparse matrix of type '&lt;class 'numpy.float64'&gt;'\n\twith 6 stored elements in List of Lists format&gt;</pre> In\u00a0[36]: Copied! <pre>A.todense()\n</pre> A.todense() Out[36]: <pre>matrix([[1., 0., 0., 0.],\n        [0., 3., 0., 0.],\n        [0., 1., 1., 0.],\n        [1., 0., 0., 1.]])</pre> <p>Conversi\u00f3n entre diferentes formatos de matriz dispersa:</p> In\u00a0[37]: Copied! <pre>A\n</pre> A Out[37]: <pre>&lt;4x4 sparse matrix of type '&lt;class 'numpy.float64'&gt;'\n\twith 6 stored elements in List of Lists format&gt;</pre> In\u00a0[38]: Copied! <pre>A = csr_matrix(A); A\n</pre> A = csr_matrix(A); A Out[38]: <pre>&lt;4x4 sparse matrix of type '&lt;class 'numpy.float64'&gt;'\n\twith 6 stored elements in Compressed Sparse Row format&gt;</pre> In\u00a0[39]: Copied! <pre>A = csc_matrix(A); A\n</pre> A = csc_matrix(A); A Out[39]: <pre>&lt;4x4 sparse matrix of type '&lt;class 'numpy.float64'&gt;'\n\twith 6 stored elements in Compressed Sparse Column format&gt;</pre> <p>Podemos calcular con matrices dispersas como con matrices densas:</p> In\u00a0[40]: Copied! <pre>A.todense()\n</pre> A.todense() Out[40]: <pre>matrix([[1., 0., 0., 0.],\n        [0., 3., 0., 0.],\n        [0., 1., 1., 0.],\n        [1., 0., 0., 1.]])</pre> In\u00a0[41]: Copied! <pre>(A * A).todense()\n</pre> (A * A).todense() Out[41]: <pre>matrix([[1., 0., 0., 0.],\n        [0., 9., 0., 0.],\n        [0., 4., 1., 0.],\n        [2., 0., 0., 1.]])</pre> In\u00a0[42]: Copied! <pre>A.todense()\n</pre> A.todense() Out[42]: <pre>matrix([[1., 0., 0., 0.],\n        [0., 3., 0., 0.],\n        [0., 1., 1., 0.],\n        [1., 0., 0., 1.]])</pre> In\u00a0[43]: Copied! <pre>A.dot(A).todense()\n</pre> A.dot(A).todense() Out[43]: <pre>matrix([[1., 0., 0., 0.],\n        [0., 9., 0., 0.],\n        [0., 4., 1., 0.],\n        [2., 0., 0., 1.]])</pre> In\u00a0[44]: Copied! <pre>v = np.array([1,2,3,4])[:,newaxis]; v\n</pre> v = np.array([1,2,3,4])[:,newaxis]; v Out[44]: <pre>array([[1],\n       [2],\n       [3],\n       [4]])</pre> In\u00a0[45]: Copied! <pre># sparse matrix - dense vector multiplication\nA * v\n</pre> # sparse matrix - dense vector multiplication A * v Out[45]: <pre>array([[1.],\n       [6.],\n       [5.],\n       [5.]])</pre> In\u00a0[46]: Copied! <pre># same result with dense matrix - dense vector multiplcation\nA.todense() * v\n</pre> # same result with dense matrix - dense vector multiplcation A.todense() * v Out[46]: <pre>matrix([[1.],\n        [6.],\n        [5.],\n        [5.]])</pre> <p>La optimizaci\u00f3n (encontrar m\u00ednimos o m\u00e1ximos de una funci\u00f3n) es un campo amplio en matem\u00e1ticas, y la optimizaci\u00f3n de funciones complicadas o en muchas variables puede estar bastante involucrada. Aqu\u00ed solo veremos algunos casos muy simples. Para obtener una introducci\u00f3n m\u00e1s detallada a la optimizaci\u00f3n con SciPy, consulte: http://scipy-lectures.github.com/advanced/mathematical_optimization/index.html</p> <p>Para usar el m\u00f3dulo de optimizaci\u00f3n en scipy, primero incluya el m\u00f3dulo <code>optimize</code>:</p> In\u00a0[47]: Copied! <pre>from scipy import optimize\n</pre> from scipy import optimize In\u00a0[48]: Copied! <pre>def f(x):\n    return 4*x**3 + (x-2)**2 + x**4\n</pre> def f(x):     return 4*x**3 + (x-2)**2 + x**4 In\u00a0[49]: Copied! <pre>fig, ax  = plt.subplots()\nx =  np.linspace(-5, 3, 100)\nax.plot(x, f(x));\n</pre> fig, ax  = plt.subplots() x =  np.linspace(-5, 3, 100) ax.plot(x, f(x)); <p>Podemos usar la funci\u00f3n <code>fmin_bfgs</code> para encontrar los m\u00ednimos de una funci\u00f3n:</p> In\u00a0[50]: Copied! <pre>x_min = optimize.fmin_bfgs(f, -2)\nx_min\n</pre> x_min = optimize.fmin_bfgs(f, -2) x_min  <pre>Optimization terminated successfully.\n         Current function value: -3.506641\n         Iterations: 5\n         Function evaluations: 16\n         Gradient evaluations: 8\n</pre> Out[50]: <pre>array([-2.67298155])</pre> In\u00a0[51]: Copied! <pre>optimize.fmin_bfgs(f, 0.5)\n</pre> optimize.fmin_bfgs(f, 0.5)  <pre>Optimization terminated successfully.\n         Current function value: 2.804988\n         Iterations: 3\n         Function evaluations: 10\n         Gradient evaluations: 5\n</pre> Out[51]: <pre>array([0.46961745])</pre> <p>Tambi\u00e9n podemos usar las funciones <code>brent</code> o<code> fminbound</code>. Tienen una sintaxis un poco diferente y usan diferentes algoritmos.</p> In\u00a0[52]: Copied! <pre>optimize.brent(f)\n</pre> optimize.brent(f) Out[52]: <pre>0.46961743402759754</pre> In\u00a0[53]: Copied! <pre>optimize.fminbound(f, -4, 2)\n</pre> optimize.fminbound(f, -4, 2) Out[53]: <pre>-2.6729822917513886</pre> In\u00a0[54]: Copied! <pre>omega_c = 3.0\ndef f(omega):\n    # a transcendental equation: resonance frequencies of a low-Q SQUID terminated microwave resonator\n    return np.tan(2*pi*omega) - omega_c/omega\n</pre> omega_c = 3.0 def f(omega):     # a transcendental equation: resonance frequencies of a low-Q SQUID terminated microwave resonator     return np.tan(2*pi*omega) - omega_c/omega In\u00a0[55]: Copied! <pre>fig, ax  = plt.subplots(figsize=(10,4))\nx =  np.linspace(0, 3, 1000)\ny = f(x)\nmask =  np.where(abs(y) &gt; 50)\nx[mask] = y[mask] = NaN # get rid of vertical line when the function flip sign\nax.plot(x, y)\nax.plot([0, 3], [0, 0], 'k')\nax.set_ylim(-5,5);\n</pre> fig, ax  = plt.subplots(figsize=(10,4)) x =  np.linspace(0, 3, 1000) y = f(x) mask =  np.where(abs(y) &gt; 50) x[mask] = y[mask] = NaN # get rid of vertical line when the function flip sign ax.plot(x, y) ax.plot([0, 3], [0, 0], 'k') ax.set_ylim(-5,5); <pre>&lt;ipython-input-54-64c57d5fd427&gt;:4: RuntimeWarning: divide by zero encountered in true_divide\n  return np.tan(2*pi*omega) - omega_c/omega\n</pre> In\u00a0[56]: Copied! <pre>optimize.fsolve(f, 0.1)\n</pre> optimize.fsolve(f, 0.1) Out[56]: <pre>array([0.23743014])</pre> In\u00a0[57]: Copied! <pre>optimize.fsolve(f, 0.6)\n</pre> optimize.fsolve(f, 0.6) Out[57]: <pre>array([0.71286972])</pre> In\u00a0[58]: Copied! <pre>optimize.fsolve(f, 1.1)\n</pre> optimize.fsolve(f, 1.1) Out[58]: <pre>array([1.18990285])</pre> <p>La interpolaci\u00f3n es simple y conveniente en scipy: la funci\u00f3n <code>interp1d</code>, cuando se dan matrices que describen datos $X$ e $Y$, devuelve un objeto que se comporta como una funci\u00f3n que se puede llamar para un valor arbitrario de $x$ (en el rango cubierto por $X$), y devuelve el valor de $y$ interpolado correspondiente:</p> In\u00a0[59]: Copied! <pre>from scipy.interpolate import *\n</pre> from scipy.interpolate import * In\u00a0[60]: Copied! <pre>def f(x):\n    return np.sin(x)\n</pre> def f(x):     return np.sin(x) In\u00a0[61]: Copied! <pre>n = np.arange(0, 10)  \nx = np.linspace(0, 9, 100)\n\ny_meas = f(n) + 0.1 * np.random.randn(len(n)) # simulate measurement with noise\ny_real = f(x)\n\nlinear_interpolation = interp1d(n, y_meas)\ny_interp1 = linear_interpolation(x)\n\ncubic_interpolation = interp1d(n, y_meas, kind='cubic')\ny_interp2 = cubic_interpolation(x)\n</pre> n = np.arange(0, 10)   x = np.linspace(0, 9, 100)  y_meas = f(n) + 0.1 * np.random.randn(len(n)) # simulate measurement with noise y_real = f(x)  linear_interpolation = interp1d(n, y_meas) y_interp1 = linear_interpolation(x)  cubic_interpolation = interp1d(n, y_meas, kind='cubic') y_interp2 = cubic_interpolation(x) In\u00a0[62]: Copied! <pre>fig, ax = plt.subplots(figsize=(10,4))\nax.plot(n, y_meas, 'bs', label='noisy data')\nax.plot(x, y_real, 'k', lw=2, label='true function')\nax.plot(x, y_interp1, 'r', label='linear interp')\nax.plot(x, y_interp2, 'g', label='cubic interp')\nax.legend(loc=3);\n</pre> fig, ax = plt.subplots(figsize=(10,4)) ax.plot(n, y_meas, 'bs', label='noisy data') ax.plot(x, y_real, 'k', lw=2, label='true function') ax.plot(x, y_interp1, 'r', label='linear interp') ax.plot(x, y_interp2, 'g', label='cubic interp') ax.legend(loc=3); <p>El m\u00f3dulo <code>scipy.stats</code> contiene una gran cantidad de distribuciones estad\u00edsticas, funciones estad\u00edsticas y pruebas. Para obtener una documentaci\u00f3n completa de sus funciones, consulte http://docs.scipy.org/doc/scipy/reference/stats.html.</p> <p>Tambi\u00e9n hay un paquete de Python muy poderoso para modelado estad\u00edstico llamado statsmodels. Consulte http://statsmodels.sourceforge.net para obtener m\u00e1s detalles.</p> In\u00a0[63]: Copied! <pre>from scipy import stats\n</pre> from scipy import stats In\u00a0[64]: Copied! <pre># create a (discreet) random variable with poissionian distribution\n\nX = stats.poisson(3.5) # photon distribution for a coherent state with n=3.5 photons\n</pre> # create a (discreet) random variable with poissionian distribution  X = stats.poisson(3.5) # photon distribution for a coherent state with n=3.5 photons In\u00a0[65]: Copied! <pre>n = np.arange(0,15)\n\nfig, axes = plt.subplots(3,1, sharex=True)\n\n# plot the probability mass function (PMF)\naxes[0].step(n, X.pmf(n))\n\n# plot the commulative distribution function (CDF)\naxes[1].step(n, X.cdf(n))\n\n# plot histogram of 1000 random realizations of the stochastic variable X\naxes[2].hist(X.rvs(size=1000));\n</pre> n = np.arange(0,15)  fig, axes = plt.subplots(3,1, sharex=True)  # plot the probability mass function (PMF) axes[0].step(n, X.pmf(n))  # plot the commulative distribution function (CDF) axes[1].step(n, X.cdf(n))  # plot histogram of 1000 random realizations of the stochastic variable X axes[2].hist(X.rvs(size=1000)); In\u00a0[66]: Copied! <pre># create a (continous) random variable with normal distribution\nY = stats.norm()\n</pre> # create a (continous) random variable with normal distribution Y = stats.norm() In\u00a0[67]: Copied! <pre>x = np.linspace(-5,5,100)\n\nfig, axes = plt.subplots(3,1, sharex=True)\n\n# plot the probability distribution function (PDF)\naxes[0].plot(x, Y.pdf(x))\n\n# plot the commulative distributin function (CDF)\naxes[1].plot(x, Y.cdf(x));\n\n# plot histogram of 1000 random realizations of the stochastic variable Y\naxes[2].hist(Y.rvs(size=1000), bins=50);\n</pre> x = np.linspace(-5,5,100)  fig, axes = plt.subplots(3,1, sharex=True)  # plot the probability distribution function (PDF) axes[0].plot(x, Y.pdf(x))  # plot the commulative distributin function (CDF) axes[1].plot(x, Y.cdf(x));  # plot histogram of 1000 random realizations of the stochastic variable Y axes[2].hist(Y.rvs(size=1000), bins=50); <p>Estad\u00edsticas</p> In\u00a0[68]: Copied! <pre>X.mean(), X.std(), X.var() # poission distribution\n</pre> X.mean(), X.std(), X.var() # poission distribution Out[68]: <pre>(3.5, 1.8708286933869707, 3.5)</pre> In\u00a0[69]: Copied! <pre>Y.mean(), Y.std(), Y.var() # normal distribution\n</pre> Y.mean(), Y.std(), Y.var() # normal distribution Out[69]: <pre>(0.0, 1.0, 1.0)</pre> <p>Pruebe si dos conjuntos de datos aleatorios (independientes) provienen de la misma distribuci\u00f3n:</p> In\u00a0[70]: Copied! <pre>t_statistic, p_value = stats.ttest_ind(X.rvs(size=1000), X.rvs(size=1000))\n\nprint (f\"t-statistic = {t_statistic}\")\nprint(f\"p-value = {p_value}\")\n</pre> t_statistic, p_value = stats.ttest_ind(X.rvs(size=1000), X.rvs(size=1000))  print (f\"t-statistic = {t_statistic}\") print(f\"p-value = {p_value}\") <pre>t-statistic = -0.3175173118125565\np-value = 0.7508842832858349\n</pre> <p>Dado que el valor $p$ es muy grande, no podemos rechazar la hip\u00f3tesis de que los dos conjuntos de datos aleatorios tienen medias * diferentes *.</p> <p>Para probar si la media de una sola muestra de datos tiene una media de 0,1 (la media verdadera es 0,0):</p> In\u00a0[71]: Copied! <pre>stats.ttest_1samp(Y.rvs(size=1000), 0.1)\n</pre> stats.ttest_1samp(Y.rvs(size=1000), 0.1) Out[71]: <pre>Ttest_1sampResult(statistic=-3.3260245451111463, pvalue=0.0009130194599003766)</pre> <p>Un valor $p$ bajo significa que podemos rechazar la hip\u00f3tesis de que la media de $Y$ es 0,1.</p> In\u00a0[72]: Copied! <pre>Y.mean()\n</pre> Y.mean() Out[72]: <pre>0.0</pre> In\u00a0[73]: Copied! <pre>stats.ttest_1samp(Y.rvs(size=1000), Y.mean())\n</pre> stats.ttest_1samp(Y.rvs(size=1000), Y.mean()) Out[73]: <pre>Ttest_1sampResult(statistic=0.7254565446907949, pvalue=0.468341895612603)</pre> <ul> <li>A tutorial on how to get started using SciPy</li> <li>The SciPy source code</li> </ul>"},{"location":"numpy/scipy/#scipy","title":"SciPy\u00b6","text":""},{"location":"numpy/scipy/#introduccion","title":"Introducci\u00f3n\u00b6","text":""},{"location":"numpy/scipy/#special-functions","title":"Special functions\u00b6","text":""},{"location":"numpy/scipy/#integration","title":"Integration\u00b6","text":""},{"location":"numpy/scipy/#numerical-integration-quadrature","title":"Numerical integration: quadrature\u00b6","text":""},{"location":"numpy/scipy/#ordinary-differential-equations-odes","title":"Ordinary differential equations (ODEs)\u00b6","text":"<p>SciPy proporciona dos formas diferentes de resolver EDO: una API basada en la funci\u00f3n <code>odeint</code> y una API orientada a objetos basada en la clase <code>ode</code>. Por lo general, <code>odeint</code> es m\u00e1s f\u00e1cil de empezar, pero la clase <code>ode</code> ofrece un nivel de control m\u00e1s fino.</p> <p>Aqu\u00ed usaremos las funciones <code>odeint</code>. Para obtener m\u00e1s informaci\u00f3n sobre la clase <code>ode</code>, pruebe con <code>help (ode)</code>. Hace pr\u00e1cticamente lo mismo que <code>odeint</code>, pero de una manera orientada a objetos.</p> <p>Para usar <code>odeint</code>, primero imp\u00f3rtelo desde el m\u00f3dulo <code>scipy.integrate</code></p>"},{"location":"numpy/scipy/#ejemplo-pendulo-doble","title":"Ejemplo: p\u00e9ndulo doble\u00b6","text":"<p>Consideremos un ejemplo f\u00edsico: el p\u00e9ndulo compuesto doble, descrito con cierto detalle aqu\u00ed: http://en.wikipedia.org/wiki/Double_pendulum</p>"},{"location":"numpy/scipy/#ejemplo-oscilador-armonico-amortiguado","title":"Ejemplo: oscilador arm\u00f3nico amortiguado\u00b6","text":"<p>Los problemas de ODE son importantes en f\u00edsica computacional, por lo que veremos un ejemplo m\u00e1s: la oscilaci\u00f3n arm\u00f3nica amortiguada. Este problema est\u00e1 bien descrito en la p\u00e1gina wiki: http://en.wikipedia.org/wiki/Damping</p> <p>La ecuaci\u00f3n de movimiento del oscilador amortiguado es:</p> <p>$\\displaystyle \\frac{\\mathrm{d}^2x}{\\mathrm{d}t^2} + 2\\zeta\\omega_0\\frac{\\mathrm{d}x}{\\mathrm{d}t} + \\omega^2_0 x = 0$</p> <p>donde $ x $ es la posici\u00f3n del oscilador, $ \\ omega_0 $ es la frecuencia y $ \\ zeta $ es la relaci\u00f3n de amortiguaci\u00f3n. Para escribir esta EDO de segundo orden en forma est\u00e1ndar, introducimos $ p = \\ frac {\\ mathrm {d} x} {\\ mathrm {d} t} $:</p> <p>$\\displaystyle \\frac{\\mathrm{d}p}{\\mathrm{d}t} = - 2\\zeta\\omega_0 p - \\omega^2_0 x$</p> <p>$\\displaystyle \\frac{\\mathrm{d}x}{\\mathrm{d}t} = p$</p> <p>En la implementaci\u00f3n de este ejemplo, agregaremos argumentos adicionales a la funci\u00f3n RHS para la ODE, en lugar de usar variables globales como hicimos en el ejemplo anterior. Como consecuencia de los argumentos adicionales al RHS, necesitamos pasar un argumento de palabra clave <code>args</code> a la funci\u00f3n <code>odeint</code>:</p>"},{"location":"numpy/scipy/#fourier-transform","title":"Fourier transform\u00b6","text":"<p>Las transformadas de Fourier son una de las herramientas universales de la f\u00edsica computacional, que aparecen una y otra vez en diferentes contextos. SciPy proporciona funciones para acceder a la biblioteca cl\u00e1sica [FFTPACK] (http://www.netlib.org/fftpack/) de NetLib, que es una biblioteca FFT eficiente y bien probada escrita en FORTRAN. La API SciPy tiene algunas funciones de conveniencia adicionales, pero en general, la API est\u00e1 estrechamente relacionada con la biblioteca FORTRAN original.</p> <p>Para usar el m\u00f3dulo <code>fftpack</code> en un programa Python, incl\u00fayalo usando:</p>"},{"location":"numpy/scipy/#sparse-matrices","title":"Sparse matrices\u00b6","text":""},{"location":"numpy/scipy/#optimization","title":"Optimization\u00b6","text":""},{"location":"numpy/scipy/#encontrar-un-minimo","title":"Encontrar un m\u00ednimo\u00b6","text":"<p>Primero veamos c\u00f3mo encontrar los m\u00ednimos de una funci\u00f3n simple de una sola variable:</p>"},{"location":"numpy/scipy/#encontrar-una-solucion-a-una-funcion","title":"Encontrar una soluci\u00f3n a una funci\u00f3n\u00b6","text":"<p>Para encontrar la ra\u00edz de una funci\u00f3n de la forma $ f (x) = 0 $ podemos usar la funci\u00f3n <code>fsolve</code>. Requiere una suposici\u00f3n inicial:</p>"},{"location":"numpy/scipy/#interpolation","title":"Interpolation\u00b6","text":""},{"location":"numpy/scipy/#statistics","title":"Statistics\u00b6","text":""},{"location":"numpy/scipy/#statistical-tests","title":"Statistical tests\u00b6","text":""},{"location":"numpy/scipy/#referencias","title":"Referencias\u00b6","text":""},{"location":"numpy/sympy/","title":"Sympy","text":"<p>Hay dos sistemas de \u00e1lgebra computarizada (CAS) notables para Python:</p> <ul> <li>SymPy: un m\u00f3dulo de Python que se puede utilizar en cualquier programa de Python, o en una sesi\u00f3n de IPython, que proporciona potentes funciones de CAS.</li> <li>Sage - Sage es un entorno CAS muy potente y con todas las funciones que tiene como objetivo proporcionar un sistema de c\u00f3digo abierto que compita con Mathematica y Maple. Sage no es un m\u00f3dulo Python normal, sino un entorno CAS que utiliza Python como lenguaje de programaci\u00f3n.</li> </ul> <p><code>Sage</code> es en algunos aspectos m\u00e1s poderoso que <code>SymPy</code>, pero ambos ofrecen una funcionalidad CAS muy completa. La ventaja de SymPy es que es un m\u00f3dulo Python normal y se integra bien con el port\u00e1til IPython.</p> <p>Para comenzar a usar SymPy en un programa o cuaderno de Python, importe el m\u00f3dulo <code>sympy</code>:</p> In\u00a0[1]: Copied! <pre>from sympy import *\n</pre> from sympy import * <p>Para obtener una salida con formato $\\LaTeX $ atractiva, ejecute:</p> In\u00a0[2]: Copied! <pre>init_printing()\n\n# or with older versions of sympy/ipython, load the IPython extension\n#%load_ext sympy.interactive.ipythonprinting\n# or\n#%load_ext sympyprinting\n</pre> init_printing()  # or with older versions of sympy/ipython, load the IPython extension #%load_ext sympy.interactive.ipythonprinting # or #%load_ext sympyprinting <p>En <code>SymPy</code> necesitamos crear s\u00edmbolos para las variables con las que queremos trabajar. Podemos crear un nuevo s\u00edmbolo usando la clase <code>Symbol</code>:</p> In\u00a0[3]: Copied! <pre>x = Symbol('x')\n</pre> x = Symbol('x') In\u00a0[4]: Copied! <pre>(pi + x)**2\n</pre> (pi + x)**2 Out[4]:  $\\displaystyle \\left(x + \\pi\\right)^{2}$  In\u00a0[5]: Copied! <pre># alternative way of defining symbols\na, b, c = symbols(\"a, b, c\")\n</pre> # alternative way of defining symbols a, b, c = symbols(\"a, b, c\") In\u00a0[6]: Copied! <pre>type(a)\n</pre> type(a) Out[6]: <pre>sympy.core.symbol.Symbol</pre> <p>Podemos agregar suposiciones a los s\u00edmbolos cuando los creamos:</p> In\u00a0[7]: Copied! <pre>x = Symbol('x', real=True)\n</pre> x = Symbol('x', real=True) In\u00a0[8]: Copied! <pre>x.is_imaginary\n</pre> x.is_imaginary Out[8]: <pre>False</pre> In\u00a0[9]: Copied! <pre>x = Symbol('x', positive=True)\n</pre> x = Symbol('x', positive=True) In\u00a0[10]: Copied! <pre>x &gt; 0\n</pre> x &gt; 0 Out[10]:  $\\displaystyle \\text{True}$  In\u00a0[11]: Copied! <pre>1+1*I\n</pre> 1+1*I Out[11]:  $\\displaystyle 1 + i$  In\u00a0[12]: Copied! <pre>I**2\n</pre> I**2 Out[12]:  $\\displaystyle -1$  In\u00a0[13]: Copied! <pre>(x * I + 1)**2\n</pre> (x * I + 1)**2 Out[13]:  $\\displaystyle \\left(i x + 1\\right)^{2}$  In\u00a0[14]: Copied! <pre>r1 = Rational(4,5)\nr2 = Rational(5,4)\n</pre> r1 = Rational(4,5) r2 = Rational(5,4) In\u00a0[15]: Copied! <pre>r1\n</pre> r1 Out[15]:  $\\displaystyle \\frac{4}{5}$  In\u00a0[16]: Copied! <pre>r1+r2\n</pre> r1+r2 Out[16]:  $\\displaystyle \\frac{41}{20}$  In\u00a0[17]: Copied! <pre>r1/r2\n</pre> r1/r2 Out[17]:  $\\displaystyle \\frac{16}{25}$  In\u00a0[18]: Copied! <pre>pi.evalf(n=50)\n</pre> pi.evalf(n=50) Out[18]:  $\\displaystyle 3.1415926535897932384626433832795028841971693993751$  In\u00a0[19]: Copied! <pre>y = (x + pi)**2\n</pre> y = (x + pi)**2 In\u00a0[20]: Copied! <pre>N(y, 5) # same as evalf\n</pre> N(y, 5) # same as evalf Out[20]:  $\\displaystyle 9.8696 \\left(0.31831 x + 1\\right)^{2}$  <p>Cuando evaluamos num\u00e9ricamente expresiones algebraicas, a menudo queremos sustituir un s\u00edmbolo por un valor num\u00e9rico. En <code>SymPy</code> lo hacemos usando la funci\u00f3n <code>subs</code>:</p> In\u00a0[21]: Copied! <pre>y.subs(x, 1.5)\n</pre> y.subs(x, 1.5) Out[21]:  $\\displaystyle \\left(1.5 + \\pi\\right)^{2}$  In\u00a0[22]: Copied! <pre>N(y.subs(x, 1.5))\n</pre> N(y.subs(x, 1.5)) Out[22]:  $\\displaystyle 21.5443823618587$  <p>Por supuesto, la funci\u00f3n <code>subs</code> tambi\u00e9n se puede utilizar para sustituir s\u00edmbolos y expresiones:</p> In\u00a0[23]: Copied! <pre>y.subs(x, a+pi)\n</pre> y.subs(x, a+pi) Out[23]:  $\\displaystyle \\left(a + 2 \\pi\\right)^{2}$  <p>Tambi\u00e9n podemos combinar la evoluci\u00f3n num\u00e9rica de expresiones con matrices <code>Numpy</code>:</p> In\u00a0[24]: Copied! <pre>import numpy\nimport matplotlib.pyplot as plt\n</pre> import numpy import matplotlib.pyplot as plt  In\u00a0[25]: Copied! <pre>x_vec = numpy.arange(0, 10, 0.1)\n</pre> x_vec = numpy.arange(0, 10, 0.1) In\u00a0[26]: Copied! <pre>y_vec = numpy.array([N(((x + pi)**2).subs(x, xx)) for xx in x_vec])\n</pre> y_vec = numpy.array([N(((x + pi)**2).subs(x, xx)) for xx in x_vec]) In\u00a0[27]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(x_vec, y_vec);\n</pre> fig, ax = plt.subplots() ax.plot(x_vec, y_vec); <p>Sin embargo, este tipo de evoluci\u00f3n num\u00e9rica puede ser muy lenta, y hay una manera mucho m\u00e1s eficiente de hacerlo: use la funci\u00f3n <code>lambdify</code> para\" compilar \"una expresi\u00f3n Sympy en una funci\u00f3n que sea mucho m\u00e1s eficiente para evaluar num\u00e9ricamente:</p> In\u00a0[28]: Copied! <pre>f = lambdify([x], (x + pi)**2, 'numpy')  # the first argument is a list of variables that\n                                         # f will be a function of: in this case only x -&gt; f(x)\n</pre> f = lambdify([x], (x + pi)**2, 'numpy')  # the first argument is a list of variables that                                          # f will be a function of: in this case only x -&gt; f(x) In\u00a0[29]: Copied! <pre>y_vec = f(x_vec)  # now we can directly pass a numpy array and f(x) is efficiently evaluated\n</pre> y_vec = f(x_vec)  # now we can directly pass a numpy array and f(x) is efficiently evaluated <p>La aceleraci\u00f3n cuando se utilizan funciones <code>lambdify</code>  en lugar de una evaluaci\u00f3n num\u00e9rica directa puede ser significativa, a menudo de varios \u00f3rdenes de magnitud. Incluso en este ejemplo simple obtenemos una velocidad significativa:</p> In\u00a0[30]: Copied! <pre>%%timeit\n\ny_vec = numpy.array([N(((x + pi)**2).subs(x, xx)) for xx in x_vec])\n</pre> %%timeit  y_vec = numpy.array([N(((x + pi)**2).subs(x, xx)) for xx in x_vec]) <pre>16.9 ms \u00b1 473 \u00b5s per loop (mean \u00b1 std. dev. of 7 runs, 100 loops each)\n</pre> In\u00a0[31]: Copied! <pre>%%timeit\n\ny_vec = f(x_vec)\n</pre> %%timeit  y_vec = f(x_vec) <pre>2.89 \u00b5s \u00b1 48.3 ns per loop (mean \u00b1 std. dev. of 7 runs, 100000 loops each)\n</pre> In\u00a0[32]: Copied! <pre>(x+1)*(x+2)*(x+3)\n</pre> (x+1)*(x+2)*(x+3) Out[32]:  $\\displaystyle \\left(x + 1\\right) \\left(x + 2\\right) \\left(x + 3\\right)$  In\u00a0[33]: Copied! <pre>expand((x+1)*(x+2)*(x+3))\n</pre> expand((x+1)*(x+2)*(x+3)) Out[33]:  $\\displaystyle x^{3} + 6 x^{2} + 11 x + 6$  <p>La funci\u00f3n <code>expand</code> toma un n\u00famero de argumentos de palabras clave que podemos decirle a las funciones qu\u00e9 tipo de expansiones queremos que se realicen. Por ejemplo, para expandir expresiones trigonom\u00e9tricas, use el argumento de palabra clave <code>trig = True</code>:</p> In\u00a0[34]: Copied! <pre>sin(a+b)\n</pre> sin(a+b) Out[34]:  $\\displaystyle \\sin{\\left(a + b \\right)}$  In\u00a0[35]: Copied! <pre>expand(sin(a+b), trig=True)\n</pre> expand(sin(a+b), trig=True) Out[35]:  $\\displaystyle \\sin{\\left(a \\right)} \\cos{\\left(b \\right)} + \\sin{\\left(b \\right)} \\cos{\\left(a \\right)}$  <p>Consulte <code>help (expand)</code> para obtener una explicaci\u00f3n detallada de los distintos tipos de expansiones que pueden realizar las funciones de \u02bbexpand`.</p> <p>Lo contrario, una expansi\u00f3n de producto es, por supuesto, factorizaci\u00f3n. El factor de una expresi\u00f3n en SymPy usa la funci\u00f3n <code>factor</code>:</p> In\u00a0[36]: Copied! <pre>factor(x**3 + 6 * x**2 + 11*x + 6)\n</pre> factor(x**3 + 6 * x**2 + 11*x + 6) Out[36]:  $\\displaystyle \\left(x + 1\\right) \\left(x + 2\\right) \\left(x + 3\\right)$  In\u00a0[37]: Copied! <pre># simplify expands a product\nsimplify((x+1)*(x+2)*(x+3))\n</pre> # simplify expands a product simplify((x+1)*(x+2)*(x+3)) Out[37]:  $\\displaystyle \\left(x + 1\\right) \\left(x + 2\\right) \\left(x + 3\\right)$  In\u00a0[38]: Copied! <pre># simplify uses trigonometric identities\nsimplify(sin(a)**2 + cos(a)**2)\n</pre> # simplify uses trigonometric identities simplify(sin(a)**2 + cos(a)**2) Out[38]:  $\\displaystyle 1$  In\u00a0[39]: Copied! <pre>simplify(cos(x)/sin(x))\n</pre> simplify(cos(x)/sin(x)) Out[39]:  $\\displaystyle \\frac{1}{\\tan{\\left(x \\right)}}$  <p>apart</p> In\u00a0[40]: Copied! <pre>f1 = 1/((a+1)*(a+2))\n</pre> f1 = 1/((a+1)*(a+2)) In\u00a0[41]: Copied! <pre>f1\n</pre> f1 Out[41]:  $\\displaystyle \\frac{1}{\\left(a + 1\\right) \\left(a + 2\\right)}$  In\u00a0[42]: Copied! <pre>apart(f1)\n</pre> apart(f1) Out[42]:  $\\displaystyle - \\frac{1}{a + 2} + \\frac{1}{a + 1}$  <p>together</p> In\u00a0[43]: Copied! <pre>f2 = 1/(a+2) + 1/(a+3)\n</pre> f2 = 1/(a+2) + 1/(a+3) In\u00a0[44]: Copied! <pre>f2\n</pre> f2 Out[44]:  $\\displaystyle \\frac{1}{a + 3} + \\frac{1}{a + 2}$  In\u00a0[45]: Copied! <pre>together(f2)\n</pre> together(f2) Out[45]:  $\\displaystyle \\frac{2 a + 5}{\\left(a + 2\\right) \\left(a + 3\\right)}$  <p>Simplificar generalmente combina fracciones pero no factoriza:</p> In\u00a0[46]: Copied! <pre>simplify(f2)\n</pre> simplify(f2) Out[46]:  $\\displaystyle \\frac{2 a + 5}{\\left(a + 2\\right) \\left(a + 3\\right)}$  In\u00a0[47]: Copied! <pre>y\n</pre> y Out[47]:  $\\displaystyle \\left(x + \\pi\\right)^{2}$  In\u00a0[48]: Copied! <pre>diff(y**2, x)\n</pre> diff(y**2, x) Out[48]:  $\\displaystyle 4 \\left(x + \\pi\\right)^{3}$  <p>Para derivados de orden superior podemos hacer:</p> In\u00a0[49]: Copied! <pre>diff(y**2, x, x)\n</pre> diff(y**2, x, x) Out[49]:  $\\displaystyle 12 \\left(x + \\pi\\right)^{2}$  In\u00a0[50]: Copied! <pre>diff(y**2, x, 2) # same as above\n</pre> diff(y**2, x, 2) # same as above Out[50]:  $\\displaystyle 12 \\left(x + \\pi\\right)^{2}$  <p>Para calcular la derivada de una expresi\u00f3n multivariante, podemos hacer:</p> In\u00a0[51]: Copied! <pre>x, y, z = symbols(\"x,y,z\")\n</pre> x, y, z = symbols(\"x,y,z\") In\u00a0[52]: Copied! <pre>f = sin(x*y) + cos(y*z)\n</pre> f = sin(x*y) + cos(y*z) <p>$\\frac{d^3f}{dxdy^2}$</p> In\u00a0[53]: Copied! <pre>diff(f, x, 1, y, 2)\n</pre> diff(f, x, 1, y, 2) Out[53]:  $\\displaystyle - x \\left(x y \\cos{\\left(x y \\right)} + 2 \\sin{\\left(x y \\right)}\\right)$  In\u00a0[54]: Copied! <pre>f\n</pre> f Out[54]:  $\\displaystyle \\sin{\\left(x y \\right)} + \\cos{\\left(y z \\right)}$  In\u00a0[55]: Copied! <pre>integrate(f, x)\n</pre> integrate(f, x) Out[55]:  $\\displaystyle x \\cos{\\left(y z \\right)} + \\begin{cases} - \\frac{\\cos{\\left(x y \\right)}}{y} &amp; \\text{for}\\: y \\neq 0 \\\\0 &amp; \\text{otherwise} \\end{cases}$  <p>Al proporcionar l\u00edmites para la variable de integraci\u00f3n, podemos evaluar integrales definidas:</p> In\u00a0[56]: Copied! <pre>integrate(f, (x, -1, 1))\n</pre> integrate(f, (x, -1, 1)) Out[56]:  $\\displaystyle 2 \\cos{\\left(y z \\right)}$  <p>y tambi\u00e9n integrales impropias:</p> In\u00a0[57]: Copied! <pre>integrate(exp(-x**2), (x, -oo, oo))\n</pre> integrate(exp(-x**2), (x, -oo, oo)) Out[57]:  $\\displaystyle \\sqrt{\\pi}$  <p>Recuerde, <code>oo</code> es la notaci\u00f3n SymPy para infinito.</p> In\u00a0[58]: Copied! <pre>n = Symbol(\"n\")\n</pre> n = Symbol(\"n\") In\u00a0[59]: Copied! <pre>Sum(1/n**2, (n, 1, 10))\n</pre> Sum(1/n**2, (n, 1, 10)) Out[59]:  $\\displaystyle \\sum_{n=1}^{10} \\frac{1}{n^{2}}$  In\u00a0[60]: Copied! <pre>Sum(1/n**2, (n,1, 10)).evalf()\n</pre> Sum(1/n**2, (n,1, 10)).evalf() Out[60]:  $\\displaystyle 1.54976773116654$  In\u00a0[61]: Copied! <pre>Sum(1/n**2, (n, 1, oo)).evalf()\n</pre> Sum(1/n**2, (n, 1, oo)).evalf() Out[61]:  $\\displaystyle 1.64493406684823$  <p>Los productos funcionan de la misma manera:</p> In\u00a0[62]: Copied! <pre>Product(n, (n, 1, 10)) # 10!\n</pre> Product(n, (n, 1, 10)) # 10! Out[62]:  $\\displaystyle \\prod_{n=1}^{10} n$  In\u00a0[63]: Copied! <pre>limit(sin(x)/x, x, 0)\n</pre> limit(sin(x)/x, x, 0) Out[63]:  $\\displaystyle 1$  <p>Podemos usar <code>limit</code> para verificar el resultado de la derivaci\u00f3n usando la funci\u00f3n <code>diff</code>:</p> In\u00a0[64]: Copied! <pre>f\n</pre> f Out[64]:  $\\displaystyle \\sin{\\left(x y \\right)} + \\cos{\\left(y z \\right)}$  In\u00a0[65]: Copied! <pre>diff(f, x)\n</pre> diff(f, x) Out[65]:  $\\displaystyle y \\cos{\\left(x y \\right)}$  <p>$\\displaystyle \\frac{\\mathrm{d}f(x,y)}{\\mathrm{d}x} = \\frac{f(x+h,y)-f(x,y)}{h}$</p> In\u00a0[66]: Copied! <pre>h = Symbol(\"h\")\n</pre> h = Symbol(\"h\") In\u00a0[67]: Copied! <pre>limit((f.subs(x, x+h) - f)/h, h, 0)\n</pre> limit((f.subs(x, x+h) - f)/h, h, 0) Out[67]:  $\\displaystyle y \\cos{\\left(x y \\right)}$  <p>Podemos cambiar la direcci\u00f3n desde la que nos acercamos al punto l\u00edmite usando el argumento <code>dir</code>:</p> In\u00a0[68]: Copied! <pre>limit(1/x, x, 0, dir=\"+\")\n</pre> limit(1/x, x, 0, dir=\"+\") Out[68]:  $\\displaystyle \\infty$  In\u00a0[69]: Copied! <pre>limit(1/x, x, 0, dir=\"-\")\n</pre> limit(1/x, x, 0, dir=\"-\") Out[69]:  $\\displaystyle -\\infty$  In\u00a0[70]: Copied! <pre>series(exp(x), x)\n</pre> series(exp(x), x) Out[70]:  $\\displaystyle 1 + x + \\frac{x^{2}}{2} + \\frac{x^{3}}{6} + \\frac{x^{4}}{24} + \\frac{x^{5}}{120} + O\\left(x^{6}\\right)$  <p>De forma predeterminada, expande la expresi\u00f3n alrededor de $x = 0$, pero podemos expandir alrededor de cualquier valor de $x$ al incluir expl\u00edcitamente un valor en la llamada a la funci\u00f3n:</p> In\u00a0[71]: Copied! <pre>series(exp(x), x, 1)\n</pre> series(exp(x), x, 1) Out[71]:  $\\displaystyle e + e \\left(x - 1\\right) + \\frac{e \\left(x - 1\\right)^{2}}{2} + \\frac{e \\left(x - 1\\right)^{3}}{6} + \\frac{e \\left(x - 1\\right)^{4}}{24} + \\frac{e \\left(x - 1\\right)^{5}}{120} + O\\left(\\left(x - 1\\right)^{6}; x\\rightarrow 1\\right)$  <p>Y podemos definir expl\u00edcitamente en qu\u00e9 orden se debe realizar la expansi\u00f3n de la serie:</p> In\u00a0[72]: Copied! <pre>series(exp(x), x, 1, 10)\n</pre> series(exp(x), x, 1, 10) Out[72]:  $\\displaystyle e + e \\left(x - 1\\right) + \\frac{e \\left(x - 1\\right)^{2}}{2} + \\frac{e \\left(x - 1\\right)^{3}}{6} + \\frac{e \\left(x - 1\\right)^{4}}{24} + \\frac{e \\left(x - 1\\right)^{5}}{120} + \\frac{e \\left(x - 1\\right)^{6}}{720} + \\frac{e \\left(x - 1\\right)^{7}}{5040} + \\frac{e \\left(x - 1\\right)^{8}}{40320} + \\frac{e \\left(x - 1\\right)^{9}}{362880} + O\\left(\\left(x - 1\\right)^{10}; x\\rightarrow 1\\right)$  <p>La expansi\u00f3n de la serie incluye el orden de la aproximaci\u00f3n, lo cual es muy \u00fatil para realizar un seguimiento del orden de validez cuando hacemos c\u00e1lculos con expansiones de la serie de diferente orden:</p> In\u00a0[73]: Copied! <pre>s1 = cos(x).series(x, 0, 5)\ns1\n</pre> s1 = cos(x).series(x, 0, 5) s1 Out[73]:  $\\displaystyle 1 - \\frac{x^{2}}{2} + \\frac{x^{4}}{24} + O\\left(x^{5}\\right)$  In\u00a0[74]: Copied! <pre>s2 = sin(x).series(x, 0, 2)\ns2\n</pre> s2 = sin(x).series(x, 0, 2) s2 Out[74]:  $\\displaystyle x + O\\left(x^{2}\\right)$  In\u00a0[75]: Copied! <pre>expand(s1 * s2)\n</pre> expand(s1 * s2) Out[75]:  $\\displaystyle x + O\\left(x^{2}\\right)$  <p>Si queremos deshacernos de la informaci\u00f3n del error, podemos usar el m\u00e9todo <code>removeO</code>:</p> In\u00a0[76]: Copied! <pre>expand(s1.removeO() * s2.removeO())\n</pre> expand(s1.removeO() * s2.removeO()) Out[76]:  $\\displaystyle \\frac{x^{5}}{24} - \\frac{x^{3}}{2} + x$  <p>Pero tenga en cuenta que esta no es la expansi\u00f3n correcta de $ \\cos(x) \\sin(x)$ a $ 5 $ \u00e9simo orden:</p> In\u00a0[77]: Copied! <pre>(cos(x)*sin(x)).series(x, 0, 6)\n</pre> (cos(x)*sin(x)).series(x, 0, 6) Out[77]:  $\\displaystyle x - \\frac{2 x^{3}}{3} + \\frac{2 x^{5}}{15} + O\\left(x^{6}\\right)$  In\u00a0[78]: Copied! <pre>m11, m12, m21, m22 = symbols(\"m11, m12, m21, m22\")\nb1, b2 = symbols(\"b1, b2\")\n</pre> m11, m12, m21, m22 = symbols(\"m11, m12, m21, m22\") b1, b2 = symbols(\"b1, b2\") In\u00a0[79]: Copied! <pre>A = Matrix([[m11, m12],[m21, m22]])\nA\n</pre> A = Matrix([[m11, m12],[m21, m22]]) A Out[79]:  $\\displaystyle \\left[\\begin{matrix}m_{11} &amp; m_{12}\\\\m_{21} &amp; m_{22}\\end{matrix}\\right]$  In\u00a0[80]: Copied! <pre>b = Matrix([[b1], [b2]])\nb\n</pre> b = Matrix([[b1], [b2]]) b Out[80]:  $\\displaystyle \\left[\\begin{matrix}b_{1}\\\\b_{2}\\end{matrix}\\right]$  <p>Con las instancias de la clase <code>Matrix</code> podemos hacer las operaciones habituales de \u00e1lgebra matricial:</p> In\u00a0[81]: Copied! <pre>A**2\n</pre> A**2 Out[81]:  $\\displaystyle \\left[\\begin{matrix}m_{11}^{2} + m_{12} m_{21} &amp; m_{11} m_{12} + m_{12} m_{22}\\\\m_{11} m_{21} + m_{21} m_{22} &amp; m_{12} m_{21} + m_{22}^{2}\\end{matrix}\\right]$  In\u00a0[82]: Copied! <pre>A * b\n</pre> A * b Out[82]:  $\\displaystyle \\left[\\begin{matrix}b_{1} m_{11} + b_{2} m_{12}\\\\b_{1} m_{21} + b_{2} m_{22}\\end{matrix}\\right]$  <p>Y calcular determinantes e inversas, y similares:</p> In\u00a0[83]: Copied! <pre>A.det()\n</pre> A.det() Out[83]:  $\\displaystyle m_{11} m_{22} - m_{12} m_{21}$  In\u00a0[84]: Copied! <pre>A.inv()\n</pre> A.inv() Out[84]:  $\\displaystyle \\left[\\begin{matrix}\\frac{m_{22}}{m_{11} m_{22} - m_{12} m_{21}} &amp; - \\frac{m_{12}}{m_{11} m_{22} - m_{12} m_{21}}\\\\- \\frac{m_{21}}{m_{11} m_{22} - m_{12} m_{21}} &amp; \\frac{m_{11}}{m_{11} m_{22} - m_{12} m_{21}}\\end{matrix}\\right]$  In\u00a0[85]: Copied! <pre>solve(x**2 - 1, x)\n</pre> solve(x**2 - 1, x) Out[85]:  $\\displaystyle \\left[ -1, \\  1\\right]$  In\u00a0[86]: Copied! <pre>solve(x**4 - x**2 - 1, x)\n</pre> solve(x**4 - x**2 - 1, x) Out[86]:  $\\displaystyle \\left[ - i \\sqrt{- \\frac{1}{2} + \\frac{\\sqrt{5}}{2}}, \\  i \\sqrt{- \\frac{1}{2} + \\frac{\\sqrt{5}}{2}}, \\  - \\sqrt{\\frac{1}{2} + \\frac{\\sqrt{5}}{2}}, \\  \\sqrt{\\frac{1}{2} + \\frac{\\sqrt{5}}{2}}\\right]$  <p>Sistema de ecuaciones:</p> In\u00a0[87]: Copied! <pre>solve([x + y - 1, x - y - 1], [x,y])\n</pre> solve([x + y - 1, x - y - 1], [x,y]) Out[87]:  $\\displaystyle \\left\\{ x : 1, \\  y : 0\\right\\}$  <p>En cuanto a otras expresiones simb\u00f3licas:</p> In\u00a0[88]: Copied! <pre>solve([x + y - a, x - y - c], [x,y])\n</pre> solve([x + y - a, x - y - c], [x,y]) Out[88]:  $\\displaystyle \\left\\{ x : \\frac{a}{2} + \\frac{c}{2}, \\  y : \\frac{a}{2} - \\frac{c}{2}\\right\\}$"},{"location":"numpy/sympy/#sympy","title":"Sympy\u00b6","text":""},{"location":"numpy/sympy/#introduccion","title":"Introducci\u00f3n\u00b6","text":""},{"location":"numpy/sympy/#variables-simbolicas","title":"Variables simb\u00f3licas\u00b6","text":""},{"location":"numpy/sympy/#numeros-complejos","title":"N\u00fameros complejos\u00b6","text":"<p>La unidad imaginaria se denota \"I\" en <code>Sympy</code>.</p>"},{"location":"numpy/sympy/#numeros-racionales","title":"Numeros racionales\u00b6","text":"<p>Hay tres tipos num\u00e9ricos diferentes en SymPy: <code>Real</code>,<code> Rational</code>, \u02bbInteger`:</p>"},{"location":"numpy/sympy/#evaluacion-numerica","title":"Evaluaci\u00f3n num\u00e9rica\u00b6","text":"<p><code>SymPy</code> usa una biblioteca para precisi\u00f3n art\u00edstica como backend num\u00e9rico, y tiene expresiones <code>SymPy</code> predefinidas para una serie de constantes matem\u00e1ticas, como: <code>pi</code>, \u02bbe<code>, \u02bboo</code> para infinito.</p> <p>Para evaluar una expresi\u00f3n num\u00e9ricamente podemos usar la funci\u00f3n <code>evalf</code> (o <code>N</code>). Toma un argumento \"n\" que especifica el n\u00famero de d\u00edgitos significativos.</p>"},{"location":"numpy/sympy/#manipulaciones-algebraicas","title":"Manipulaciones algebraicas\u00b6","text":"<p>Uno de los usos principales de un CAS es realizar manipulaciones algebraicas de expresiones. Por ejemplo, podr\u00edamos querer expandir un producto, factorizar una expresi\u00f3n o simplemente una expresi\u00f3n. Las funciones para realizar estas operaciones b\u00e1sicas en SymPy se muestran en esta secci\u00f3n.</p>"},{"location":"numpy/sympy/#expandir-y-factorizar","title":"Expandir y factorizar\u00b6","text":"<p>Los primeros pasos en una manipulaci\u00f3n algebraica</p>"},{"location":"numpy/sympy/#simplificar","title":"Simplificar\u00b6","text":"<p>El \"simplificar\" intenta simplificar una expresi\u00f3n en una expresi\u00f3n agradable, utilizando varias t\u00e9cnicas. Tambi\u00e9n existen alternativas m\u00e1s espec\u00edficas a las funciones <code>simplify</code>:<code> trigsimp</code>, <code>powsimp</code>,<code> logcombine</code>, etc.</p> <p>Los usos b\u00e1sicos de estas funciones son los siguientes:</p>"},{"location":"numpy/sympy/#separados-y-juntos","title":"Separados y juntos\u00b6","text":"<p>Para manipular expresiones simb\u00f3licas de fracciones, podemos usar las funciones <code>apart</code> y <code>together</code>:</p>"},{"location":"numpy/sympy/#calculo","title":"C\u00e1lculo\u00b6","text":"<p>Adem\u00e1s de las manipulaciones algebraicas, el otro uso principal de CAS es hacer c\u00e1lculo, como derivadas e integrales de expresiones algebraicas.</p>"},{"location":"numpy/sympy/#diferenciacion","title":"Diferenciaci\u00f3n\u00b6","text":"<p>La diferenciaci\u00f3n suele ser sencilla. Utilice la funci\u00f3n <code>diff</code>. El primer argumento es la expresi\u00f3n para tomar la derivada y el segundo argumento es el s\u00edmbolo por el cual tomar la derivada:</p>"},{"location":"numpy/sympy/#integracion","title":"Integraci\u00f3n\u00b6","text":"<p>La integraci\u00f3n se realiza de manera similar:</p>"},{"location":"numpy/sympy/#sumas-y-productos","title":"Sumas y productos\u00b6","text":"<p>Podemos evaluar sumas y productos usando las funciones: 'Suma'</p>"},{"location":"numpy/sympy/#limites","title":"L\u00edmites\u00b6","text":"<p>Los l\u00edmites se pueden evaluar utilizando la funci\u00f3n <code>limit</code>. Por ejemplo,</p>"},{"location":"numpy/sympy/#serie","title":"Serie\u00b6","text":"<p>La expansi\u00f3n de la serie tambi\u00e9n es una de las caracter\u00edsticas m\u00e1s \u00fatiles de un CAS. En SymPy podemos realizar una expansi\u00f3n en serie de una expresi\u00f3n usando la funci\u00f3n <code>series</code>:</p>"},{"location":"numpy/sympy/#algebra-lineal","title":"\u00c1lgebra lineal\u00b6","text":""},{"location":"numpy/sympy/#matrices","title":"Matrices\u00b6","text":"<p>Las matrices se definen usando la clase <code>Matrix</code>:</p>"},{"location":"numpy/sympy/#resolver-ecuaciones","title":"Resolver ecuaciones\u00b6","text":"<p>Para resolver ecuaciones y sistemas de ecuaciones podemos usar la funci\u00f3n <code>resolver</code>:</p>"},{"location":"numpy/sympy/#referencias","title":"Referencias\u00b6","text":"<ul> <li>The SymPy projects web page</li> <li>The source code of SymPy</li> <li>Online version of SymPy for testing and demonstrations</li> </ul>"},{"location":"pandas/01_pandas_intro/","title":"Introducci\u00f3n","text":"<p>Origen</p> <p>Pandas fue desarrollado por Wes McKinney en 2008 mientras trabajaba en AQR Capital Management. McKinney cre\u00f3 Pandas como una herramienta para el an\u00e1lisis y la manipulaci\u00f3n de datos para ayudar a los analistas e investigadores a trabajar con conjuntos de datos grandes y complejos de una manera m\u00e1s eficiente e intuitiva. Desde entonces, Pandas se ha convertido en una de las bibliotecas m\u00e1s utilizadas para el an\u00e1lisis de datos en Python y es mantenida por un equipo de colaboradores de c\u00f3digo abierto.</p> <p>Importar librer\u00eda</p> <p>Para importar la librer\u00eda Pandas en Python, simplemente debes usar la palabra reservada <code>import</code> seguida del nombre de la librer\u00eda:</p> <pre>import pandas\n</pre> <p>Al hacerlo, puedes utilizar todas las funciones y objetos disponibles en Pandas. Sin embargo, para ahorrar tiempo en la escritura del c\u00f3digo, es com\u00fan utilizar un alias para Pandas, que generalmente es <code>pd</code>. Para hacerlo, puedes usar la siguiente l\u00ednea de c\u00f3digo:</p> <pre>import pandas as pd\n</pre>"},{"location":"pandas/01_pandas_intro/#introduccion","title":"Introducci\u00f3n\u00b6","text":"<p>Pandas es una biblioteca que proporciona estructuras de datos r\u00e1pidas, flexibles y expresivas dise\u00f1adas para que trabajar con datos \"relacionales\" o \"etiquetados\" sea f\u00e1cil e intuitivo.</p> <p>Su objetivo es ser el bloque de construcci\u00f3n fundamental de alto nivel para hacer an\u00e1lisis de datos pr\u00e1cticos del mundo real en Python. Adem\u00e1s, tiene el objetivo m\u00e1s amplio de convertirse en la herramienta de an\u00e1lisis/manipulaci\u00f3n de datos de c\u00f3digo abierto m\u00e1s potente y flexible disponible en cualquier idioma. Ya est\u00e1 en camino hacia este objetivo.</p> <p>Las principales estructuras de datos en Pandas son <code>Series</code> y <code>DataFrames</code>.</p> <ul> <li><p>Las <code>Series</code> son  arreglos unidimensionales con \u00edndices. Se puede pensar como una generalizaci\u00f3n de los arreglos de <code>Numpy</code>.</p> </li> <li><p>Los <code>DataFrames</code> son arreglos bidimensionales y una extensi\u00f3n natural de las <code>Series</code>.</p> </li> </ul>"},{"location":"pandas/021_objetos/","title":"Objetos de Pandas","text":"In\u00a0[2]: Copied! <pre>import pandas as pd\n\ns = pd.Series([1, 2, 3, 4, 5])\ns\n</pre> import pandas as pd  s = pd.Series([1, 2, 3, 4, 5]) s Out[2]: <pre>0    1\n1    2\n2    3\n3    4\n4    5\ndtype: int64</pre> <p>En la salida, el objeto Series se imprime con los valores de la lista de datos y sus \u00edndices correspondientes (del 0 al 4). El tipo de dato del objeto Series es <code>int64</code>, que es un tipo de dato entero de 64 bits. Ahora, podemos acceder con los valores (<code>values</code>) y los atributos de \u00edndice (<code>index</code>).</p> <p>Para acceder a los valores de la serie, ocupamos el comando <code>values</code>:</p> In\u00a0[3]: Copied! <pre># valores\ns.values\n</pre> # valores s.values Out[3]: <pre>array([1, 2, 3, 4, 5], dtype=int64)</pre> <p>Para acceder a los valores del \u00edndice, ocupamos el comando <code>index</code>:</p> In\u00a0[4]: Copied! <pre># indice\ns.index\n</pre> # indice s.index Out[4]: <pre>RangeIndex(start=0, stop=5, step=1)</pre> <p>Por otro lado, puedes especificar un \u00edndice personalizado para una serie de Pandas utilizando el par\u00e1metro index al crear la serie. Por ejemplo:</p> In\u00a0[5]: Copied! <pre>data = [10, 20, 30, 40, 50]\nindex = ['a', 'b', 'c', 'd', 'e']\ns = pd.Series(data, index=index)\ns\n</pre> data = [10, 20, 30, 40, 50] index = ['a', 'b', 'c', 'd', 'e'] s = pd.Series(data, index=index) s Out[5]: <pre>a    10\nb    20\nc    30\nd    40\ne    50\ndtype: int64</pre> <p>En este caso, el \u00edndice de la serie se ha definido como una lista de cadenas de texto. Al especificar un \u00edndice personalizado, se puede utilizar ese \u00edndice para seleccionar elementos de la serie en lugar del \u00edndice num\u00e9rico predeterminado.</p> In\u00a0[6]: Copied! <pre>data = {'nombre': ['Juan', 'Ana', 'Pedro', 'Maria'],\n        'edad': [25, 31, 19, 42],\n        'ciudad': ['Madrid', 'Barcelona', 'Valencia', 'Sevilla']}\ndf = pd.DataFrame(data)\n\ndf\n</pre> data = {'nombre': ['Juan', 'Ana', 'Pedro', 'Maria'],         'edad': [25, 31, 19, 42],         'ciudad': ['Madrid', 'Barcelona', 'Valencia', 'Sevilla']} df = pd.DataFrame(data)  df Out[6]: nombre edad ciudad 0 Juan 25 Madrid 1 Ana 31 Barcelona 2 Pedro 19 Valencia 3 Maria 42 Sevilla <p>Este c\u00f3digo crea un DataFrame a partir de un diccionario que contiene tres columnas: nombre, edad y ciudad.</p> <p>Al igual que los objetos Series, los Dataframes tienen \u00edndices y valores.</p> In\u00a0[7]: Copied! <pre># valores\ndf.values\n</pre> # valores df.values Out[7]: <pre>array([['Juan', 25, 'Madrid'],\n       ['Ana', 31, 'Barcelona'],\n       ['Pedro', 19, 'Valencia'],\n       ['Maria', 42, 'Sevilla']], dtype=object)</pre> In\u00a0[8]: Copied! <pre># indice\ndf.index\n</pre> # indice df.index Out[8]: <pre>RangeIndex(start=0, stop=4, step=1)</pre> <p>Adicionalmente, los objetos Dataframe tienen el atributo <code>columns</code>, objeto que contiene las etiquetas de las columnas:</p> In\u00a0[9]: Copied! <pre># columnas\ndf.columns\n</pre> # columnas df.columns Out[9]: <pre>Index(['nombre', 'edad', 'ciudad'], dtype='object')</pre>"},{"location":"pandas/021_objetos/#objetos-de-pandas","title":"Objetos de Pandas\u00b6","text":"<p>En un nivel muy b\u00e1sico, los objetos de Pandas se pueden considerar como versiones mejoradas de matrices de <code>NumPy</code> en las que las filas y columnas se identifican con etiquetas en lugar de simples \u00edndices enteros.</p>"},{"location":"pandas/021_objetos/#tipo-de-objetos","title":"Tipo de Objetos\u00b6","text":""},{"location":"pandas/021_objetos/#pandas-series","title":"Pandas Series\u00b6","text":"<p>Un objeto de tipo Series es un array unidimensional etiquetado que puede contener cualquier tipo de dato, como enteros, n\u00fameros decimales, cadenas de texto o incluso objetos de Python. Es una estructura de datos fundamental en Pandas y es similar a un array unidimensional de NumPy, pero con \u00edndices etiquetados que permiten una manipulaci\u00f3n de datos f\u00e1cil e intuitiva.</p> <p>Un objeto de tipo Series de Pandas puede ser creado a partir de una lista, tupla, array de NumPy, o incluso de un diccionario. Por ejemplo, el siguiente c\u00f3digo crea un objeto Series a partir de una lista de n\u00fameros enteros:</p>"},{"location":"pandas/021_objetos/#pandas-dataframes","title":"Pandas Dataframes\u00b6","text":"<p>Un objeto DataFrame es una estructura de datos tabular bidimensional, similar a una hoja de c\u00e1lculo de Excel o una tabla de una base de datos relacional. Consiste en un conjunto ordenado de columnas, donde cada columna puede ser de un tipo de dato diferente (como enteros, n\u00fameros decimales o cadenas de texto), y un \u00edndice que identifica cada una de las filas.</p> <p>Los datos en un DataFrame se almacenan en una o varias estructuras de tipo Series de Pandas, una para cada columna del DataFrame. Cada serie de columnas tiene su propio nombre, y los nombres de las columnas se utilizan como etiquetas para acceder a los datos de esa columna. El \u00edndice de un DataFrame es un objeto de tipo Series que identifica cada una de las filas.</p> <p>Un objeto DataFrame de Pandas se puede crear a partir de una amplia variedad de fuentes de datos:</p> <ul> <li>listas</li> <li>diccionarios</li> <li>arrays de NumPy</li> <li>archivos CSV</li> <li>bases de datos</li> <li>muchas otras</li> </ul> <p>Aqu\u00ed hay un ejemplo de c\u00f3mo crear un DataFrame a partir de un diccionario:</p>"},{"location":"pandas/022_op_basicas/","title":"Operaciones en Pandas","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport numpy as np\n\ndata = {\n    'nombre': [f'N{x}' for x in range(1,10+1) ],\n    'valor': [1,1,2,2,2,3,3,4,4,5]\n}\ndf = pd.DataFrame(data)\ndf\n</pre> import pandas as pd import numpy as np  data = {     'nombre': [f'N{x}' for x in range(1,10+1) ],     'valor': [1,1,2,2,2,3,3,4,4,5] } df = pd.DataFrame(data) df Out[1]: nombre valor 0 N1 1 1 N2 1 2 N3 2 3 N4 2 4 N5 2 5 N6 3 6 N7 3 7 N8 4 8 N9 4 9 N10 5 In\u00a0[2]: Copied! <pre># priemras filas \ndf.head()\n</pre> # priemras filas  df.head() Out[2]: nombre valor 0 N1 1 1 N2 1 2 N3 2 3 N4 2 4 N5 2 In\u00a0[3]: Copied! <pre># ultimas filas \ndf.tail()\n</pre> # ultimas filas  df.tail() Out[3]: nombre valor 5 N6 3 6 N7 3 7 N8 4 8 N9 4 9 N10 5 In\u00a0[4]: Copied! <pre># informacion del dataframe\ndf.info()\n</pre> # informacion del dataframe df.info() <pre>&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 10 entries, 0 to 9\nData columns (total 2 columns):\n #   Column  Non-Null Count  Dtype \n---  ------  --------------  ----- \n 0   nombre  10 non-null     object\n 1   valor   10 non-null     int64 \ndtypes: int64(1), object(1)\nmemory usage: 288.0+ bytes\n</pre> In\u00a0[5]: Copied! <pre># estadisticas basicas\ndf.describe()\n</pre> # estadisticas basicas df.describe() Out[5]: valor count 10.000000 mean 2.700000 std 1.337494 min 1.000000 25% 2.000000 50% 2.500000 75% 3.750000 max 5.000000 In\u00a0[6]: Copied! <pre># filas y columnas\ndf.shape\n</pre> # filas y columnas df.shape Out[6]: <pre>(10, 2)</pre> In\u00a0[7]: Copied! <pre># tipo de datos por columnas\ndf.dtypes\n</pre> # tipo de datos por columnas df.dtypes Out[7]: <pre>nombre    object\nvalor      int64\ndtype: object</pre> In\u00a0[8]: Copied! <pre># objetos unicos por columna especifica\ndf['valor'].unique()\n</pre> # objetos unicos por columna especifica df['valor'].unique() Out[8]: <pre>array([1, 2, 3, 4, 5], dtype=int64)</pre> In\u00a0[9]: Copied! <pre># cantidad de objetos unicos - todas las columnas\ndf.nunique()\n</pre> # cantidad de objetos unicos - todas las columnas df.nunique() Out[9]: <pre>nombre    10\nvalor      5\ndtype: int64</pre> In\u00a0[10]: Copied! <pre># cantidad de objetos unicos - columna especifica\ndf['valor'].nunique()\n</pre> # cantidad de objetos unicos - columna especifica df['valor'].nunique() Out[10]: <pre>5</pre> In\u00a0[11]: Copied! <pre># numero de ocurrencias de cada valor en una columna\ndf['valor'].value_counts()\n</pre> # numero de ocurrencias de cada valor en una columna df['valor'].value_counts() Out[11]: <pre>2    3\n1    2\n3    2\n4    2\n5    1\nName: valor, dtype: int64</pre> In\u00a0[12]: Copied! <pre># ordenar valores - por columna especifica, menor a mayor\ndf.sort_values('valor', ascending = True)\n</pre> # ordenar valores - por columna especifica, menor a mayor df.sort_values('valor', ascending = True) Out[12]: nombre valor 0 N1 1 1 N2 1 2 N3 2 3 N4 2 4 N5 2 5 N6 3 6 N7 3 7 N8 4 8 N9 4 9 N10 5 In\u00a0[13]: Copied! <pre># ordenar valores - por columna especifica, mayor a menor\ndf.sort_values('valor', ascending = False)\n</pre> # ordenar valores - por columna especifica, mayor a menor df.sort_values('valor', ascending = False) Out[13]: nombre valor 9 N10 5 7 N8 4 8 N9 4 5 N6 3 6 N7 3 2 N3 2 3 N4 2 4 N5 2 0 N1 1 1 N2 1 In\u00a0[14]: Copied! <pre># cambiar nombre de columnas\ndf.rename(columns={\n    'nombre': 'Nombre',\n    'valor':'Valor'\n})\n</pre> # cambiar nombre de columnas df.rename(columns={     'nombre': 'Nombre',     'valor':'Valor' }) Out[14]: Nombre Valor 0 N1 1 1 N2 1 2 N3 2 3 N4 2 4 N5 2 5 N6 3 6 N7 3 7 N8 4 8 N9 4 9 N10 5 In\u00a0[15]: Copied! <pre># aplicar funcion columna especifica\ndf['valor']\n</pre> # aplicar funcion columna especifica df['valor'] Out[15]: <pre>0    1\n1    1\n2    2\n3    2\n4    2\n5    3\n6    3\n7    4\n8    4\n9    5\nName: valor, dtype: int64</pre> In\u00a0[16]: Copied! <pre># funcion apply\n\ndf['valor'] = df['valor'].apply(np.sqrt)\ndf\n</pre> # funcion apply  df['valor'] = df['valor'].apply(np.sqrt) df Out[16]: nombre valor 0 N1 1.000000 1 N2 1.000000 2 N3 1.414214 3 N4 1.414214 4 N5 1.414214 5 N6 1.732051 6 N7 1.732051 7 N8 2.000000 8 N9 2.000000 9 N10 2.236068 In\u00a0[17]: Copied! <pre>s1 = pd.Series([1,2,3,4,5])\ns2 = pd.Series([1,1,2,2,2])\n\n# suma\nprint(f\"suma: \\n{s1+s2}\\n\")\n\n# resta\nprint(f\"resta: \\n{s1-s2}\\n\")\n\n# multiplicacion\nprint(f\"multiplicacion: \\n{s1*s2}\\n\")\n\n# division\nprint(f\"division: \\n{s1/s2}\")\n</pre> s1 = pd.Series([1,2,3,4,5]) s2 = pd.Series([1,1,2,2,2])  # suma print(f\"suma: \\n{s1+s2}\\n\")  # resta print(f\"resta: \\n{s1-s2}\\n\")  # multiplicacion print(f\"multiplicacion: \\n{s1*s2}\\n\")  # division print(f\"division: \\n{s1/s2}\") <pre>suma: \n0    2\n1    3\n2    5\n3    6\n4    7\ndtype: int64\n\nresta: \n0    0\n1    1\n2    1\n3    2\n4    3\ndtype: int64\n\nmultiplicacion: \n0     1\n1     2\n2     6\n3     8\n4    10\ndtype: int64\n\ndivision: \n0    1.0\n1    2.0\n2    1.5\n3    2.0\n4    2.5\ndtype: float64\n</pre> <p>Adem\u00e1s, Pandas tambi\u00e9n proporciona una serie de funciones \u00fatiles para realizar operaciones estad\u00edsticas en las series, como <code>mean()</code>, <code>std()</code>, <code>min()</code>, <code>max()</code> y otras. Estas funciones se pueden utilizar para calcular estad\u00edsticas de resumen de una serie.</p> In\u00a0[18]: Copied! <pre># operaciones estadisticas\ns1 = pd.Series([1,1,1,2,2,2,3,3,3,4,5,5,5,5])\n\nprint(f\"mean: {s1.mean()}\") # mean\nprint(f\"std:  {s1.std()}\") # std\nprint(f\"min:  {s1.min()}\") # min\nprint(f\"max:  {s1.max()}\") # max\n</pre> # operaciones estadisticas s1 = pd.Series([1,1,1,2,2,2,3,3,3,4,5,5,5,5])  print(f\"mean: {s1.mean()}\") # mean print(f\"std:  {s1.std()}\") # std print(f\"min:  {s1.min()}\") # min print(f\"max:  {s1.max()}\") # max <pre>mean: 3.0\nstd:  1.5689290811054724\nmin:  1\nmax:  5\n</pre> <p>Tambi\u00e9n, se pueden realizar una variedad de operaciones matem\u00e1ticas en un DataFrame. Al igual que con las series, las operaciones se realizan elemento por elemento. Aqu\u00ed hay algunos ejemplos de operaciones matem\u00e1ticas comunes en un DataFrame.</p> In\u00a0[19]: Copied! <pre># Crear un DataFrame\ndf = pd.DataFrame({\n    'A': [2, 1, 3], \n    'B': [1, 2, 6], \n    'C': [3, 10, 9]}\n)\ndf\n</pre> # Crear un DataFrame df = pd.DataFrame({     'A': [2, 1, 3],      'B': [1, 2, 6],      'C': [3, 10, 9]} ) df Out[19]: A B C 0 2 1 3 1 1 2 10 2 3 6 9 In\u00a0[20]: Copied! <pre># sumar la columna A de la columna B - opcion dataframe\ndf['B'].add(df['A'])\n</pre> # sumar la columna A de la columna B - opcion dataframe df['B'].add(df['A']) Out[20]: <pre>0    3\n1    3\n2    9\ndtype: int64</pre> In\u00a0[21]: Copied! <pre># sumar la columna A de la columna B - opcion series\ndf['B'] + (df['A'])\n</pre> # sumar la columna A de la columna B - opcion series df['B'] + (df['A']) Out[21]: <pre>0    3\n1    3\n2    9\ndtype: int64</pre> <p>Nota: Lo anterior se extiende para las operaciones restar, multiplicar y dividir.</p> In\u00a0[22]: Copied! <pre># Sumar las columnas\ncolumn_sum = df.sum(axis=0)\nprint(column_sum)\n</pre> # Sumar las columnas column_sum = df.sum(axis=0) print(column_sum) <pre>A     6\nB     9\nC    22\ndtype: int64\n</pre> In\u00a0[23]: Copied! <pre># Sumar las filas\nrow_sum = df.sum(axis=1)\nprint(row_sum)\n</pre> # Sumar las filas row_sum = df.sum(axis=1) print(row_sum) <pre>0     6\n1    13\n2    18\ndtype: int64\n</pre> In\u00a0[24]: Copied! <pre># resumen estadistico\ndf.describe()\n</pre> # resumen estadistico df.describe() Out[24]: A B C count 3.0 3.000000 3.000000 mean 2.0 3.000000 7.333333 std 1.0 2.645751 3.785939 min 1.0 1.000000 3.000000 25% 1.5 1.500000 6.000000 50% 2.0 2.000000 9.000000 75% 2.5 4.000000 9.500000 max 3.0 6.000000 10.000000 In\u00a0[25]: Copied! <pre># correlaciones lineales\ndf.corr()\n</pre> # correlaciones lineales df.corr() Out[25]: A B C A 1.000000 0.755929 -0.132068 B 0.755929 1.000000 0.549086 C -0.132068 0.549086 1.000000 <p>Observaci\u00f3n</p> <p><code>axis</code> es un par\u00e1metro que se utiliza en varias funciones de Pandas para especificar si una operaci\u00f3n se realiza a lo largo de las filas (<code>axis=0</code>) o a lo largo de las columnas (<code>axis=1</code>) de un DataFrame.</p> <ul> <li><p><code>axis=0</code> se refiere a las filas. Algunas operaciones que se realizan a lo largo del eje 0 son la suma (sum()), el conteo (<code>count()</code>), la media (<code>mean()</code>), entre otras.</p> </li> <li><p><code>axis=1</code> se refiere a las columnas. Algunas operaciones que se realizan a lo largo del eje 1 son la transposici\u00f3n (<code>T</code>), el acceso a una columna (<code>['columna']</code>),  entre otras.</p> </li> </ul> <p>Por ejemplo, si se desea calcular la suma de las columnas y filas de un DataFrame <code>df</code>, se puede utilizar la funci\u00f3n <code>sum()</code> de la siguiente manera:</p> In\u00a0[26]: Copied! <pre>df = pd.DataFrame({\n    'A': [1, 2, 3], \n    'B': [4, 5, 6], \n    'C': [7, 8, 9]}\n)\ndf\n</pre> df = pd.DataFrame({     'A': [1, 2, 3],      'B': [4, 5, 6],      'C': [7, 8, 9]} ) df Out[26]: A B C 0 1 4 7 1 2 5 8 2 3 6 9 In\u00a0[27]: Copied! <pre># operacion .sum por defecto\ndf.sum()\n</pre> # operacion .sum por defecto df.sum() Out[27]: <pre>A     6\nB    15\nC    24\ndtype: int64</pre> In\u00a0[28]: Copied! <pre># sumar columnas\nsuma_columnas = df.sum(axis=0)\nsuma_columnas\n</pre> # sumar columnas suma_columnas = df.sum(axis=0) suma_columnas Out[28]: <pre>A     6\nB    15\nC    24\ndtype: int64</pre> In\u00a0[29]: Copied! <pre># sumar filas\nsuma_filas = df.sum(axis=1)\nsuma_filas\n</pre> # sumar filas suma_filas = df.sum(axis=1) suma_filas Out[29]: <pre>0    12\n1    15\n2    18\ndtype: int64</pre> In\u00a0[30]: Copied! <pre># Crear un DataFrame\ndf = pd.DataFrame({\n    'A': [2, 1, 3], \n    'B': [1, 2, 6], \n    'C': [3, 10, 9]}\n)\ndf\n</pre> # Crear un DataFrame df = pd.DataFrame({     'A': [2, 1, 3],      'B': [1, 2, 6],      'C': [3, 10, 9]} ) df Out[30]: A B C 0 2 1 3 1 1 2 10 2 3 6 9 In\u00a0[31]: Copied! <pre># opcion 01 - igualando \ndf['D'] = 1\ndf\n</pre> # opcion 01 - igualando  df['D'] = 1 df Out[31]: A B C D 0 2 1 3 1 1 1 2 10 1 2 3 6 9 1 In\u00a0[32]: Copied! <pre># ocupando 'assign'\ndf.assign(D=1)\n</pre> # ocupando 'assign' df.assign(D=1) Out[32]: A B C D 0 2 1 3 1 1 1 2 10 1 2 3 6 9 1 <p>Tambi\u00e9n puede agregar operaciones entre columnas para crear otra nueva:</p> In\u00a0[33]: Copied! <pre># nueva columna a partir de otras dos\ndf['D'] = df['A']+df['B']\ndf\n</pre> # nueva columna a partir de otras dos df['D'] = df['A']+df['B'] df Out[33]: A B C D 0 2 1 3 3 1 1 2 10 3 2 3 6 9 9 <p>Si usted necesita aplicar una funci\u00f3n a una columna en espec\u00edfico y dicha funci\u00f3n tiene varios par\u00e1metros, puede utilizar la notaci\u00f3n lambda para trabajar. Veamos un ejemplo:</p> In\u00a0[34]: Copied! <pre># crear funcion\ndef funcion_objetivo(x,y):\n    return x+2*y\n</pre> # crear funcion def funcion_objetivo(x,y):     return x+2*y In\u00a0[35]: Copied! <pre># aplicar funcion\ndf['D'] = df['A'].apply(lambda x: funcion_objetivo(x,5))\ndf\n</pre> # aplicar funcion df['D'] = df['A'].apply(lambda x: funcion_objetivo(x,5)) df Out[35]: A B C D 0 2 1 3 12 1 1 2 10 11 2 3 6 9 13 <p>Ahora si usted necesita aplicar <code>funcion_objetivo</code> a dos columnas, realizamos la siguiente operaci\u00f3n</p> In\u00a0[36]: Copied! <pre>df['D'] = df.apply(lambda x: funcion_objetivo(x['A'], x['B']), axis=1)\ndf\n</pre> df['D'] = df.apply(lambda x: funcion_objetivo(x['A'], x['B']), axis=1) df Out[36]: A B C D 0 2 1 3 4 1 1 2 10 5 2 3 6 9 15 <p>Por otro lado, para copiar la informaci\u00f3n de un objeto de pandas, siempre debe ocupar <code>.copy()</code>, ya que en caso contrario, estar\u00e1 guardando los dos objetos en la misma asignaci\u00f3n de memoria. Veamos un ejemplo:</p> In\u00a0[37]: Copied! <pre>from IPython.display import display_html\n\n# correcto - solo se modifica nuevo_df\nnuevo_df = df.copy()\nnuevo_df['A'] = 1\n\nprint(f\"df\")\ndisplay_html(df)\nprint()\nprint(f\"nuevo_df\")\ndisplay_html(nuevo_df)\n</pre> from IPython.display import display_html  # correcto - solo se modifica nuevo_df nuevo_df = df.copy() nuevo_df['A'] = 1  print(f\"df\") display_html(df) print() print(f\"nuevo_df\") display_html(nuevo_df) <pre>df\n</pre> A B C D 0 2 1 3 4 1 1 2 10 5 2 3 6 9 15 <pre>\nnuevo_df\n</pre> A B C D 0 1 1 3 4 1 1 2 10 5 2 1 6 9 15 In\u00a0[38]: Copied! <pre># incorrecto - se modifica df y nuevo_df\nnuevo_df = df\nnuevo_df['A'] = 1\n\nprint(f\"df\")\ndisplay_html(df)\nprint()\nprint(f\"nuevo_df\")\ndisplay_html(nuevo_df)\n</pre> # incorrecto - se modifica df y nuevo_df nuevo_df = df nuevo_df['A'] = 1  print(f\"df\") display_html(df) print() print(f\"nuevo_df\") display_html(nuevo_df) <pre>df\n</pre> A B C D 0 1 1 3 4 1 1 2 10 5 2 1 6 9 15 <pre>\nnuevo_df\n</pre> A B C D 0 1 1 3 4 1 1 2 10 5 2 1 6 9 15 <p>Muchas veces, en un Dataframe se necesita realizar operaciones entre  la fila actual y la fila anterior, lo cual puede ser complejo si no se utilizan las funciones correctas. A continuaci\u00f3n se trabajan algunas de estas funciones:</p> <ol> <li><code>shift()</code>: Se utiliza para mover hacia arriba o hacia abajo los valores de una columna o serie de datos.</li> <li><code>cumsum()</code>: es una funci\u00f3n que se utiliza para calcular la suma acumulativa de valores a lo largo de un eje en un DataFrame o una Serie.</li> <li><code>pct_change()</code>: es una funci\u00f3n que se utiliza para calcular el cambio porcentual entre los elementos de una serie o columna en un DataFrame.</li> <li><code>rank()</code>: es una funci\u00f3n que se utiliza para asignar un rango a los elementos de una serie o columna en un DataFrame.</li> </ol> In\u00a0[39]: Copied! <pre>data = {'ventas': [100,200, 200, 300, 400, 500]}\ndf = pd.DataFrame(data)\ndf\n</pre> data = {'ventas': [100,200, 200, 300, 400, 500]} df = pd.DataFrame(data) df Out[39]: ventas 0 100 1 200 2 200 3 300 4 400 5 500 In\u00a0[40]: Copied! <pre># aplicar funciones\ndf['shift'] = df['ventas'].shift() # se muestra el valor de la fila anterior (la primera fila en este caso es NaN)\ndf['cumsum'] = df['ventas'].cumsum()  # suma acumulada entre la fila actual y todas las anteriores\ndf['pct_change'] = df['ventas'].pct_change() # porcentaje de cambio entre la fila actual y la anterior \ndf['rank'] = df['ventas'].rank() # ranking de los valores (donde 1 es el menor valor)\ndf\n</pre> # aplicar funciones df['shift'] = df['ventas'].shift() # se muestra el valor de la fila anterior (la primera fila en este caso es NaN) df['cumsum'] = df['ventas'].cumsum()  # suma acumulada entre la fila actual y todas las anteriores df['pct_change'] = df['ventas'].pct_change() # porcentaje de cambio entre la fila actual y la anterior  df['rank'] = df['ventas'].rank() # ranking de los valores (donde 1 es el menor valor) df Out[40]: ventas shift cumsum pct_change rank 0 100 NaN 100 NaN 1.0 1 200 100.0 300 1.000000 2.5 2 200 200.0 500 0.000000 2.5 3 300 200.0 800 0.500000 4.0 4 400 300.0 1200 0.333333 5.0 5 500 400.0 1700 0.250000 6.0 <p>Finalmente, una funci\u00f3n que merece nuestra atenci\u00f3n es <code>explode</code>. En Pandas, <code>explode()</code> es una funci\u00f3n que se utiliza para descomponer una columna que contiene listas o arrays en varias filas, una por cada elemento de la lista o array. La sintaxis b\u00e1sica de <code>explode()</code> es la siguiente:</p> <pre>df.explode(column, ignore_index=False)\n</pre> <p>donde:</p> <ul> <li><code>column</code>: es el nombre de la columna que se va a explotar.</li> <li><code>ignore_index</code>: indica si se deben reiniciar los \u00edndices despu\u00e9s de la explosi\u00f3n. El valor por defecto es False.</li> </ul> <p>Veamos un ejemplo sencillo:</p> In\u00a0[41]: Copied! <pre>import pandas as pd\n\ndata = {'id': [1, 2, 3], 'nombres': [['Juan', 'Pedro'], ['Mar\u00eda', 'Luisa'], ['Ana', 'Sof\u00eda', 'Luc\u00eda']]}\ndf = pd.DataFrame(data)\ndf\n</pre> import pandas as pd  data = {'id': [1, 2, 3], 'nombres': [['Juan', 'Pedro'], ['Mar\u00eda', 'Luisa'], ['Ana', 'Sof\u00eda', 'Luc\u00eda']]} df = pd.DataFrame(data) df Out[41]: id nombres 0 1 [Juan, Pedro] 1 2 [Mar\u00eda, Luisa] 2 3 [Ana, Sof\u00eda, Luc\u00eda] <p>Si queremos descomponer la columna \"nombres\" en varias filas, una por cada nombre, podemos utilizar la siguiente sintaxis:</p> In\u00a0[42]: Copied! <pre>df_exploded = df.explode('nombres')\ndf_exploded\n</pre> df_exploded = df.explode('nombres') df_exploded Out[42]: id nombres 0 1 Juan 0 1 Pedro 1 2 Mar\u00eda 1 2 Luisa 2 3 Ana 2 3 Sof\u00eda 2 3 Luc\u00eda <p>En este ejemplo, se ha utilizado la funci\u00f3n <code>explode()</code> para descomponer la columna \"nombres\" en varias filas, una por cada nombre. Como resultado, se ha creado un nuevo DataFrame llamado \"df_exploded\" que contiene tres filas por cada fila del DataFrame original. Cada fila contiene un solo nombre y el valor correspondiente de la columna \"id\" se ha replicado para cada fila.</p>"},{"location":"pandas/022_op_basicas/#operaciones-en-pandas","title":"Operaciones en Pandas\u00b6","text":""},{"location":"pandas/022_op_basicas/#operaciones-basicas","title":"Operaciones B\u00e1sicas\u00b6","text":"<p>Pandas es una biblioteca de Python para la manipulaci\u00f3n y an\u00e1lisis de datos. Aqu\u00ed est\u00e1n algunas de las operaciones b\u00e1sicas de Pandas que puedes realizar en un DataFrame:</p> <ul> <li><p><code>pd.read_csv()</code>: para leer archivos CSV y crear un DataFrame.</p> </li> <li><p><code>df.to_csv('filename.csv')</code>: para guardar el DataFrame en un archivo CSV.</p> </li> <li><p><code>df.head(n)</code>: para mostrar los primeros n elementos del DataFrame.</p> </li> <li><p><code>df.tail(n)</code>: para mostrar los \u00faltimos n elementos del DataFrame.</p> </li> <li><p><code>df.info()</code>: para obtener informaci\u00f3n sobre el DataFrame, como el tipo de datos, el n\u00famero de valores no nulos, etc.</p> </li> <li><p><code>df.describe()</code>: para obtener estad\u00edsticas descriptivas del DataFrame, como la media, la mediana, el valor m\u00ednimo y m\u00e1ximo, etc.</p> </li> <li><p><code>df.shape</code>: para obtener el n\u00famero de filas y columnas del DataFrame.</p> </li> <li><p><code>df.dtypes</code>: para obtener los tipos de datos de cada columna del DataFrame.</p> </li> <li><p><code>df.unique()</code>: para obtener valores \u00fanicos en una columna del DataFrame.</p> </li> <li><p><code>df.nunique()</code>: para obtener el n\u00famero de valores \u00fanicos en cada columna del DataFrame.</p> </li> <li><p><code>df.value_counts()</code>: para obtener el n\u00famero de ocurrencias de cada valor en una columna del DataFrame.</p> </li> <li><p><code>df.sort_values(column_name)</code>: para ordenar el DataFrame por valores en una columna.</p> </li> <li><p><code>df.rename(columns={'old_name': 'new_name'})</code>: para cambiar los nombres de las columnas en el DataFrame.</p> </li> <li><p><code>df.apply(func)</code>: para aplicar una funci\u00f3n a cada columna o fila del DataFrame.</p> </li> </ul> <p>Veamos un ejemplo aplicado:</p>"},{"location":"pandas/022_op_basicas/#operaciones-matematicas","title":"Operaciones Matem\u00e1ticas\u00b6","text":"<p>Al igual que numpy, las series de pandas pueden realizar operaciones matem\u00e1ticas similares (mientr\u00e1s los arreglos a operar sean del tipo num\u00e9rico).</p> <p>Podemos realizar operaciones aritm\u00e9ticas en las series, como la suma, resta, la multiplicaci\u00f3n y la divisi\u00f3n, utilizando los operadores <code>+</code>,<code>-</code>, <code>*</code> y <code>/</code>, respectivamente.</p>"},{"location":"pandas/022_op_basicas/#operaciones-avanzadas","title":"Operaciones Avanzadas\u00b6","text":"<p>Para modificar agregar una columan en una dataframe, existen dos maneras:</p>"},{"location":"pandas/023_index/","title":"Indexaci\u00f3n y Selecci\u00f3n","text":"In\u00a0[20]: Copied! <pre>import pandas as pd\n\ndata = {'manzanas': 10, 'naranjas': 5, 'pl\u00e1tanos': 7, 'peras': 3}\nfrutas = pd.Series(data)\nfrutas\n</pre> import pandas as pd  data = {'manzanas': 10, 'naranjas': 5, 'pl\u00e1tanos': 7, 'peras': 3} frutas = pd.Series(data) frutas Out[20]: <pre>manzanas    10\nnaranjas     5\npl\u00e1tanos     7\nperas        3\ndtype: int64</pre> In\u00a0[28]: Copied! <pre># acceder por indice 'manzana' - sin '.loc'\nprint(frutas['manzanas']) # 10\n</pre> # acceder por indice 'manzana' - sin '.loc' print(frutas['manzanas']) # 10 <pre>10\n</pre> In\u00a0[29]: Copied! <pre># acceder por indice 'manzana' - con '.loc'\nprint(frutas.loc['manzanas']) # 10\n</pre> # acceder por indice 'manzana' - con '.loc' print(frutas.loc['manzanas']) # 10 <pre>10\n</pre> In\u00a0[32]: Copied! <pre># acceder por la posicion 0 - sin '.loc'\nprint(frutas[0]) # 10\n</pre> # acceder por la posicion 0 - sin '.loc' print(frutas[0]) # 10 <pre>10\n</pre> In\u00a0[31]: Copied! <pre># acceder por la posicion 0 - con '.iloc'\nprint(frutas.iloc[0]) # 10\n</pre> # acceder por la posicion 0 - con '.iloc' print(frutas.iloc[0]) # 10 <pre>10\n</pre> <p>Nota: De aqu\u00ed en m\u00e1s utilizaremos <code>.loc</code> e <code>.iloc</code> para acceder a los elementos de un Dataframe, para ser expl\u00edcito en la forma de acceder a los datos.</p> In\u00a0[22]: Copied! <pre># seleccionar por indices 'manzanas' y 'naranjas'\nprint(frutas.loc[['manzanas', 'naranjas']])\n</pre> # seleccionar por indices 'manzanas' y 'naranjas' print(frutas.loc[['manzanas', 'naranjas']])  <pre>manzanas    10\nnaranjas     5\ndtype: int64\n</pre> <p>Tambi\u00e9n podemos seleccionar los elementos por su posici\u00f3n utilizando la funci\u00f3n <code>iloc()</code>:</p> In\u00a0[5]: Copied! <pre># acceder por posicion 0 y 2\nprint(frutas.iloc[[0, 2]])\n</pre> # acceder por posicion 0 y 2 print(frutas.iloc[[0, 2]]) <pre>manzanas    10\npl\u00e1tanos     7\ndtype: int64\n</pre> In\u00a0[23]: Copied! <pre># rango de indices\nprint(frutas.loc['manzanas':'pl\u00e1tanos'])\n</pre> # rango de indices print(frutas.loc['manzanas':'pl\u00e1tanos'])  <pre>manzanas    10\nnaranjas     5\npl\u00e1tanos     7\ndtype: int64\n</pre> <p>Tambi\u00e9n podemos seleccionar un rango de elementos utilizando la funci\u00f3n <code>iloc()</code> y especificando las posiciones del rango:</p> In\u00a0[7]: Copied! <pre># rango de posiciones\nprint(frutas.iloc[1:3])\n</pre> # rango de posiciones print(frutas.iloc[1:3])  <pre>naranjas    5\npl\u00e1tanos    7\ndtype: int64\n</pre> In\u00a0[8]: Copied! <pre># Crear un DataFrame de ejemplo\ndata = {\n    'nombre': ['Juan', 'Ana', 'Pedro'], \n    'edad': [28, 23, 35], \n    'ciudad': ['Madrid', 'Barcelona', 'Valencia'],\n    \n}\ndf = pd.DataFrame(data,index = ['a','b','c'])\ndf\n</pre> # Crear un DataFrame de ejemplo data = {     'nombre': ['Juan', 'Ana', 'Pedro'],      'edad': [28, 23, 35],      'ciudad': ['Madrid', 'Barcelona', 'Valencia'],      } df = pd.DataFrame(data,index = ['a','b','c']) df Out[8]: nombre edad ciudad a Juan 28 Madrid b Ana 23 Barcelona c Pedro 35 Valencia In\u00a0[9]: Copied! <pre># Selecci\u00f3n de una columna\nnombre_columna = df['nombre']\nnombre_columna\n</pre> # Selecci\u00f3n de una columna nombre_columna = df['nombre'] nombre_columna Out[9]: <pre>a     Juan\nb      Ana\nc    Pedro\nName: nombre, dtype: object</pre> In\u00a0[10]: Copied! <pre># Selecci\u00f3n de varias columnas\nvarias_columnas = df[['nombre', 'edad']]\nvarias_columnas\n</pre> # Selecci\u00f3n de varias columnas varias_columnas = df[['nombre', 'edad']] varias_columnas Out[10]: nombre edad a Juan 28 b Ana 23 c Pedro 35 In\u00a0[11]: Copied! <pre># Selecci\u00f3n de una fila por etiqueta\nfila = df.loc['a']\nfila\n</pre> # Selecci\u00f3n de una fila por etiqueta fila = df.loc['a'] fila Out[11]: <pre>nombre      Juan\nedad          28\nciudad    Madrid\nName: a, dtype: object</pre> In\u00a0[12]: Copied! <pre># Selecci\u00f3n de varias filas por etiqueta\nvarias_filas = df.loc['a':'b']\nvarias_filas\n</pre> # Selecci\u00f3n de varias filas por etiqueta varias_filas = df.loc['a':'b'] varias_filas Out[12]: nombre edad ciudad a Juan 28 Madrid b Ana 23 Barcelona In\u00a0[13]: Copied! <pre># Selecci\u00f3n de una fila por posici\u00f3n\nfila_posicion = df.iloc[0]\nfila_posicion\n</pre> # Selecci\u00f3n de una fila por posici\u00f3n fila_posicion = df.iloc[0] fila_posicion Out[13]: <pre>nombre      Juan\nedad          28\nciudad    Madrid\nName: a, dtype: object</pre> In\u00a0[14]: Copied! <pre># Selecci\u00f3n de varias filas por posici\u00f3n\nvarias_filas_posicion = df.iloc[0:2]\nvarias_filas_posicion\n</pre> # Selecci\u00f3n de varias filas por posici\u00f3n varias_filas_posicion = df.iloc[0:2] varias_filas_posicion Out[14]: nombre edad ciudad a Juan 28 Madrid b Ana 23 Barcelona In\u00a0[15]: Copied! <pre># Selecci\u00f3n de filas y columnas por etiqueta\nsubconjunto = df.loc['a':'b', ['nombre', 'edad']]\nsubconjunto\n</pre> # Selecci\u00f3n de filas y columnas por etiqueta subconjunto = df.loc['a':'b', ['nombre', 'edad']] subconjunto Out[15]: nombre edad a Juan 28 b Ana 23 In\u00a0[16]: Copied! <pre># Selecci\u00f3n de filas y columnas por posici\u00f3n\nsubconjunto_posicion = df.iloc[0:2, 0:2]\nsubconjunto_posicion\n</pre> # Selecci\u00f3n de filas y columnas por posici\u00f3n subconjunto_posicion = df.iloc[0:2, 0:2] subconjunto_posicion Out[16]: nombre edad a Juan 28 b Ana 23 In\u00a0[17]: Copied! <pre>df = pd.DataFrame({\n    'col_1': [1, 2, 3, 4, 5], \n    'col_2': [6, 7, 8, 9, 10], \n    'col_3': [11, 12, 13, 14, 15]},\n    index=['A', 'B', 'C', 'D', 'E']\n)\n\ndf\n</pre> df = pd.DataFrame({     'col_1': [1, 2, 3, 4, 5],      'col_2': [6, 7, 8, 9, 10],      'col_3': [11, 12, 13, 14, 15]},     index=['A', 'B', 'C', 'D', 'E'] )  df Out[17]: col_1 col_2 col_3 A 1 6 11 B 2 7 12 C 3 8 13 D 4 9 14 E 5 10 15 In\u00a0[18]: Copied! <pre># Selecci\u00f3n utilizando loc\ndf.loc['B':'D', ['col_1','col_2']]\n</pre> # Selecci\u00f3n utilizando loc df.loc['B':'D', ['col_1','col_2']] Out[18]: col_1 col_2 B 2 7 C 3 8 D 4 9 In\u00a0[19]: Copied! <pre># Selecci\u00f3n utilizando iloc\ndf.iloc[1:4, 0:2]\n</pre> # Selecci\u00f3n utilizando iloc df.iloc[1:4, 0:2] Out[19]: col_1 col_2 B 2 7 C 3 8 D 4 9 <p>En resumen, la principal diferencia entre <code>loc</code> e <code>iloc</code> es el tipo de indexaci\u00f3n utilizado y c\u00f3mo se maneja el l\u00edmite superior en la selecci\u00f3n. <code>loc</code> se utiliza para indexar los datos mediante etiquetas expl\u00edcitas, mientras que <code>iloc</code> se utiliza para indexar los datos mediante posiciones impl\u00edcitas.</p>"},{"location":"pandas/023_index/#indexacion-y-seleccion","title":"Indexaci\u00f3n y Selecci\u00f3n\u00b6","text":""},{"location":"pandas/023_index/#indexacion-pandas-series","title":"Indexaci\u00f3n pandas Series\u00b6","text":"<p>La indexaci\u00f3n y selecci\u00f3n de objetos Series de Pandas es una de las funcionalidades m\u00e1s importantes de la biblioteca, y permite acceder a los elementos individuales de una serie, as\u00ed como seleccionar subconjuntos de elementos seg\u00fan diferentes criterios.</p> <p>Para acceder a los elementos hay 2 formas de hacerlo.</p> <ol> <li><p>Por etiquetas o m\u00e9todo <code>.loc</code></p> </li> <li><p>Por posici\u00f3n o el m\u00e9todo <code>.iloc</code></p> </li> </ol>"},{"location":"pandas/023_index/#indexacion-de-etiquetas","title":"Indexaci\u00f3n de etiquetas\u00b6","text":"<p>Podemos acceder a los elementos de la serie utilizando las etiquetas del \u00edndice de la serie. Podemos acceder a los elementos por su etiqueta de la siguiente manera:</p>"},{"location":"pandas/023_index/#indexacion-de-posicion","title":"Indexaci\u00f3n de posici\u00f3n\u00b6","text":"<p>Podemos acceder a los elementos de la serie utilizando la posici\u00f3n en la serie. Podemos acceder a los elementos por su posici\u00f3n de la siguiente manera:</p>"},{"location":"pandas/023_index/#seleccion-de-multiples-elementos","title":"Selecci\u00f3n de m\u00faltiples elementos\u00b6","text":"<p>Podemos seleccionar m\u00faltiples elementos de la serie de varias maneras. Por ejemplo, podemos seleccionar los elementos por etiquetas de \u00edndice utilizando una lista de etiquetas:</p>"},{"location":"pandas/023_index/#seleccion-de-rangos","title":"Selecci\u00f3n de rangos\u00b6","text":"<p>Podemos seleccionar rangos de elementos de la serie de varias maneras. Podemos seleccionar un rango de elementos utilizando etiquetas de \u00edndice:</p>"},{"location":"pandas/023_index/#indexacion-pandas-dataframe","title":"Indexaci\u00f3n pandas dataframe\u00b6","text":"<p>En Pandas, la indexaci\u00f3n y selecci\u00f3n de datos en un DataFrame se pueden realizar de varias maneras. Primero, es importante tener en cuenta que un DataFrame consta de filas y columnas etiquetadas. La selecci\u00f3n de datos se puede hacer utilizando estas etiquetas o mediante la posici\u00f3n de las filas y columnas.</p> <p>Aqu\u00ed hay algunas formas comunes de indexaci\u00f3n y selecci\u00f3n de datos en un DataFrame de Pandas:</p>"},{"location":"pandas/023_index/#seleccion-de-columnas","title":"Selecci\u00f3n de columnas\u00b6","text":"<p>Podemos seleccionar una o varias columnas de un DataFrame de la siguiente manera:</p>"},{"location":"pandas/023_index/#seleccion-de-filas","title":"Selecci\u00f3n de filas\u00b6","text":"<p>Podemos seleccionar una o varias filas de un DataFrame utilizando el \u00edndice de la fila o utilizando la funci\u00f3n <code>iloc()</code>:</p>"},{"location":"pandas/023_index/#seleccion-de-filas-y-columnas","title":"Selecci\u00f3n de filas y columnas\u00b6","text":"<p>Podemos seleccionar un subconjunto de filas y columnas de un DataFrame utilizando etiquetas o posici\u00f3n de fila y columna:</p>"},{"location":"pandas/023_index/#diferencia-de-loc-e-iloc","title":"Diferencia de loc e iloc\u00b6","text":"<p><code>loc</code> e <code>iloc</code> son dos atributos que se utilizan para la selecci\u00f3n de datos en un DataFrame o una Serie. Ambos atributos permiten la selecci\u00f3n de filas y columnas espec\u00edficas en un DataFrame, pero utilizan diferentes m\u00e9todos para hacerlo.</p> <ul> <li><p><code>loc</code>: este atributo permite la selecci\u00f3n de datos mediante etiquetas de filas y columnas. Se utiliza para acceder a las filas y columnas utilizando etiquetas expl\u00edcitas. Por ejemplo, <code>data.loc[3, 'columna']</code> seleccionar\u00eda el valor en la fila 3 y la columna 'columna'.</p> </li> <li><p><code>iloc</code> : este atributo permite la selecci\u00f3n de datos mediante \u00edndices enteros de filas y columnas. Se utiliza para acceder a las filas y columnas utilizando \u00edndices enteros impl\u00edcitos. Por ejemplo, <code>df.iloc[3, 1]</code> seleccionar\u00eda el valor en la cuarta fila y la segunda columna.</p> </li> </ul> <p>La principal diferencia entre loc e iloc es el tipo de indexaci\u00f3n utilizado. loc se utiliza para indexar los datos mediante etiquetas, mientras que iloc se utiliza para indexar los datos mediante la posici\u00f3n en la matriz de datos.</p> <p>Adem\u00e1s, <code>loc</code> es inclusivo en el sentido de que el l\u00edmite superior se incluye en la selecci\u00f3n, mientras que <code>iloc</code> es exclusivo en el l\u00edmite superior y no incluye el valor correspondiente. Es decir, <code>loc</code> incluye la \u00faltima fila/columna seleccionada, mientras que <code>iloc</code> no lo hace.</p> <p></p> <p>Por ejemplo, si tenemos un DataFrame con \u00edndice de etiquetas de <code>A</code> a <code>E</code> y un \u00edndice num\u00e9rico de <code>0</code> a <code>4</code>, la selecci\u00f3n utilizando <code>loc</code> incluir\u00eda la \u00faltima fila y columna seleccionada, mientras que la selecci\u00f3n utilizando <code>iloc</code> no lo har\u00eda:</p>"},{"location":"pandas/024_filtros/","title":"Filtrar Datos","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\ndata = {'Nombre': ['Juan', 'Ana', 'Pedro', 'Maria'],\n        'Edad': [15, 17, 35, None],\n        'G\u00e9nero': ['Masculino', 'Femenino', 'Masculino', '-']}\n\ndf = pd.DataFrame(data)\ndf\n</pre> import pandas as pd data = {'Nombre': ['Juan', 'Ana', 'Pedro', 'Maria'],         'Edad': [15, 17, 35, None],         'G\u00e9nero': ['Masculino', 'Femenino', 'Masculino', '-']}  df = pd.DataFrame(data) df Out[1]: Nombre Edad G\u00e9nero 0 Juan 15.0 Masculino 1 Ana 17.0 Femenino 2 Pedro 35.0 Masculino 3 Maria NaN - In\u00a0[2]: Copied! <pre># mayor o igual a 18.\ndf.loc[df['Edad'] &gt;= 18]\n</pre> # mayor o igual a 18. df.loc[df['Edad'] &gt;= 18] Out[2]: Nombre Edad G\u00e9nero 2 Pedro 35.0 Masculino <p>Para entender mejor los filtros de pandas, separemos el problema. Lo primero ser\u00e1 definir la condici\u00f3n:</p> In\u00a0[3]: Copied! <pre># crear condicion\nvalor_objetivo = 18 \ncondicion = (df['Edad'] &gt;= valor_objetivo)\n</pre> # crear condicion valor_objetivo = 18  condicion = (df['Edad'] &gt;= valor_objetivo) <p>Obsersevemos que la variable <code>condicion</code> corresponde un panda series con objetos Booleanos.</p> In\u00a0[4]: Copied! <pre># ver objetos de la variable condicion\ncondicion\n</pre> # ver objetos de la variable condicion condicion Out[4]: <pre>0    False\n1    False\n2     True\n3    False\nName: Edad, dtype: bool</pre> <p>Ahora, al aplicar la varible <code>condicion</code> al pandas dataframe, esto retornar\u00e1 el dataframe objetivo en donde los \u00ednidices de la condici\u00f3n son verdaderas (<code>True</code>).</p> In\u00a0[5]: Copied! <pre>df[condicion]\n</pre> df[condicion] Out[5]: Nombre Edad G\u00e9nero 2 Pedro 35.0 Masculino In\u00a0[6]: Copied! <pre># mayor o igual a 18\ndf[df['Edad'] &gt;= 18]\n</pre> # mayor o igual a 18 df[df['Edad'] &gt;= 18] Out[6]: Nombre Edad G\u00e9nero 2 Pedro 35.0 Masculino <p>Veamos m\u00e1s ejemplos:</p> In\u00a0[7]: Copied! <pre># edad entre 0 y 18 \ndf.loc[df['Edad'].between(0,18)]\n</pre> # edad entre 0 y 18  df.loc[df['Edad'].between(0,18)] Out[7]: Nombre Edad G\u00e9nero 0 Juan 15.0 Masculino 1 Ana 17.0 Femenino In\u00a0[8]: Copied! <pre># nombre igual a Pedro\ndf.loc[df['Nombre']=='Pedro']\n</pre> # nombre igual a Pedro df.loc[df['Nombre']=='Pedro'] Out[8]: Nombre Edad G\u00e9nero 2 Pedro 35.0 Masculino In\u00a0[9]: Copied! <pre># columna \"G\u00e9nero\" es \"Masculino\" o \"Femenino\"\ndf[df['G\u00e9nero'].isin(['Masculino', 'Femenino'])]\n</pre> # columna \"G\u00e9nero\" es \"Masculino\" o \"Femenino\" df[df['G\u00e9nero'].isin(['Masculino', 'Femenino'])] Out[9]: Nombre Edad G\u00e9nero 0 Juan 15.0 Masculino 1 Ana 17.0 Femenino 2 Pedro 35.0 Masculino In\u00a0[10]: Copied! <pre># columna \"Nombre\" contiene la palabra \"Juan\"\ndf[df['Nombre'].str.contains('Juan')]\n</pre> # columna \"Nombre\" contiene la palabra \"Juan\" df[df['Nombre'].str.contains('Juan')] Out[10]: Nombre Edad G\u00e9nero 0 Juan 15.0 Masculino In\u00a0[11]: Copied! <pre>df[df['Edad'].isnull()]\n</pre> df[df['Edad'].isnull()] Out[11]: Nombre Edad G\u00e9nero 3 Maria NaN - <p>al mismo tiempo, podemos filtrar por los datos que NO son nulos con <code>notnull()</code></p> In\u00a0[12]: Copied! <pre>df[df['Edad'].notnull()]\n</pre> df[df['Edad'].notnull()] Out[12]: Nombre Edad G\u00e9nero 0 Juan 15.0 Masculino 1 Ana 17.0 Femenino 2 Pedro 35.0 Masculino In\u00a0[13]: Copied! <pre>df[(df['Edad'] &gt;= 18) &amp; (df['G\u00e9nero'] == 'Masculino')]\n</pre> df[(df['Edad'] &gt;= 18) &amp; (df['G\u00e9nero'] == 'Masculino')] Out[13]: Nombre Edad G\u00e9nero 2 Pedro 35.0 Masculino <p>Observaci\u00f3n: Una alternativa para filtrar datos es utilizar la notaci\u00f3n lambda, la cual resulta m\u00e1s pr\u00e1ctica sobre todo cuando el nombre del dataframe es largo.</p> <p>Veamos unos ejemplos:</p> In\u00a0[14]: Copied! <pre>data = {'Nombre': ['Juan', 'Ana', 'Pedro', 'Maria'],\n        'Edad': [15, 17, 35, None],\n        'G\u00e9nero': ['Masculino', 'Femenino', 'Masculino', '-']}\n\ndf_nombre_muy_largo = pd.DataFrame(data)\ndf_nombre_muy_largo\n</pre> data = {'Nombre': ['Juan', 'Ana', 'Pedro', 'Maria'],         'Edad': [15, 17, 35, None],         'G\u00e9nero': ['Masculino', 'Femenino', 'Masculino', '-']}  df_nombre_muy_largo = pd.DataFrame(data) df_nombre_muy_largo Out[14]: Nombre Edad G\u00e9nero 0 Juan 15.0 Masculino 1 Ana 17.0 Femenino 2 Pedro 35.0 Masculino 3 Maria NaN - In\u00a0[15]: Copied! <pre># caso normal\ndf_nombre_muy_largo.loc[(df_nombre_muy_largo['Edad'] &gt;= 18) &amp; (df_nombre_muy_largo['G\u00e9nero'] == 'Masculino')]\n</pre> # caso normal df_nombre_muy_largo.loc[(df_nombre_muy_largo['Edad'] &gt;= 18) &amp; (df_nombre_muy_largo['G\u00e9nero'] == 'Masculino')] Out[15]: Nombre Edad G\u00e9nero 2 Pedro 35.0 Masculino In\u00a0[16]: Copied! <pre># caso lambda \ndf_nombre_muy_largo.loc[lambda x: (x['Edad'] &gt;= 18) &amp; (x['G\u00e9nero'] == 'Masculino')]\n</pre> # caso lambda  df_nombre_muy_largo.loc[lambda x: (x['Edad'] &gt;= 18) &amp; (x['G\u00e9nero'] == 'Masculino')] Out[16]: Nombre Edad G\u00e9nero 2 Pedro 35.0 Masculino"},{"location":"pandas/024_filtros/#filtrar-datos","title":"Filtrar Datos\u00b6","text":"<p>Para filtrar datos en Pandas, se utiliza el m\u00e9todo <code>loc()</code> o <code>iloc()</code>, dependiendo de si queremos filtrar por etiquetas de \u00edndice o por posici\u00f3n. Para efectos pr\u00e1cticos, utilizaremos solo <code>loc()</code>.</p> <p>Supongamos que tenemos un DataFrame llamado <code>df</code> con las columnas \"Nombre\", \"Edad\" y \"G\u00e9nero\", y queremos filtrar los datos para obtener solo las filas donde la edad sea mayor o igual a 18.</p> <p>Para hacer esto utilizando el m\u00e9todo <code>loc()</code>, podemos utilizar la siguiente l\u00ednea de c\u00f3digo:</p>"},{"location":"pandas/024_filtros/#tipos-de-filtros","title":"Tipos de Filtros\u00b6","text":""},{"location":"pandas/024_filtros/#filtrar-por-valor","title":"Filtrar por valor\u00b6","text":"<p>podemos utilizar los operadores de comparaci\u00f3n, como <code>==</code>, <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code> y <code>&lt;=</code>, para filtrar datos por valor. Por ejemplo, si queremos filtrar solo las filas donde la columna \"Edad\" es mayor o igual a 18, podemos utilizar la siguiente l\u00ednea de c\u00f3digo:</p>"},{"location":"pandas/024_filtros/#filtrar-por-multiples-valores","title":"Filtrar por m\u00faltiples valores\u00b6","text":"<p>podemos utilizar el operador <code>isin()</code> para filtrar datos por m\u00faltiples valores. Por ejemplo, si queremos filtrar solo las filas donde la columna \"G\u00e9nero\" es \"Masculino\" o \"Femenino\", podemos utilizar la siguiente l\u00ednea de c\u00f3digo:</p>"},{"location":"pandas/024_filtros/#filtrar-por-patron-de-texto","title":"Filtrar por patr\u00f3n de texto\u00b6","text":"<p>podemos utilizar el m\u00e9todo <code>str.contains()</code> para filtrar datos por un patr\u00f3n de texto en una columna. Por ejemplo, si queremos filtrar solo las filas donde la columna \"Nombre\" contiene la palabra \"Juan\", podemos utilizar la siguiente l\u00ednea de c\u00f3digo:</p>"},{"location":"pandas/024_filtros/#filtrar-por-nulos","title":"Filtrar por nulos\u00b6","text":"<p>podemos utilizar el m\u00e9todo <code>isnull()</code> para filtrar datos por valores nulos en una columna. Por ejemplo, si queremos filtrar solo las filas donde la columna \"Edad\" tiene un valor nulo, podemos utilizar la siguiente l\u00ednea de c\u00f3digo:</p>"},{"location":"pandas/024_filtros/#filtrar-por-varias-condiciones","title":"Filtrar por varias condiciones\u00b6","text":"<p>podemos utilizar operadores l\u00f3gicos como <code>&amp;</code> (and) y <code>|</code> (or) para combinar varias condiciones de filtrado. Por ejemplo, si queremos filtrar solo las filas donde la columna \"Edad\" es mayor o igual a 18 y la columna \"G\u00e9nero\" es \"Masculino\", podemos utilizar la siguiente l\u00ednea de c\u00f3digo:</p>"},{"location":"pandas/025_nulos_duplicados/","title":"Valores Nulos y Duplicados","text":"In\u00a0[1]: Copied! <pre>import pandas as pd\nimport numpy as np\n\nvals1 = np.array([1, None, 3, 4])\nvals1\n</pre> import pandas as pd import numpy as np  vals1 = np.array([1, None, 3, 4]) vals1 Out[1]: <pre>array([1, None, 3, 4], dtype=object)</pre> In\u00a0[2]: Copied! <pre>vals1.dtype\n</pre> vals1.dtype Out[2]: <pre>dtype('O')</pre> <p>Si realiza una operaci\u00f3n como <code>sum()</code> o <code> min()</code>  en un arreglo con <code>None</code>, generalmente obtendr\u00e1 un error:</p> <pre># error\nvals1.sum()\n</pre> <p>NaN</p> <p>La otra representaci\u00f3n de datos faltantes, <code>NaN</code> (acr\u00f3nimo de Not a Number), es diferente; es un valor de punto flotante especial reconocido por todos los sistemas que usan la representaci\u00f3n de punto flotante est\u00e1ndar IEEE:</p> In\u00a0[3]: Copied! <pre>vals2 = np.array([1, np.nan, 3, 4]) \nvals2.dtype\n</pre> vals2 = np.array([1, np.nan, 3, 4])  vals2.dtype Out[3]: <pre>dtype('float64')</pre> <p>Debe tener en cuenta que  <code>NaN</code> es como un virus de datos: infecta cualquier otro objeto que toca. Independientemente de la operaci\u00f3n, el resultado de la aritm\u00e9tica con <code>NaN</code> ser\u00e1 otro <code>NaN</code>:</p> In\u00a0[4]: Copied! <pre>1 + np.nan\n</pre> 1 + np.nan Out[4]: <pre>nan</pre> In\u00a0[5]: Copied! <pre>0 *  np.nan\n</pre> 0 *  np.nan Out[5]: <pre>nan</pre> In\u00a0[6]: Copied! <pre>vals2.sum(), vals2.min(), vals2.max()\n</pre> vals2.sum(), vals2.min(), vals2.max() Out[6]: <pre>(nan, nan, nan)</pre> <p>NaN y None en Pandas</p> <p><code>NaN</code> y <code>None</code> tienen su lugar, y Pandas est\u00e1 dise\u00f1ado para manejarlos casi indistintamente, convirtiendo entre ellos cuando corresponda. Por otro lado, Pandas convierte autom\u00e1ticamente el valor <code>None</code> en un valor <code>NaN</code>.</p> <p>Veamos un ejemplo:</p> In\u00a0[7]: Copied! <pre>s = pd.Series([1, np.nan, 2, None])\ns\n</pre> s = pd.Series([1, np.nan, 2, None]) s Out[7]: <pre>0    1.0\n1    NaN\n2    2.0\n3    NaN\ndtype: float64</pre> <ul> <li><p><code>isnull()</code>: esta funci\u00f3n devuelve una matriz booleana que indica qu\u00e9 valores son nulos en un DataFrame o Serie.</p> </li> <li><p><code>notnull()</code>: esta funci\u00f3n es el complemento de isnull(), y devuelve una matriz booleana que indica qu\u00e9 valores no son nulos en un DataFrame o Serie.</p> </li> <li><p><code>dropna()</code>: este m\u00e9todo elimina las filas o columnas que contienen al menos un valor nulo en un DataFrame.</p> </li> <li><p><code>fillna()</code>: este m\u00e9todo rellena los valores nulos en un DataFrame o Serie con un valor especificado.</p> </li> <li><p><code>interpolate()</code>: este m\u00e9todo rellena los valores nulos en un DataFrame o Serie mediante la interpolaci\u00f3n lineal entre los valores no nulos.</p> </li> <li><p><code>replace()</code>: este m\u00e9todo permite reemplazar un valor espec\u00edfico, incluyendo valores nulos, con otro valor.</p> </li> </ul> <p>Por ejemplo, para manejar valores nulos en un DataFrame df, se podr\u00eda utilizar el siguiente c\u00f3digo:</p> In\u00a0[8]: Copied! <pre># Crear un DataFrame con valores nulos\ndata = {'Nombre': ['Juan', 'Mar\u00eda', 'Pedro', 'Ana', 'Luis'],\n        'Edad': [20, 30, np.nan, 25, 27],\n        'G\u00e9nero': ['M', 'F', 'M', np.nan, 'M']}\ndf = pd.DataFrame(data)\ndf\n</pre> # Crear un DataFrame con valores nulos data = {'Nombre': ['Juan', 'Mar\u00eda', 'Pedro', 'Ana', 'Luis'],         'Edad': [20, 30, np.nan, 25, 27],         'G\u00e9nero': ['M', 'F', 'M', np.nan, 'M']} df = pd.DataFrame(data) df Out[8]: Nombre Edad G\u00e9nero 0 Juan 20.0 M 1 Mar\u00eda 30.0 F 2 Pedro NaN M 3 Ana 25.0 NaN 4 Luis 27.0 M In\u00a0[9]: Copied! <pre># Verificar qu\u00e9 valores son nulos\nprint(df.isnull())\n</pre> # Verificar qu\u00e9 valores son nulos print(df.isnull()) <pre>   Nombre   Edad  G\u00e9nero\n0   False  False   False\n1   False  False   False\n2   False   True   False\n3   False  False    True\n4   False  False   False\n</pre> In\u00a0[10]: Copied! <pre>df[df.isnull().all(axis=1)]\n</pre> df[df.isnull().all(axis=1)] Out[10]: Nombre Edad G\u00e9nero In\u00a0[11]: Copied! <pre># Verificar qu\u00e9 valores son no nulos\nprint(df.notnull())\n</pre> # Verificar qu\u00e9 valores son no nulos print(df.notnull()) <pre>   Nombre   Edad  G\u00e9nero\n0    True   True    True\n1    True   True    True\n2    True  False    True\n3    True   True   False\n4    True   True    True\n</pre> In\u00a0[12]: Copied! <pre>df[df.notnull().all(axis=1)]\n</pre> df[df.notnull().all(axis=1)] Out[12]: Nombre Edad G\u00e9nero 0 Juan 20.0 M 1 Mar\u00eda 30.0 F 4 Luis 27.0 M In\u00a0[13]: Copied! <pre># Eliminar las filas que contienen valores nulos\ndf.dropna()\n</pre> # Eliminar las filas que contienen valores nulos df.dropna() Out[13]: Nombre Edad G\u00e9nero 0 Juan 20.0 M 1 Mar\u00eda 30.0 F 4 Luis 27.0 M In\u00a0[14]: Copied! <pre># Rellenar los valores nulos con un valor espec\u00edfico, por ejemplo cero\ndf.fillna(0)\n</pre> # Rellenar los valores nulos con un valor espec\u00edfico, por ejemplo cero df.fillna(0) Out[14]: Nombre Edad G\u00e9nero 0 Juan 20.0 M 1 Mar\u00eda 30.0 F 2 Pedro 0.0 M 3 Ana 25.0 0 4 Luis 27.0 M In\u00a0[15]: Copied! <pre># Rellenar los valores nulos mediante interpolaci\u00f3n\ndf.interpolate()\n</pre> # Rellenar los valores nulos mediante interpolaci\u00f3n df.interpolate() Out[15]: Nombre Edad G\u00e9nero 0 Juan 20.0 M 1 Mar\u00eda 30.0 F 2 Pedro 27.5 M 3 Ana 25.0 NaN 4 Luis 27.0 M In\u00a0[16]: Copied! <pre># Reemplazar un valor espec\u00edfico (incluyendo valores nulos) con otro valor\ndf.replace({\"G\u00e9nero\": {np.nan: \"Otro\"}})\n</pre> # Reemplazar un valor espec\u00edfico (incluyendo valores nulos) con otro valor df.replace({\"G\u00e9nero\": {np.nan: \"Otro\"}}) Out[16]: Nombre Edad G\u00e9nero 0 Juan 20.0 M 1 Mar\u00eda 30.0 F 2 Pedro NaN M 3 Ana 25.0 Otro 4 Luis 27.0 M <p>Observaci\u00f3n</p> <p>En Pandas, la funci\u00f3n <code>.all()</code> se utiliza para verificar si todos los valores en un eje determinado (filas o columnas) de un DataFrame son <code>True</code>.</p> <p>Cuando se aplica <code>.all()</code> a un DataFrame, se eval\u00faa cada valor del eje especificado (0 para filas y 1 para columnas) y devuelve True si todos los valores son <code>True</code>, y <code>False</code> en caso contrario. Si el DataFrame contiene valores nulos (<code>NaN</code>), se consideran como False para la evaluaci\u00f3n.</p> <p>Por ejemplo, supongamos que tenemos el siguiente DataFrame:</p> In\u00a0[17]: Copied! <pre>df = pd.DataFrame({\n    'A': [True, False, True],\n    'B': [True, True, True],\n    'C': [False, True, True]\n})\n</pre> df = pd.DataFrame({     'A': [True, False, True],     'B': [True, True, True],     'C': [False, True, True] }) <p>Si queremos verificar si todos los valores de cada columna son <code>True</code>, podemos usar la funci\u00f3n <code>.all()</code> de la siguiente manera:</p> In\u00a0[18]: Copied! <pre># Verificar si todos los valores de cada columna son True\ncolumnas_con_todos_true = df.all()\nprint(columnas_con_todos_true)\n</pre> # Verificar si todos los valores de cada columna son True columnas_con_todos_true = df.all() print(columnas_con_todos_true) <pre>A    False\nB     True\nC    False\ndtype: bool\n</pre> <p>Si queremos verificar si todos los valores de cada fila son <code>True</code>, podemos usar la funci\u00f3n <code>.all(axis=1)</code> de la siguiente manera:</p> In\u00a0[19]: Copied! <pre># Verificar si todos los valores de cada fila son True\nfilas_con_todos_true = df.all(axis=1)\nprint(filas_con_todos_true)\n</pre> # Verificar si todos los valores de cada fila son True filas_con_todos_true = df.all(axis=1) print(filas_con_todos_true) <pre>0    False\n1    False\n2     True\ndtype: bool\n</pre> <p>Estos son solo algunos ejemplos de c\u00f3mo puedes trabajar con fechas y horas en Pandas utilizando las clases <code>Timestamp</code>, <code>DatetimeIndex</code> y <code>Period</code>. Pandas tambi\u00e9n proporciona muchas m\u00e1s funciones \u00fatiles para trabajar con datos de tiempo de manera eficiente.</p> In\u00a0[20]: Copied! <pre># Crear un DataFrame de ejemplo con datos duplicados\ndata = {\n    'id': [1, 2, 3, 3, 4, 5, 5],\n    'name': ['John', 'Mary', 'Peter', 'Peter', 'Anna', 'George', 'George'],\n    'age': [25, 25, 35, 35, 40, 45, 45]\n}\ndf = pd.DataFrame(data)\ndf\n</pre> # Crear un DataFrame de ejemplo con datos duplicados data = {     'id': [1, 2, 3, 3, 4, 5, 5],     'name': ['John', 'Mary', 'Peter', 'Peter', 'Anna', 'George', 'George'],     'age': [25, 25, 35, 35, 40, 45, 45] } df = pd.DataFrame(data) df Out[20]: id name age 0 1 John 25 1 2 Mary 25 2 3 Peter 35 3 3 Peter 35 4 4 Anna 40 5 5 George 45 6 5 George 45 In\u00a0[21]: Copied! <pre># Comprobar filas duplicadas\nduplicates = df.duplicated()\nduplicates\n</pre> # Comprobar filas duplicadas duplicates = df.duplicated() duplicates Out[21]: <pre>0    False\n1    False\n2    False\n3     True\n4    False\n5    False\n6     True\ndtype: bool</pre> In\u00a0[22]: Copied! <pre># Eliminar filas duplicadas\ndf = df.drop_duplicates()\ndf\n</pre> # Eliminar filas duplicadas df = df.drop_duplicates() df Out[22]: id name age 0 1 John 25 1 2 Mary 25 2 3 Peter 35 4 4 Anna 40 5 5 George 45 <p>Tambi\u00e9n podemos eliminar duplicados por una o var\u00edas columnas utilizando el comando <code>subset</code>:</p> In\u00a0[23]: Copied! <pre># Eliminar duplicados por columna 'name'\ndf_sin_duplicados = df.drop_duplicates(subset=['name'])\ndf_sin_duplicados\n</pre> # Eliminar duplicados por columna 'name' df_sin_duplicados = df.drop_duplicates(subset=['name']) df_sin_duplicados Out[23]: id name age 0 1 John 25 1 2 Mary 25 2 3 Peter 35 4 4 Anna 40 5 5 George 45"},{"location":"pandas/025_nulos_duplicados/#valores-nulos-y-duplicados","title":"Valores Nulos y Duplicados\u00b6","text":""},{"location":"pandas/025_nulos_duplicados/#valores-nulos","title":"Valores Nulos\u00b6","text":"<p>En Pandas, un valor nulo (o faltante) representa la ausencia de un valor en una celda espec\u00edfica de un DataFrame o una Serie. Los valores nulos pueden ocurrir por varias razones, como datos perdidos o no disponibles, errores de medici\u00f3n o problemas de entrada de datos.</p> <p>Los valores nulos se representan en Pandas mediante el objeto <code>NaN</code> (acr\u00f3nimo de \"Not a Number\"). <code>NaN</code> es un valor especial de punto flotante definido en el est\u00e1ndar IEEE para representar valores no definidos o indefinidos. En Pandas, los valores nulos se representan como <code>NaN</code> para las Series y DataFrames que utilizan datos num\u00e9ricos, y como <code>None</code> para las Series y DataFrames que utilizan datos no num\u00e9ricos.</p>"},{"location":"pandas/025_nulos_duplicados/#tipos-de-valores-nulos","title":"Tipos de Valores Nulos\u00b6","text":"<p>None</p> <p>Es un objeto \u00fanico de Python que a menudo se usa para datos faltantes en el c\u00f3digo de Python. Debido a que es un objeto de Python, <code>None</code> no se puede usar en ning\u00fan arreglo NumPy/Pandas arbitrario, sino solo en arreglos con el tipo de datos <code>object</code> (es decir, arreglos de objetos de Python):</p>"},{"location":"pandas/025_nulos_duplicados/#operando-con-valores-nulos","title":"Operando con valores nulos\u00b6","text":"<p>Para manipular los datos nulos en Pandas, se pueden utilizar varias funciones y m\u00e9todos que permiten detectar, eliminar o rellenar valores nulos en un DataFrame o Serie. Algunas de las funciones y m\u00e9todos m\u00e1s comunes son:</p>"},{"location":"pandas/025_nulos_duplicados/#datos-duplicados","title":"Datos Duplicados\u00b6","text":"<p>En Pandas, se pueden manejar los datos duplicados utilizando el m\u00e9todo <code>duplicated()</code> y <code>drop_duplicates()</code>.</p> <ul> <li>El m\u00e9todo <code>duplicated()</code> devuelve un booleano que indica si una fila es duplicada o no, es decir, si existe otra fila con los mismos valores.</li> <li>El m\u00e9todo <code>drop_duplicates()</code> elimina las filas duplicadas de un DataFrame.</li> </ul> <p>Veamos un ejemplo:</p>"},{"location":"pandas/026_fechas/","title":"Manipulaci\u00f3n de Fechas","text":"In\u00a0[1]: Copied! <pre>import datetime\n\nnow = datetime.datetime.now()\nprint(now)\n</pre> import datetime  now = datetime.datetime.now() print(now) <pre>2023-02-20 14:54:24.462728\n</pre> <p>Puedes acceder a partes espec\u00edficas de un objeto <code>datetime.datetime</code>, como el a\u00f1o, el mes, el d\u00eda, la hora, el minuto y el segundo. Algunos de los atributos m\u00e1s comunes son:</p> <ul> <li><code>year</code>: representa el a\u00f1o de la fecha y la hora.</li> <li><code>month</code>: representa el mes de la fecha y la hora, como un n\u00famero entre 1 y 12.</li> <li><code>day</code>: representa el d\u00eda del mes de la fecha y la hora, como un n\u00famero entre 1 y 31.</li> <li><code>hour</code>: representa la hora del d\u00eda de la fecha y la hora, como un n\u00famero entre 0 y 23.</li> <li><code>minute</code>: representa los minutos de la hora de la fecha y la hora, como un n\u00famero entre 0 y 59.</li> <li><code>second</code>: representa los segundos de la hora de la fecha y la hora, como un n\u00famero entre 0 y 59.</li> <li><code>microsecond</code>: representa los microsegundos de la hora de la fecha y la hora, como un n\u00famero entre 0 y 999999.</li> </ul> In\u00a0[2]: Copied! <pre>from datetime import datetime\n\n# Crear objeto datetime\nnow = datetime.now()\n\n# Acceder a los atributos\nprint(now.year)\nprint(now.month)\nprint(now.day)\nprint(now.hour)\nprint(now.minute)\nprint(now.second)\nprint(now.microsecond)\n</pre> from datetime import datetime  # Crear objeto datetime now = datetime.now()  # Acceder a los atributos print(now.year) print(now.month) print(now.day) print(now.hour) print(now.minute) print(now.second) print(now.microsecond) <pre>2023\n2\n20\n14\n54\n24\n482265\n</pre> <p>Tambi\u00e9n puedes crear un objeto <code>datetime.datetime</code> a partir de una cadena de texto usando la funci\u00f3n <code>strptime()</code>:</p> In\u00a0[3]: Copied! <pre>from datetime import datetime\n\n# Crear objeto datetime\nnow = datetime.now()\n\n# Convertir objeto datetime en cadena de texto\n# Formato: AAAA-MM-DD\ndate_string = now.strftime('%Y-%m-%d')\nprint(date_string)\n\n# Formato: DD/MM/AAAA\ndate_string = now.strftime('%d/%m/%Y')\nprint(date_string)\n\n# Formato: AAAA-MM-DD HH:MM:SS\ndate_string = now.strftime('%Y-%m-%d %H:%M:%S')\nprint(date_string)\n\n# Formato: DD/MM/AAAA HH:MM\ndate_string = now.strftime('%d/%m/%Y %H:%M')\nprint(date_string)\n\n# Formato: D\u00eda de la semana, Mes DD, AAAA\ndate_string = now.strftime('%A, %B %d, %Y')\nprint(date_string)\n</pre> from datetime import datetime  # Crear objeto datetime now = datetime.now()  # Convertir objeto datetime en cadena de texto # Formato: AAAA-MM-DD date_string = now.strftime('%Y-%m-%d') print(date_string)  # Formato: DD/MM/AAAA date_string = now.strftime('%d/%m/%Y') print(date_string)  # Formato: AAAA-MM-DD HH:MM:SS date_string = now.strftime('%Y-%m-%d %H:%M:%S') print(date_string)  # Formato: DD/MM/AAAA HH:MM date_string = now.strftime('%d/%m/%Y %H:%M') print(date_string)  # Formato: D\u00eda de la semana, Mes DD, AAAA date_string = now.strftime('%A, %B %d, %Y') print(date_string) <pre>2023-02-20\n20/02/2023\n2023-02-20 14:54:24\n20/02/2023 14:54\nMonday, February 20, 2023\n</pre> <p>Algunos de los c\u00f3digos de formato m\u00e1s comunes son:</p> <ul> <li><code>%Y</code>: a\u00f1o con cuatro d\u00edgitos.</li> <li><code>%y</code>: a\u00f1o con dos d\u00edgitos.</li> <li><code>%m</code>: mes como n\u00famero de dos d\u00edgitos.</li> <li><code>%d</code>: d\u00eda del mes como n\u00famero de dos d\u00edgitos.</li> <li><code>%H</code>: hora en formato de 24 horas con dos d\u00edgitos.</li> <li><code>%I</code>: hora en formato de 12 horas con dos d\u00edgitos.</li> <li><code>%M</code>: minutos con dos d\u00edgitos.</li> <li><code>%S</code>: segundos con dos d\u00edgitos.</li> <li><code>%p</code>: indicador de AM/PM.</li> </ul> <p>Nota: La lista completa de c\u00f3digos de formato se puede encontrar en la documentaci\u00f3n oficial de Python.</p> <p>El m\u00f3dulo <code>dateutil</code> es una extensi\u00f3n del m\u00f3dulo <code>datetime</code> que proporciona funciones adicionales para trabajar con fechas y horas. Por ejemplo, puedes crear un objeto <code>dateutil.parser.parse()</code> a partir de una cadena de texto que contenga una fecha y hora, y <code>dateutil.relativedelta.relativedelta()</code> para calcular la diferencia entre dos fechas:</p> In\u00a0[4]: Copied! <pre>from dateutil.parser import parse\nfrom dateutil.relativedelta import relativedelta\n</pre> from dateutil.parser import parse from dateutil.relativedelta import relativedelta In\u00a0[5]: Copied! <pre># funcion parse\ndate_string = 'February 17, 2022 3:30 PM'\ndate = parse(date_string)\nprint(date)\n</pre> # funcion parse date_string = 'February 17, 2022 3:30 PM' date = parse(date_string) print(date) <pre>2022-02-17 15:30:00\n</pre> In\u00a0[7]: Copied! <pre># diferencia de fechas\ndate1 = datetime(2022, 2, 17)\ndate2 = datetime(2022, 3, 17)\ndelta = relativedelta(date2, date1)\n\nprint(delta)\nprint(delta.months, delta.days)\n</pre> # diferencia de fechas date1 = datetime(2022, 2, 17) date2 = datetime(2022, 3, 17) delta = relativedelta(date2, date1)  print(delta) print(delta.months, delta.days) <pre>relativedelta(months=+1)\n1 0\n</pre> <p>Estos son solo algunos ejemplos de c\u00f3mo puedes trabajar con fechas y horas en Python utilizando los m\u00f3dulos <code>datetime</code> y <code>dateutil</code>. Hay muchas m\u00e1s funciones disponibles en estos m\u00f3dulos que pueden ayudarte a trabajar con fechas y horas de manera m\u00e1s avanzada.</p> In\u00a0[8]: Copied! <pre>import numpy as np\n\ndate_string = '2022-02-17'\ndate = np.datetime64(date_string)\nprint(date)\n</pre> import numpy as np  date_string = '2022-02-17' date = np.datetime64(date_string) print(date) <pre>2022-02-17\n</pre> <p>Puedes crear un rango de fechas usando la funci\u00f3n <code>numpy.arange()</code> con un paso de tiempo de <code>datetime64</code>:</p> In\u00a0[9]: Copied! <pre>dates = np.arange('2022-02', '2022-03', dtype='datetime64[D]')\nprint(dates)\n</pre> dates = np.arange('2022-02', '2022-03', dtype='datetime64[D]') print(dates) <pre>['2022-02-01' '2022-02-02' '2022-02-03' '2022-02-04' '2022-02-05'\n '2022-02-06' '2022-02-07' '2022-02-08' '2022-02-09' '2022-02-10'\n '2022-02-11' '2022-02-12' '2022-02-13' '2022-02-14' '2022-02-15'\n '2022-02-16' '2022-02-17' '2022-02-18' '2022-02-19' '2022-02-20'\n '2022-02-21' '2022-02-22' '2022-02-23' '2022-02-24' '2022-02-25'\n '2022-02-26' '2022-02-27' '2022-02-28']\n</pre> <p>Tambi\u00e9n puedes realizar operaciones aritm\u00e9ticas en objetos <code>datetime64</code>, como agregar d\u00edas, meses o a\u00f1os. Por ejemplo:</p> In\u00a0[10]: Copied! <pre>dates = np.array(['2022-02-17', '2022-02-18', '2022-02-19'], dtype='datetime64')\nnew_dates = dates + np.timedelta64(1, 'D')\nprint(new_dates)\n</pre> dates = np.array(['2022-02-17', '2022-02-18', '2022-02-19'], dtype='datetime64') new_dates = dates + np.timedelta64(1, 'D') print(new_dates) <pre>['2022-02-18' '2022-02-19' '2022-02-20']\n</pre> <p>Adem\u00e1s, NumPy proporciona funciones para realizar c\u00e1lculos de fechas y horas, como <code>numpy.busday_count()</code>, que calcula el n\u00famero de d\u00edas h\u00e1biles entre dos fechas. Por ejemplo:</p> In\u00a0[11]: Copied! <pre>start_date = np.datetime64('2022-02-15')\nend_date = np.datetime64('2022-02-20')\ncount = np.busday_count(start_date, end_date)\nprint(count)\n</pre> start_date = np.datetime64('2022-02-15') end_date = np.datetime64('2022-02-20') count = np.busday_count(start_date, end_date) print(count) <pre>4\n</pre> <p>Estos son solo algunos ejemplos de c\u00f3mo puedes trabajar con fechas y horas en NumPy utilizando el tipo de datos <code>datetime64</code>. NumPy tambi\u00e9n proporciona muchas m\u00e1s funciones \u00fatiles para trabajar con datos de tiempo de manera eficiente.</p> In\u00a0[12]: Copied! <pre>import pandas as pd\n\ndate_string = '2022-02-17'\ndate = pd.to_datetime(date_string)\nprint(date)\n</pre> import pandas as pd  date_string = '2022-02-17' date = pd.to_datetime(date_string) print(date) <pre>2022-02-17 00:00:00\n</pre> <p>La clase <code>DatetimeIndex</code> es una estructura de datos que contiene una serie de fechas y horas. Puedes crear un objeto <code>DatetimeIndex</code> a partir de una lista o un rango de fechas usando la funci\u00f3n <code>pandas.date_range()</code>:</p> In\u00a0[13]: Copied! <pre>dates = pd.date_range('2022-02-01', '2022-02-28')\nprint(dates)\n</pre> dates = pd.date_range('2022-02-01', '2022-02-28') print(dates) <pre>DatetimeIndex(['2022-02-01', '2022-02-02', '2022-02-03', '2022-02-04',\n               '2022-02-05', '2022-02-06', '2022-02-07', '2022-02-08',\n               '2022-02-09', '2022-02-10', '2022-02-11', '2022-02-12',\n               '2022-02-13', '2022-02-14', '2022-02-15', '2022-02-16',\n               '2022-02-17', '2022-02-18', '2022-02-19', '2022-02-20',\n               '2022-02-21', '2022-02-22', '2022-02-23', '2022-02-24',\n               '2022-02-25', '2022-02-26', '2022-02-27', '2022-02-28'],\n              dtype='datetime64[ns]', freq='D')\n</pre> <p>La clase <code>Period</code> representa un per\u00edodo de tiempo, como un mes o un trimestre. Puedes crear un objeto <code>Period</code> a partir de una cadena de texto que contenga un per\u00edodo de tiempo usando la funci\u00f3n <code>pandas.Period()</code>:</p> In\u00a0[14]: Copied! <pre>month_string = '2022-02'\nmonth = pd.Period(month_string, freq='M')\nprint(month)\n</pre> month_string = '2022-02' month = pd.Period(month_string, freq='M') print(month) <pre>2022-02\n</pre> <p>Pandas tambi\u00e9n proporciona muchas funciones para trabajar con fechas y horas. Por ejemplo, puedes seleccionar filas de un dataframe por fecha y hora utilizando el m\u00e9todo <code>loc[]</code> y especificando una condici\u00f3n booleana:</p> In\u00a0[15]: Copied! <pre>data = {'date': pd.date_range('2022-02-01', '2022-02-28'), 'value': range(28)}\ndf = pd.DataFrame(data)\ndf.set_index('date', inplace=True)\nselected = df.loc['2022-02-17':'2022-02-20']\nselected\n</pre> data = {'date': pd.date_range('2022-02-01', '2022-02-28'), 'value': range(28)} df = pd.DataFrame(data) df.set_index('date', inplace=True) selected = df.loc['2022-02-17':'2022-02-20'] selected Out[15]: value date 2022-02-17 16 2022-02-18 17 2022-02-19 18 2022-02-20 19 <p>Tambi\u00e9n puedes realizar operaciones aritm\u00e9ticas en objetos <code>Timestamp</code>, <code>DatetimeIndex</code> y <code>Period</code>. Por ejemplo, puedes agregar d\u00edas, meses o a\u00f1os a un objeto <code>Timestamp</code> usando el m\u00e9todo <code>Timestamp + pd.Timedelta()</code>:</p> In\u00a0[16]: Copied! <pre>date = pd.to_datetime('2022-02-17')\nnew_date = date + pd.Timedelta(days=1)\nprint(new_date)\n</pre> date = pd.to_datetime('2022-02-17') new_date = date + pd.Timedelta(days=1) print(new_date) <pre>2022-02-18 00:00:00\n</pre> <p>Estos son solo algunos ejemplos de c\u00f3mo puedes trabajar con fechas y horas en Pandas utilizando las clases <code>Timestamp</code>, <code>DatetimeIndex</code> y <code>Period</code>. Pandas tambi\u00e9n proporciona muchas m\u00e1s funciones \u00fatiles para trabajar con datos de tiempo de manera eficiente.</p>"},{"location":"pandas/026_fechas/#manipulacion-de-fechas","title":"Manipulaci\u00f3n de Fechas\u00b6","text":"<p>Pandas se desarroll\u00f3 en el contexto del modelado financiero, por lo que, contiene varias herramientas para trabajar con fechas, horas y datos indexados por tiempo.</p> <p>Comenzaremos por entendender las herramientas para manejar fechas y horas en Python, antes de pasar m\u00e1s espec\u00edficamente a las herramientas proporcionadas por Pandas.</p>"},{"location":"pandas/026_fechas/#fechas-y-horas-python","title":"Fechas y horas Python\u00b6","text":"<p>Python tiene dos m\u00f3dulos integrados para trabajar con fechas y horas: <code>datetime</code> y <code>dateutil</code>.</p> <p>El m\u00f3dulo <code>datetime</code> proporciona clases para trabajar con fechas y horas. La clase principal es <code>datetime.datetime</code>, que combina una fecha y una hora. Por ejemplo, puedes crear un objeto <code>datetime.datetime</code> con la fecha y hora actual usando la funci\u00f3n <code>now()</code>:</p>"},{"location":"pandas/026_fechas/#fechas-y-horas-numpy","title":"Fechas y horas Numpy\u00b6","text":"<p>NumPy es una librer\u00eda de Python que se enfoca en el procesamiento de matrices y arreglos num\u00e9ricos. El tipo de datos <code>datetime64</code> de NumPy permite trabajar con datos de tiempo de manera m\u00e1s eficiente que con las clases <code>datetime</code> y <code>dateutil</code>.</p> <p>El tipo de datos <code>datetime64</code> es un tipo de datos de fecha y hora nativo de NumPy. <code>datetime64</code> representa fechas y horas como enteros de 64 bits, donde el n\u00famero entero representa un n\u00famero de nanosegundos desde el 1 de enero de 1970. Puedes crear un arreglo <code>datetime64</code> a partir de una cadena de texto que contenga una fecha y hora usando la funci\u00f3n <code>numpy.datetime64()</code>:</p>"},{"location":"pandas/026_fechas/#fechas-y-horas-pandas","title":"Fechas y horas Pandas\u00b6","text":"<p>Pandas tiene una amplia variedad de herramientas para trabajar con fechas y horas, incluyendo las clases <code>Timestamp</code>, <code>DatetimeIndex</code>, y <code>Period</code>.</p> <p>La clase <code>Timestamp</code> representa una sola fecha y hora. Puedes crear un objeto <code>Timestamp</code> a partir de una cadena de texto que contenga una fecha y hora usando la funci\u00f3n <code>pandas.to_datetime()</code>:</p>"},{"location":"pandas/027_ejemplo_practico/","title":"Ejemplo Pr\u00e1ctico 01","text":"In\u00a0[1]: Copied! <pre># load data\nimport pandas as pd\npath =  \"https://raw.githubusercontent.com/fralfaro/python_data_manipulation/main/docs/pandas/data/player_data.csv\"\nplayer_data = pd.read_csv(\n    path, # path\n    sep=\",\" # separation\n)\nplayer_data\n</pre> # load data import pandas as pd path =  \"https://raw.githubusercontent.com/fralfaro/python_data_manipulation/main/docs/pandas/data/player_data.csv\" player_data = pd.read_csv(     path, # path     sep=\",\" # separation ) player_data Out[1]: name year_start year_end position height weight birth_date college 0 Alaa Abdelnaby 1991 1995 F-C 6-10 240.0 June 24, 1968 Duke University 1 Zaid Abdul-Aziz 1969 1978 C-F 6-9 235.0 April 7, 1946 Iowa State University 2 Kareem Abdul-Jabbar 1970 1989 C 7-2 225.0 April 16, 1947 University of California, Los Angeles 3 Mahmoud Abdul-Rauf 1991 2001 G 6-1 162.0 March 9, 1969 Louisiana State University 4 Tariq Abdul-Wahad 1998 2003 F 6-6 223.0 November 3, 1974 San Jose State University ... ... ... ... ... ... ... ... ... 4545 Ante Zizic 2018 2018 F-C 6-11 250.0 January 4, 1997 NaN 4546 Jim Zoet 1983 1983 C 7-1 240.0 December 20, 1953 Kent State University 4547 Bill Zopf 1971 1971 G 6-1 170.0 June 7, 1948 Duquesne University 4548 Ivica Zubac 2017 2018 C 7-1 265.0 March 18, 1997 NaN 4549 Matt Zunic 1949 1949 G-F 6-3 195.0 December 19, 1919 George Washington University <p>4550 rows \u00d7 8 columns</p> In\u00a0[2]: Copied! <pre># primeras silas\nprint(\"first 5 rows:\")\nplayer_data.head(5)\n</pre> # primeras silas print(\"first 5 rows:\") player_data.head(5) <pre>first 5 rows:\n</pre> Out[2]: name year_start year_end position height weight birth_date college 0 Alaa Abdelnaby 1991 1995 F-C 6-10 240.0 June 24, 1968 Duke University 1 Zaid Abdul-Aziz 1969 1978 C-F 6-9 235.0 April 7, 1946 Iowa State University 2 Kareem Abdul-Jabbar 1970 1989 C 7-2 225.0 April 16, 1947 University of California, Los Angeles 3 Mahmoud Abdul-Rauf 1991 2001 G 6-1 162.0 March 9, 1969 Louisiana State University 4 Tariq Abdul-Wahad 1998 2003 F 6-6 223.0 November 3, 1974 San Jose State University In\u00a0[3]: Copied! <pre># ultimas filas\nprint(\"\\nlast 5 rows:\")\nplayer_data.tail(5)\n</pre> # ultimas filas print(\"\\nlast 5 rows:\") player_data.tail(5) <pre>\nlast 5 rows:\n</pre> Out[3]: name year_start year_end position height weight birth_date college 4545 Ante Zizic 2018 2018 F-C 6-11 250.0 January 4, 1997 NaN 4546 Jim Zoet 1983 1983 C 7-1 240.0 December 20, 1953 Kent State University 4547 Bill Zopf 1971 1971 G 6-1 170.0 June 7, 1948 Duquesne University 4548 Ivica Zubac 2017 2018 C 7-1 265.0 March 18, 1997 NaN 4549 Matt Zunic 1949 1949 G-F 6-3 195.0 December 19, 1919 George Washington University In\u00a0[4]: Copied! <pre># tipo\nprint(\"\\ntype of dataframe:\")\ntype(player_data)\n</pre> # tipo print(\"\\ntype of dataframe:\") type(player_data) <pre>\ntype of dataframe:\n</pre> Out[4]: <pre>pandas.core.frame.DataFrame</pre> In\u00a0[5]: Copied! <pre># tipo por columnas\nprint(\"\\ntype of columns:\")\nplayer_data.dtypes\n</pre> # tipo por columnas print(\"\\ntype of columns:\") player_data.dtypes <pre>\ntype of columns:\n</pre> Out[5]: <pre>name           object\nyear_start      int64\nyear_end        int64\nposition       object\nheight         object\nweight        float64\nbirth_date     object\ncollege        object\ndtype: object</pre> In\u00a0[6]: Copied! <pre># dimension\nprint(\"\\nshape:\")\nplayer_data.shape\n</pre> # dimension print(\"\\nshape:\") player_data.shape <pre>\nshape:\n</pre> Out[6]: <pre>(4550, 8)</pre> In\u00a0[7]: Copied! <pre># nombre de las columnas\nprint(\"\\ncols:\")\nplayer_data.columns\n</pre> # nombre de las columnas print(\"\\ncols:\") player_data.columns <pre>\ncols:\n</pre> Out[7]: <pre>Index(['name', 'year_start', 'year_end', 'position', 'height', 'weight',\n       'birth_date', 'college'],\n      dtype='object')</pre> In\u00a0[8]: Copied! <pre># indice\nprint(\"\\nindex:\")\nplayer_data.index\n</pre> # indice print(\"\\nindex:\") player_data.index <pre>\nindex:\n</pre> Out[8]: <pre>RangeIndex(start=0, stop=4550, step=1)</pre> In\u00a0[9]: Copied! <pre># acceder a la columna posicion\nprint(\"\\ncolumn 'position': \")\nplayer_data['position'].head()\n</pre> # acceder a la columna posicion print(\"\\ncolumn 'position': \") player_data['position'].head() <pre>\ncolumn 'position': \n</pre> Out[9]: <pre>0    F-C\n1    C-F\n2      C\n3      G\n4      F\nName: position, dtype: object</pre> In\u00a0[10]: Copied! <pre># cambiar nombre de una o varias columnas\nplayer_data = player_data.rename(columns={\"birth_date\": \"Birth\", \"college\": \"College\"})\nplayer_data.head()\n</pre> # cambiar nombre de una o varias columnas player_data = player_data.rename(columns={\"birth_date\": \"Birth\", \"college\": \"College\"}) player_data.head() Out[10]: name year_start year_end position height weight Birth College 0 Alaa Abdelnaby 1991 1995 F-C 6-10 240.0 June 24, 1968 Duke University 1 Zaid Abdul-Aziz 1969 1978 C-F 6-9 235.0 April 7, 1946 Iowa State University 2 Kareem Abdul-Jabbar 1970 1989 C 7-2 225.0 April 16, 1947 University of California, Los Angeles 3 Mahmoud Abdul-Rauf 1991 2001 G 6-1 162.0 March 9, 1969 Louisiana State University 4 Tariq Abdul-Wahad 1998 2003 F 6-6 223.0 November 3, 1974 San Jose State University In\u00a0[11]: Copied! <pre># fijar columna especifica como indice\nplayer_data = player_data.set_index([\"name\"])\nplayer_data.head()\n</pre> # fijar columna especifica como indice player_data = player_data.set_index([\"name\"]) player_data.head() Out[11]: year_start year_end position height weight Birth College name Alaa Abdelnaby 1991 1995 F-C 6-10 240.0 June 24, 1968 Duke University Zaid Abdul-Aziz 1969 1978 C-F 6-9 235.0 April 7, 1946 Iowa State University Kareem Abdul-Jabbar 1970 1989 C 7-2 225.0 April 16, 1947 University of California, Los Angeles Mahmoud Abdul-Rauf 1991 2001 G 6-1 162.0 March 9, 1969 Louisiana State University Tariq Abdul-Wahad 1998 2003 F 6-6 223.0 November 3, 1974 San Jose State University In\u00a0[12]: Copied! <pre># ordenar dataframe por columna especifica\nplayer_data = player_data.sort_values(\"weight\")\nplayer_data.head()\n</pre> # ordenar dataframe por columna especifica player_data = player_data.sort_values(\"weight\") player_data.head() Out[12]: year_start year_end position height weight Birth College name Penny Early 1969 1969 G 5-3 114.0 May 30, 1943 NaN Spud Webb 1986 1998 G 5-6 133.0 July 13, 1963 North Carolina State University Earl Boykins 1999 2012 G 5-5 135.0 June 2, 1976 Eastern Michigan University Muggsy Bogues 1988 2001 G 5-3 136.0 January 9, 1965 Wake Forest University Chet Aubuchon 1947 1947 G 5-10 137.0 May 18, 1916 Michigan State University In\u00a0[13]: Copied! <pre># resumen de la informaci\u00f3n \nplayer_data.describe(include='all')# player_data.describe()\n</pre> # resumen de la informaci\u00f3n  player_data.describe(include='all')# player_data.describe() Out[13]: year_start year_end position height weight Birth College count 4550.000000 4550.000000 4549 4549 4544.000000 4519 4248 unique NaN NaN 7 28 NaN 4161 473 top NaN NaN G 6-7 NaN February 23, 1945 University of Kentucky freq NaN NaN 1574 473 NaN 3 99 mean 1985.076264 1989.272527 NaN NaN 208.908011 NaN NaN std 20.974188 21.874761 NaN NaN 26.268662 NaN NaN min 1947.000000 1947.000000 NaN NaN 114.000000 NaN NaN 25% 1969.000000 1973.000000 NaN NaN 190.000000 NaN NaN 50% 1986.000000 1992.000000 NaN NaN 210.000000 NaN NaN 75% 2003.000000 2009.000000 NaN NaN 225.000000 NaN NaN max 2018.000000 2018.000000 NaN NaN 360.000000 NaN NaN <p>a) Determine si el dataframe tiene valores nulos</p> In\u00a0[14]: Copied! <pre># veamos las columnas con datos nulos\nfor col in player_data.columns:\n   \n    temp = player_data[player_data[col].isnull()]\n    print(col)\n    print(f\"valores nulos: {len(temp)}\\n\")\n</pre> # veamos las columnas con datos nulos for col in player_data.columns:         temp = player_data[player_data[col].isnull()]     print(col)     print(f\"valores nulos: {len(temp)}\\n\") <pre>year_start\nvalores nulos: 0\n\nyear_end\nvalores nulos: 0\n\nposition\nvalores nulos: 1\n\nheight\nvalores nulos: 1\n\nweight\nvalores nulos: 6\n\nBirth\nvalores nulos: 31\n\nCollege\nvalores nulos: 302\n\n</pre> In\u00a0[15]: Copied! <pre># ocupar comando .notnull().all(axis=1) para ver todos los valores que NO son nulos para todas las columnas\nplayer_data.notnull().all(axis=1).head(10)\n</pre> # ocupar comando .notnull().all(axis=1) para ver todos los valores que NO son nulos para todas las columnas player_data.notnull().all(axis=1).head(10) Out[15]: <pre>name\nPenny Early        False\nSpud Webb           True\nEarl Boykins        True\nMuggsy Bogues       True\nChet Aubuchon       True\nGreg Grant          True\nAngelo Musi         True\nErnie Calverley     True\nTyler Ulis          True\nLionel Malamed      True\ndtype: bool</pre> <p>b) Elimine los valores nulos del dataframe</p> In\u00a0[16]: Copied! <pre># ocupar masking\nmask = lambda df: df.notnull().all(axis=1)\nplayer_data = player_data[mask]\nplayer_data.head()\n</pre> # ocupar masking mask = lambda df: df.notnull().all(axis=1) player_data = player_data[mask] player_data.head() Out[16]: year_start year_end position height weight Birth College name Spud Webb 1986 1998 G 5-6 133.0 July 13, 1963 North Carolina State University Earl Boykins 1999 2012 G 5-5 135.0 June 2, 1976 Eastern Michigan University Muggsy Bogues 1988 2001 G 5-3 136.0 January 9, 1965 Wake Forest University Chet Aubuchon 1947 1947 G 5-10 137.0 May 18, 1916 Michigan State University Greg Grant 1990 1996 G 5-7 140.0 August 29, 1966 Trenton State University <p>c) Determinar el tiempo (en a\u00f1os) de cada jugador en su posici\u00f3n</p> In\u00a0[17]: Copied! <pre>player_data['duration'] = player_data['year_end'] - player_data['year_start']\nplayer_data.head()\n</pre> player_data['duration'] = player_data['year_end'] - player_data['year_start'] player_data.head() Out[17]: year_start year_end position height weight Birth College duration name Spud Webb 1986 1998 G 5-6 133.0 July 13, 1963 North Carolina State University 12 Earl Boykins 1999 2012 G 5-5 135.0 June 2, 1976 Eastern Michigan University 13 Muggsy Bogues 1988 2001 G 5-3 136.0 January 9, 1965 Wake Forest University 13 Chet Aubuchon 1947 1947 G 5-10 137.0 May 18, 1916 Michigan State University 0 Greg Grant 1990 1996 G 5-7 140.0 August 29, 1966 Trenton State University 6 <p>d) Fecha de <code>str</code> a objeto <code>datetime</code></p> In\u00a0[18]: Copied! <pre>player_data['birth_date_dt'] = pd.to_datetime(player_data['Birth'], format=\"%B %d, %Y\")\nplayer_data.head()\n</pre> player_data['birth_date_dt'] = pd.to_datetime(player_data['Birth'], format=\"%B %d, %Y\") player_data.head() Out[18]: year_start year_end position height weight Birth College duration birth_date_dt name Spud Webb 1986 1998 G 5-6 133.0 July 13, 1963 North Carolina State University 12 1963-07-13 Earl Boykins 1999 2012 G 5-5 135.0 June 2, 1976 Eastern Michigan University 13 1976-06-02 Muggsy Bogues 1988 2001 G 5-3 136.0 January 9, 1965 Wake Forest University 13 1965-01-09 Chet Aubuchon 1947 1947 G 5-10 137.0 May 18, 1916 Michigan State University 0 1916-05-18 Greg Grant 1990 1996 G 5-7 140.0 August 29, 1966 Trenton State University 6 1966-08-29 <p>e) Determinar todas las posiciones</p> In\u00a0[19]: Copied! <pre>positions = player_data['position'].unique()\npositions\n</pre> positions = player_data['position'].unique() positions Out[19]: <pre>array(['G', 'G-F', 'F-G', 'F', 'F-C', 'C-F', 'C'], dtype=object)</pre> <p>f) Iterar sobre cada posici\u00f3n y encontrar el mayor valor de la columna <code>weight</code></p> In\u00a0[20]: Copied! <pre># Iterar sobre cada posici\u00f3n y encontrar el mayor valor.\nnba_position_duration = dict()\n\n# iterar\nfor position in positions:\n    \n    # filtrar \n    df_aux = player_data.loc[lambda x: x['position'] == position]\n    \n    # encontrar maximo de la columna objetivo\n    max_duration = df_aux['weight'].max()\n    \n    # guardar en pd.Series\n    nba_position_duration[position] = max_duration\n    \n# retornar serie\nnba_position_duration\n</pre> # Iterar sobre cada posici\u00f3n y encontrar el mayor valor. nba_position_duration = dict()  # iterar for position in positions:          # filtrar      df_aux = player_data.loc[lambda x: x['position'] == position]          # encontrar maximo de la columna objetivo     max_duration = df_aux['weight'].max()          # guardar en pd.Series     nba_position_duration[position] = max_duration      # retornar serie nba_position_duration Out[20]: <pre>{'G': 235.0,\n 'G-F': 240.0,\n 'F-G': 245.0,\n 'F': 284.0,\n 'F-C': 290.0,\n 'C-F': 280.0,\n 'C': 360.0}</pre>"},{"location":"pandas/027_ejemplo_practico/#ejemplo-practico-01","title":"Ejemplo Pr\u00e1ctico 01\u00b6","text":""},{"location":"pandas/027_ejemplo_practico/#descripcion-del-conjunto-de-datos","title":"Descripci\u00f3n del conjunto de datos\u00b6","text":""},{"location":"pandas/027_ejemplo_practico/#introduccion","title":"Introducci\u00f3n\u00b6","text":"<p>A continuaci\u00f3n analizaremos el conjunto de datos denominado player_data.csv, el cual contiene informaci\u00f3n b\u00e1sica de los jugadores de la NBA.</p>"},{"location":"pandas/027_ejemplo_practico/#descripcion-de-las-columnas","title":"Descripci\u00f3n de las Columnas\u00b6","text":"<p>| columna    \t| tipo    \t| descripci\u00f3n                          \t| |------------\t|---------\t|--------------------------------------\t| | name       \t| object  \t| nombre del jugador                   \t| | year_start \t| int64   \t| a\u00f1o de inicio de carrera en la NBA   \t| | year_end   \t| int64   \t| a\u00f1o de t\u00e9rmino de carrera en la NBA  \t| | position   \t| object  \t| posici\u00f3n del jugador                 \t| | height     \t| object  \t| altura del jugador                   \t| | weight     \t| float64 \t| peso del jugador                     \t| | birth_date \t| object  \t| fecha de nacimiento                  \t| | college    \t| object  \t| universidad antes de entrar a la NBA \t|</p>"},{"location":"pandas/027_ejemplo_practico/#resolucion-del-problema","title":"Resoluci\u00f3n del Problema\u00b6","text":""},{"location":"pandas/027_ejemplo_practico/#modulos-basicos","title":"M\u00f3dulos B\u00e1sicos\u00b6","text":"<p>Existen m\u00f3dulos para comprender r\u00e1pidamente la naturaleza del dataframe.</p>"},{"location":"pandas/027_ejemplo_practico/#modulos-avanzados","title":"M\u00f3dulos Avanzados\u00b6","text":"<p>Cuando se trabaja con un conjunto de datos, se crea una din\u00e1mica de preguntas y respuestas, en donde a medida que necesito informaci\u00f3n, se va accediendo al dataframe. En algunas ocaciones es directo, basta un simple m\u00f3dulo, aunque en otras ser\u00e1 necesaria realizar operaciones un poco m\u00e1s complejas.</p> <p>Por ejemplo, del conjunto de datos en estudio, se esta interesado en responder las siguientes preguntas:</p>"},{"location":"pandas/031_groupby/","title":"Groupby","text":"In\u00a0[24]: Copied! <pre>import pandas as pd\n\n# Crear un DataFrame de ejemplo\ndatos = {\n    'Producto': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'], \n    'Mes': ['Enero', 'Enero','Enero', 'Enero', 'Febrero', 'Febrero','Febrero', 'Febrero'], \n    'Ventas': [100, 200, 150, 250, 300, 350, 400, 450]\n}\ndf = pd.DataFrame(datos).sort_values(['Producto'])\ndf\n</pre> import pandas as pd  # Crear un DataFrame de ejemplo datos = {     'Producto': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],      'Mes': ['Enero', 'Enero','Enero', 'Enero', 'Febrero', 'Febrero','Febrero', 'Febrero'],      'Ventas': [100, 200, 150, 250, 300, 350, 400, 450] } df = pd.DataFrame(datos).sort_values(['Producto']) df Out[24]: Producto Mes Ventas 0 A Enero 100 2 A Enero 150 4 A Febrero 300 6 A Febrero 400 1 B Enero 200 3 B Enero 250 5 B Febrero 350 7 B Febrero 450 In\u00a0[25]: Copied! <pre># Agrupar por Producto y calcular la suma de las ventas en cada grupo\nagrupado = df.groupby('Producto')['Ventas'].sum()\nagrupado\n</pre> # Agrupar por Producto y calcular la suma de las ventas en cada grupo agrupado = df.groupby('Producto')['Ventas'].sum() agrupado Out[25]: <pre>Producto\nA     950\nB    1250\nName: Ventas, dtype: int64</pre> In\u00a0[26]: Copied! <pre># Agrupar por Producto y Mes y calcular la suma de las ventas en cada grupo\nagrupado = df.groupby(['Producto', 'Mes'])['Ventas'].sum()\nagrupado\n</pre> # Agrupar por Producto y Mes y calcular la suma de las ventas en cada grupo agrupado = df.groupby(['Producto', 'Mes'])['Ventas'].sum() agrupado Out[26]: <pre>Producto  Mes    \nA         Enero      250\n          Febrero    700\nB         Enero      450\n          Febrero    800\nName: Ventas, dtype: int64</pre> In\u00a0[27]: Copied! <pre># Agrupar por Producto y Mes y calcular la suma y promedio de las ventas en cada grupo\nagrupado = df.groupby(['Producto', 'Mes']).agg({'Ventas': ['sum', 'mean']})\nagrupado\n</pre> # Agrupar por Producto y Mes y calcular la suma y promedio de las ventas en cada grupo agrupado = df.groupby(['Producto', 'Mes']).agg({'Ventas': ['sum', 'mean']}) agrupado Out[27]: Ventas sum mean Producto Mes A Enero 250 125.0 Febrero 700 350.0 B Enero 450 225.0 Febrero 800 400.0 In\u00a0[28]: Copied! <pre>import pandas as pd\n\ndata = {\n    'Region': ['North', 'North', 'South', 'South', 'East', 'West', 'East', 'West'],\n    'Product': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],\n    'Sales': [100, 200, 150, 250, 120, 180, 110, 190]\n}\n\ndf = pd.DataFrame(data)\ndf\n</pre> import pandas as pd  data = {     'Region': ['North', 'North', 'South', 'South', 'East', 'West', 'East', 'West'],     'Product': ['A', 'B', 'A', 'B', 'A', 'B', 'A', 'B'],     'Sales': [100, 200, 150, 250, 120, 180, 110, 190] }  df = pd.DataFrame(data) df Out[28]: Region Product Sales 0 North A 100 1 North B 200 2 South A 150 3 South B 250 4 East A 120 5 West B 180 6 East A 110 7 West B 190 <p>Podemos usar <code>groupby()</code> para agrupar los datos por regi\u00f3n y aplicar una funci\u00f3n personalizada que calcule el porcentaje de ventas de cada producto en cada regi\u00f3n:</p> In\u00a0[29]: Copied! <pre>def porcentaje_ventas_grupo(grupo):\n    grupo['Porcentaje_Ventas'] = grupo['Sales'] / grupo['Sales'].sum()\n    return grupo\n\ndf.groupby('Region').apply(porcentaje_ventas_grupo)\n</pre> def porcentaje_ventas_grupo(grupo):     grupo['Porcentaje_Ventas'] = grupo['Sales'] / grupo['Sales'].sum()     return grupo  df.groupby('Region').apply(porcentaje_ventas_grupo) Out[29]: Region Product Sales Porcentaje_Ventas 0 North A 100 0.333333 1 North B 200 0.666667 2 South A 150 0.375000 3 South B 250 0.625000 4 East A 120 0.521739 5 West B 180 0.486486 6 East A 110 0.478261 7 West B 190 0.513514 <p>En este ejemplo, hemos definido una funci\u00f3n personalizada <code>porcentaje_ventas_grupo</code> que toma como argumento un grupo de datos y calcula el porcentaje de ventas de cada producto en ese grupo. Despu\u00e9s, hemos aplicado esta funci\u00f3n a cada grupo usando el m\u00e9todo <code>apply()</code>.</p> In\u00a0[31]: Copied! <pre>df['Promedio_Ventas'] = df.groupby('Region')['Sales'].transform('mean')\ndf\n</pre> df['Promedio_Ventas'] = df.groupby('Region')['Sales'].transform('mean') df Out[31]: Region Product Sales Promedio_Ventas 0 North A 100 150.0 1 North B 200 150.0 2 South A 150 200.0 3 South B 250 200.0 4 East A 120 115.0 5 West B 180 185.0 6 East A 110 115.0 7 West B 190 185.0 <p>En este ejemplo, hemos usado el m\u00e9todo <code>transform()</code> para calcular el promedio de ventas de cada producto en cada regi\u00f3n y lo hemos asignado como una nueva columna llamada \"Promedio_Ventas\" en el DataFrame original. La funci\u00f3n de transformaci\u00f3n que hemos usado es <code>mean()</code>, que calcula la media de las ventas en cada grupo.</p> In\u00a0[32]: Copied! <pre>df_filtered = df.groupby('Region').filter(lambda x: x['Sales'].mean() &gt; 150)\ndf_filtered\n</pre> df_filtered = df.groupby('Region').filter(lambda x: x['Sales'].mean() &gt; 150) df_filtered Out[32]: Region Product Sales Promedio_Ventas 2 South A 150 200.0 3 South B 250 200.0 5 West B 180 185.0 7 West B 190 185.0 <p>En este ejemplo, hemos usado la funci\u00f3n lambda lambda x: <code>x['Sales'].mean() &gt; 150</code> como condici\u00f3n para filtrar los grupos. Esta funci\u00f3n lambda devuelve True si el promedio de ventas en el grupo <code>x</code> es mayor que 150 y False en caso contrario. El m\u00e9todo <code>filter()</code> devuelve un nuevo DataFrame que contiene solo las filas de los grupos que cumplen esta condici\u00f3n.</p> <p>Observaci\u00f3n: Para iterar a trav\u00e9s de los grupos generados por el m\u00e9todo <code>groupby()</code> de Pandas, se puede usar un bucle <code>for</code>. En cada iteraci\u00f3n, se obtiene una tupla <code>(nombre_grupo, subconjunto_datos)</code> donde <code>nombre_grupo</code> es el nombre del grupo y <code>subconjunto_datos</code> es un objeto DataFrame que contiene solo las filas que pertenecen a ese grupo.</p> <p>En el ejemplo anterior, podemos agrupar los datos por regi\u00f3n y luego iterar a trav\u00e9s de los grupos usando un bucle <code>for</code>:</p> In\u00a0[33]: Copied! <pre>for region, data in df.groupby('Region'):\n    print(region)\n    print(data)\n    print('--------------')\n</pre> for region, data in df.groupby('Region'):     print(region)     print(data)     print('--------------') <pre>East\n  Region Product  Sales  Promedio_Ventas\n4   East       A    120            115.0\n6   East       A    110            115.0\n--------------\nNorth\n  Region Product  Sales  Promedio_Ventas\n0  North       A    100            150.0\n1  North       B    200            150.0\n--------------\nSouth\n  Region Product  Sales  Promedio_Ventas\n2  South       A    150            200.0\n3  South       B    250            200.0\n--------------\nWest\n  Region Product  Sales  Promedio_Ventas\n5   West       B    180            185.0\n7   West       B    190            185.0\n--------------\n</pre>"},{"location":"pandas/031_groupby/#groupby","title":"Groupby\u00b6","text":"<p>Groupby es un concepto bastante simple. Podemos crear una agrupaci\u00f3n de categor\u00edas y aplicar una funci\u00f3n a las categor\u00edas.</p> <p>El proceso de groupby se puede resumiren los siguientes pasos:</p> <ul> <li>Divisi\u00f3n: es un proceso en el que dividimos los datos en grupos aplicando algunas condiciones en los conjuntos de datos.</li> <li>Aplicaci\u00f3n: es un proceso en el que aplicamos una funci\u00f3n a cada grupo de forma independiente</li> <li>Combinaci\u00f3n: es un proceso en el que combinamos diferentes conjuntos de datos despu\u00e9s de aplicar groupby y resultados en una estructura de datos</li> </ul> <p></p> <p>Despu\u00e9s de dividir los datos en un grupo, aplicamos una funci\u00f3n a cada grupo para realizar algunas operaciones que son:</p> <ul> <li>Agregaci\u00f3n: es un proceso en el que calculamos una estad\u00edstica resumida (o estad\u00edstica) sobre cada grupo. Por ejemplo, Calcular sumas de grupo o medios</li> <li>Transformaci\u00f3n: es un proceso en el que realizamos algunos c\u00e1lculos espec\u00edficos del grupo y devolvemos un \u00edndice similar. Por ejemplo, llenar NA dentro de grupos con un valor derivado de cada grupo</li> <li>Filtraci\u00f3n: es un proceso en el cual descartamos algunos grupos, de acuerdo con un c\u00e1lculo grupal que eval\u00faa Verdadero o Falso. Por ejemplo, Filtrar datos en funci\u00f3n de la suma o media grupal</li> </ul>"},{"location":"pandas/031_groupby/#agrupar-por-una-columna","title":"Agrupar por una columna\u00b6","text":"<p>Supongamos que tenemos un conjunto de datos de ventas de productos y queremos agruparlos por la columna \"Producto\". El siguiente c\u00f3digo nos permitir\u00e1 hacerlo:</p>"},{"location":"pandas/031_groupby/#agrupar-por-varias-columnas","title":"Agrupar por varias columnas\u00b6","text":"<p>En este ejemplo, supongamos que queremos agrupar los datos por dos columnas: \"Producto\" y \"Mes\". El siguiente c\u00f3digo nos permitir\u00e1 hacerlo:</p>"},{"location":"pandas/031_groupby/#aplicar-multiples-funciones-a-cada-grupo","title":"Aplicar m\u00faltiples funciones a cada grupo\u00b6","text":"<p>En este ejemplo, supongamos que queremos calcular la suma y el promedio de las ventas en cada grupo. El siguiente c\u00f3digo nos permitir\u00e1 hacerlo:</p>"},{"location":"pandas/031_groupby/#groupby-apply","title":"Groupby Apply\u00b6","text":"<p>Este m\u00e9todo permite aplicar una funci\u00f3n a cada grupo y devolver un DataFrame con el resultado.</p> <pre>df.groupby(columnas_a_agrupar).apply(funcion)\n</pre> <p>Supongamos que tenemos un DataFrame con informaci\u00f3n sobre ventas de diferentes productos en diferentes regiones:</p>"},{"location":"pandas/031_groupby/#groupby-transform","title":"Groupby Transform\u00b6","text":"<p>En pandas, el m\u00e9todo <code>transform()</code> permite aplicar una funci\u00f3n de transformaci\u00f3n a cada grupo de un objeto groupby. La funci\u00f3n de transformaci\u00f3n se aplica a cada grupo y el resultado se asigna de vuelta a las filas correspondientes en el DataFrame original.</p> <p>Para el ejemplo anterior, podemos usar <code>groupby()</code> para agrupar los datos por regi\u00f3n y aplicar una funci\u00f3n de transformaci\u00f3n que calcule el promedio de ventas de cada producto en cada regi\u00f3n y lo a\u00f1ada como una nueva columna en el DataFrame original:</p>"},{"location":"pandas/031_groupby/#groupby-filter","title":"Groupby Filter\u00b6","text":"<p>En pandas, el m\u00e9todo <code>groupby()</code> se puede combinar con el m\u00e9todo <code>filter()</code> para filtrar filas de un DataFrame seg\u00fan ciertas condiciones aplicadas a los grupos de un objeto groupby. <code>filter()</code> devuelve un nuevo DataFrame que contiene las filas que cumplen las condiciones especificadas para cada grupo.</p> <p>Para el ejemplo anterior, podemos usar <code>groupby()</code> para agrupar los datos por regi\u00f3n y luego usar <code>filter()</code> para seleccionar los grupos que tienen un promedio de ventas mayor que 150:</p>"},{"location":"pandas/032_merge_concat/","title":"Merge y Concat","text":"In\u00a0[1]: Copied! <pre>from IPython.display import display_html\n\ndef display_side_by_side(*args):\n    html_str = ''\n    for df in args:\n        html_str += df.to_html()\n        html_str += '&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;'\n    display_html(\n        html_str.replace('table','table style=\"display:inline\"'), \n        raw=True\n    )\n</pre> from IPython.display import display_html  def display_side_by_side(*args):     html_str = ''     for df in args:         html_str += df.to_html()         html_str += '\u00a0\u00a0\u00a0\u00a0'     display_html(         html_str.replace('table','table style=\"display:inline\"'),          raw=True     ) In\u00a0[2]: Copied! <pre>import pandas as pd\n\ndf1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\ndf2 = pd.DataFrame({'A': [7, 8, 9], 'B': [10, 11, 12]})\n\nresult = pd.concat([df1, df2])\ndisplay_side_by_side(df1,df2,result)\n</pre> import pandas as pd  df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}) df2 = pd.DataFrame({'A': [7, 8, 9], 'B': [10, 11, 12]})  result = pd.concat([df1, df2]) display_side_by_side(df1,df2,result) A B 0 1 4 1 2 5 2 3 6 A B 0 7 10 1 8 11 2 9 12 A B 0 1 4 1 2 5 2 3 6 0 7 10 1 8 11 2 9 12 In\u00a0[3]: Copied! <pre>import pandas as pd\n\ndf1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\ndf2 = pd.DataFrame({'C': [7, 8, 9], 'D': [10, 11, 12]})\n\nresult = pd.concat([df1, df2], axis=1)\ndisplay_side_by_side(df1,df2,result)\n</pre> import pandas as pd  df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}) df2 = pd.DataFrame({'C': [7, 8, 9], 'D': [10, 11, 12]})  result = pd.concat([df1, df2], axis=1) display_side_by_side(df1,df2,result) A B 0 1 4 1 2 5 2 3 6 C D 0 7 10 1 8 11 2 9 12 A B C D 0 1 4 7 10 1 2 5 8 11 2 3 6 9 12 In\u00a0[4]: Copied! <pre>import pandas as pd\n\ndf1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\ndf2 = pd.DataFrame({'A': [7, 8, 9], 'C': [10, 11, 12]})\n\nresult = pd.concat([df1, df2])\ndisplay_side_by_side(df1,df2,result)\n</pre> import pandas as pd  df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}) df2 = pd.DataFrame({'A': [7, 8, 9], 'C': [10, 11, 12]})  result = pd.concat([df1, df2]) display_side_by_side(df1,df2,result) A B 0 1 4 1 2 5 2 3 6 A C 0 7 10 1 8 11 2 9 12 A B C 0 1 4.0 NaN 1 2 5.0 NaN 2 3 6.0 NaN 0 7 NaN 10.0 1 8 NaN 11.0 2 9 NaN 12.0 In\u00a0[5]: Copied! <pre>import pandas as pd\n\ndf1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}, index=[0, 1, 2])\ndf2 = pd.DataFrame({'A': [7, 8, 9], 'B': [10, 11, 12]}, index=[3, 4, 5])\n\nresult = pd.concat([df1, df2])\ndisplay_side_by_side(df1,df2,result)\n</pre> import pandas as pd  df1 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]}, index=[0, 1, 2]) df2 = pd.DataFrame({'A': [7, 8, 9], 'B': [10, 11, 12]}, index=[3, 4, 5])  result = pd.concat([df1, df2]) display_side_by_side(df1,df2,result) A B 0 1 4 1 2 5 2 3 6 A B 3 7 10 4 8 11 5 9 12 A B 0 1 4 1 2 5 2 3 6 3 7 10 4 8 11 5 9 12 In\u00a0[6]: Copied! <pre>import pandas as pd\n\nleft = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n                     'A': ['A0', 'A1', 'A2', 'A3'],\n                     'B': ['B0', 'B1', 'B2', 'B3']})\n\n\nright = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n                      'C': ['C0', 'C1', 'C2', 'C3'],\n                      'D': ['D0', 'D1', 'D2', 'D3']})\n\nresult = pd.merge(left, right, on='key')\ndisplay_side_by_side(left,right,result)\n</pre> import pandas as pd  left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],                      'A': ['A0', 'A1', 'A2', 'A3'],                      'B': ['B0', 'B1', 'B2', 'B3']})   right = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],                       'C': ['C0', 'C1', 'C2', 'C3'],                       'D': ['D0', 'D1', 'D2', 'D3']})  result = pd.merge(left, right, on='key') display_side_by_side(left,right,result) key A B 0 K0 A0 B0 1 K1 A1 B1 2 K2 A2 B2 3 K3 A3 B3 key C D 0 K0 C0 D0 1 K1 C1 D1 2 K2 C2 D2 3 K3 C3 D3 key A B C D 0 K0 A0 B0 C0 D0 1 K1 A1 B1 C1 D1 2 K2 A2 B2 C2 D2 3 K3 A3 B3 C3 D3 In\u00a0[7]: Copied! <pre>import pandas as pd\n\nleft = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],\n                     'A': ['A0', 'A1', 'A2', 'A3'],\n                     'B': ['B0', 'B1', 'B2', 'B3']})\n\n\nright = pd.DataFrame({'key': ['K0', 'K0', 'K2', 'K3'],\n                      'C': ['C0', 'C1', 'C2', 'C3'],\n                      'D': ['D0', 'D1', 'D2', 'D3']})\n\nresult = pd.merge(left, right, on='key')\ndisplay_side_by_side(left,right,result)\n</pre> import pandas as pd  left = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3'],                      'A': ['A0', 'A1', 'A2', 'A3'],                      'B': ['B0', 'B1', 'B2', 'B3']})   right = pd.DataFrame({'key': ['K0', 'K0', 'K2', 'K3'],                       'C': ['C0', 'C1', 'C2', 'C3'],                       'D': ['D0', 'D1', 'D2', 'D3']})  result = pd.merge(left, right, on='key') display_side_by_side(left,right,result) key A B 0 K0 A0 B0 1 K1 A1 B1 2 K2 A2 B2 3 K3 A3 B3 key C D 0 K0 C0 D0 1 K0 C1 D1 2 K2 C2 D2 3 K3 C3 D3 key A B C D 0 K0 A0 B0 C0 D0 1 K0 A0 B0 C1 D1 2 K2 A2 B2 C2 D2 3 K3 A3 B3 C3 D3 In\u00a0[8]: Copied! <pre>import pandas as pd\n\nleft = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n                     'key2': ['K0', 'K1', 'K0', 'K1'],\n                     'A': ['A0', 'A1', 'A2', 'A3'],\n                     'B': ['B0', 'B1', 'B2', 'B3']})\n\n\nright = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n                     'key2': ['K0', 'K1', 'K0', 'K1'],\n                      'C': ['C0', 'C1', 'C2', 'C3'],\n                      'D': ['D0', 'D1', 'D2', 'D3']})\n\nresult = pd.merge(left, right, on=['key1', 'key2'])\ndisplay_side_by_side(left,right,result)\n</pre> import pandas as pd  left = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],                      'key2': ['K0', 'K1', 'K0', 'K1'],                      'A': ['A0', 'A1', 'A2', 'A3'],                      'B': ['B0', 'B1', 'B2', 'B3']})   right = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],                      'key2': ['K0', 'K1', 'K0', 'K1'],                       'C': ['C0', 'C1', 'C2', 'C3'],                       'D': ['D0', 'D1', 'D2', 'D3']})  result = pd.merge(left, right, on=['key1', 'key2']) display_side_by_side(left,right,result) key1 key2 A B 0 K0 K0 A0 B0 1 K0 K1 A1 B1 2 K1 K0 A2 B2 3 K2 K1 A3 B3 key1 key2 C D 0 K0 K0 C0 D0 1 K0 K1 C1 D1 2 K1 K0 C2 D2 3 K2 K1 C3 D3 key1 key2 A B C D 0 K0 K0 A0 B0 C0 D0 1 K0 K1 A1 B1 C1 D1 2 K1 K0 A2 B2 C2 D2 3 K2 K1 A3 B3 C3 D3 In\u00a0[9]: Copied! <pre>import pandas as pd\n\nleft = pd.DataFrame({'key1': ['A', 'B', 'C', 'D'], 'value1': [1, 2, 3, 4]})\nright = pd.DataFrame({'key2': ['A', 'B', 'C', 'D'], 'value2': [5, 6, 7, 8]})\n\nresult = pd.merge(left, right, left_on='key1', right_on='key2')\ndisplay_side_by_side(left,right,result)\n</pre> import pandas as pd  left = pd.DataFrame({'key1': ['A', 'B', 'C', 'D'], 'value1': [1, 2, 3, 4]}) right = pd.DataFrame({'key2': ['A', 'B', 'C', 'D'], 'value2': [5, 6, 7, 8]})  result = pd.merge(left, right, left_on='key1', right_on='key2') display_side_by_side(left,right,result) key1 value1 0 A 1 1 B 2 2 C 3 3 D 4 key2 value2 0 A 5 1 B 6 2 C 7 3 D 8 key1 value1 key2 value2 0 A 1 A 5 1 B 2 B 6 2 C 3 C 7 3 D 4 D 8 In\u00a0[10]: Copied! <pre>import pandas as pd\n\nleft = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],\n                     'key2': ['K0', 'K1', 'K0', 'K1'],\n                     'A': ['A0', 'A1', 'A2', 'A3'],\n                     'B': ['B0', 'B1', 'B2', 'B3']})\n\n\nright = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],\n                      'key2': ['K0', 'K0', 'K0', 'K0'],\n                      'C': ['C0', 'C1', 'C2', 'C3'],\n                      'D': ['D0', 'D1', 'D2', 'D3']})\n</pre> import pandas as pd  left = pd.DataFrame({'key1': ['K0', 'K0', 'K1', 'K2'],                      'key2': ['K0', 'K1', 'K0', 'K1'],                      'A': ['A0', 'A1', 'A2', 'A3'],                      'B': ['B0', 'B1', 'B2', 'B3']})   right = pd.DataFrame({'key1': ['K0', 'K1', 'K1', 'K2'],                       'key2': ['K0', 'K0', 'K0', 'K0'],                       'C': ['C0', 'C1', 'C2', 'C3'],                       'D': ['D0', 'D1', 'D2', 'D3']}) In\u00a0[11]: Copied! <pre># left merge\nresult = pd.merge(left, right, how= 'left', on=['key1', 'key2'])\ndisplay_side_by_side(left,right,result)\n</pre> # left merge result = pd.merge(left, right, how= 'left', on=['key1', 'key2']) display_side_by_side(left,right,result) key1 key2 A B 0 K0 K0 A0 B0 1 K0 K1 A1 B1 2 K1 K0 A2 B2 3 K2 K1 A3 B3 key1 key2 C D 0 K0 K0 C0 D0 1 K1 K0 C1 D1 2 K1 K0 C2 D2 3 K2 K0 C3 D3 key1 key2 A B C D 0 K0 K0 A0 B0 C0 D0 1 K0 K1 A1 B1 NaN NaN 2 K1 K0 A2 B2 C1 D1 3 K1 K0 A2 B2 C2 D2 4 K2 K1 A3 B3 NaN NaN In\u00a0[12]: Copied! <pre># right merge\nresult = pd.merge(left, right, how='right', on=['key1', 'key2'])\ndisplay_side_by_side(left,right,result)\n</pre> # right merge result = pd.merge(left, right, how='right', on=['key1', 'key2']) display_side_by_side(left,right,result) key1 key2 A B 0 K0 K0 A0 B0 1 K0 K1 A1 B1 2 K1 K0 A2 B2 3 K2 K1 A3 B3 key1 key2 C D 0 K0 K0 C0 D0 1 K1 K0 C1 D1 2 K1 K0 C2 D2 3 K2 K0 C3 D3 key1 key2 A B C D 0 K0 K0 A0 B0 C0 D0 1 K1 K0 A2 B2 C1 D1 2 K1 K0 A2 B2 C2 D2 3 K2 K0 NaN NaN C3 D3 In\u00a0[13]: Copied! <pre># outer merge\nresult = pd.merge(left, right, how='outer', on=['key1', 'key2'])\ndisplay_side_by_side(left,right,result)\n</pre> # outer merge result = pd.merge(left, right, how='outer', on=['key1', 'key2']) display_side_by_side(left,right,result) key1 key2 A B 0 K0 K0 A0 B0 1 K0 K1 A1 B1 2 K1 K0 A2 B2 3 K2 K1 A3 B3 key1 key2 C D 0 K0 K0 C0 D0 1 K1 K0 C1 D1 2 K1 K0 C2 D2 3 K2 K0 C3 D3 key1 key2 A B C D 0 K0 K0 A0 B0 C0 D0 1 K0 K1 A1 B1 NaN NaN 2 K1 K0 A2 B2 C1 D1 3 K1 K0 A2 B2 C2 D2 4 K2 K1 A3 B3 NaN NaN 5 K2 K0 NaN NaN C3 D3 In\u00a0[14]: Copied! <pre># inner merge\nresult = pd.merge(left, right, how='inner', on=['key1', 'key2'])\ndisplay_side_by_side(left,right,result)\n</pre> # inner merge result = pd.merge(left, right, how='inner', on=['key1', 'key2']) display_side_by_side(left,right,result) key1 key2 A B 0 K0 K0 A0 B0 1 K0 K1 A1 B1 2 K1 K0 A2 B2 3 K2 K1 A3 B3 key1 key2 C D 0 K0 K0 C0 D0 1 K1 K0 C1 D1 2 K1 K0 C2 D2 3 K2 K0 C3 D3 key1 key2 A B C D 0 K0 K0 A0 B0 C0 D0 1 K1 K0 A2 B2 C1 D1 2 K1 K0 A2 B2 C2 D2 In\u00a0[15]: Copied! <pre>left = pd.DataFrame({'A': [1, 2, 3], 'B': [1,2,3]})\nright = pd.DataFrame({'A': [4, 5, 6], 'B': [1, 2, 3]})\n\nresult = pd.merge(left, right, on='B')\ndisplay_side_by_side(left,right,result)\n</pre> left = pd.DataFrame({'A': [1, 2, 3], 'B': [1,2,3]}) right = pd.DataFrame({'A': [4, 5, 6], 'B': [1, 2, 3]})  result = pd.merge(left, right, on='B') display_side_by_side(left,right,result) A B 0 1 1 1 2 2 2 3 3 A B 0 4 1 1 5 2 2 6 3 A_x B A_y 0 1 1 4 1 2 2 5 2 3 3 6"},{"location":"pandas/032_merge_concat/#merge-y-concat","title":"Merge y Concat\u00b6","text":""},{"location":"pandas/032_merge_concat/#concat","title":"Concat\u00b6","text":"<p><code>concat()</code> es una funci\u00f3n de Pandas que se utiliza para combinar DataFrames y Series en un solo objeto. Permite unir varios objetos a lo largo de un eje en particular con opciones para configurar la forma en que se realiza la concatenaci\u00f3n.</p> <p>Observaci\u00f3n: Se define la funci\u00f3n <code>display_side_by_side</code> para poder imprimir dos o m\u00e1s dataframe lados a lado.</p>"},{"location":"pandas/032_merge_concat/#concatenar-dos-dataframes-verticalmente","title":"Concatenar dos DataFrames verticalmente\u00b6","text":""},{"location":"pandas/032_merge_concat/#concatenar-dos-dataframes-horizontalmente","title":"Concatenar dos DataFrames horizontalmente\u00b6","text":""},{"location":"pandas/032_merge_concat/#concatenar-dos-dataframes-verticalmente-con-distintas-columnas","title":"Concatenar dos DataFrames verticalmente con distintas columnas\u00b6","text":""},{"location":"pandas/032_merge_concat/#concatenar-dataframes-con-diferentes-indices","title":"Concatenar DataFrames con diferentes \u00edndices\u00b6","text":""},{"location":"pandas/032_merge_concat/#merge","title":"Merge\u00b6","text":"<p><code>merge()</code> es una funci\u00f3n de Pandas que se utiliza para combinar dos o m\u00e1s DataFrames en un solo DataFrame. La funci\u00f3n <code>merge()</code> combina los datos bas\u00e1ndose en las columnas compartidas, tambi\u00e9n conocidas como claves.</p>"},{"location":"pandas/032_merge_concat/#combinar-dos-dataframes-en-funcion-de-una-columna-comun","title":"Combinar dos DataFrames en funci\u00f3n de una columna com\u00fan\u00b6","text":""},{"location":"pandas/032_merge_concat/#combinar-dos-dataframes-en-funcion-de-una-columna-comun-con-valores-duplicados","title":"Combinar dos DataFrames en funci\u00f3n de una columna com\u00fan - con valores duplicados\u00b6","text":""},{"location":"pandas/032_merge_concat/#combinar-dos-dataframes-en-funcion-de-multiples-columnas-comunes","title":"Combinar dos DataFrames en funci\u00f3n de m\u00faltiples columnas comunes\u00b6","text":""},{"location":"pandas/032_merge_concat/#unir-dos-dataframes-utilizando-diferentes-columnas-en-cada-dataframe","title":"Unir dos DataFrames utilizando diferentes columnas en cada DataFrame\u00b6","text":""},{"location":"pandas/032_merge_concat/#combinar-dataframes-utilizando-el-comando-how","title":"Combinar Dataframes utilizando el comando <code>how</code>\u00b6","text":"<p>Existen distintos tipos de merge, para ello se utiliza la opci\u00f3n <code>how</code>, el cual especificica el tipo de cruce que se realizar\u00e1.</p> <ul> <li>left: usa las llaves solo de la tabla izquierda</li> <li>right: usa las llaves solo de la tabla derecha</li> <li>outer: usa las llaves de la uni\u00f3n de  ambas tablas.</li> <li>inner: usa las llaves de la intersecci\u00f3n de  ambas tablas.</li> </ul> <p></p>"},{"location":"pandas/032_merge_concat/#problemas-de-llaves-duplicadas","title":"Problemas de llaves duplicadas\u00b6","text":"<p>Cuando se quiere realizar el cruce de dos tablas, pero an ambas tablas existe una columna (<code>key</code>) con el mismo nombre, para diferenciar la informaci\u00f3n entre la columna de una tabla y otra, pandas devulve el nombre de la columna con un gui\u00f3n bajo x (<code>key_x</code>) y otra con un gui\u00f3n bajo y (<code>key_y</code>)</p>"},{"location":"pandas/033_pivot_melt/","title":"Pivot y Melt","text":"<p>En python, existen maneras de pasar del formato wide al formato long y viceversa.</p> In\u00a0[1]: Copied! <pre>import pandas as pd\n\ndatos = {\n    'Fecha': ['2022-01-01', '2022-01-01', '2022-01-02', '2022-01-02', '2022-01-03', '2022-01-03'],\n    'Vendedor': ['Juan', 'Pedro', 'Juan', 'Pedro', 'Juan', 'Pedro'],\n    'Producto': ['A', 'B', 'A', 'B', 'A', 'B'],\n    'Ventas': [100, 200, 150, 250, 120, 180]\n}\n\ndf = pd.DataFrame(datos)\n</pre> import pandas as pd  datos = {     'Fecha': ['2022-01-01', '2022-01-01', '2022-01-02', '2022-01-02', '2022-01-03', '2022-01-03'],     'Vendedor': ['Juan', 'Pedro', 'Juan', 'Pedro', 'Juan', 'Pedro'],     'Producto': ['A', 'B', 'A', 'B', 'A', 'B'],     'Ventas': [100, 200, 150, 250, 120, 180] }  df = pd.DataFrame(datos)  <p>1.- Pivot simple: si queremos ver las ventas totales por vendedor y por fecha, podemos hacer lo siguiente:</p> In\u00a0[2]: Copied! <pre>pivot_df = df.pivot(index='Fecha', columns='Vendedor', values='Ventas')\npivot_df\n</pre> pivot_df = df.pivot(index='Fecha', columns='Vendedor', values='Ventas') pivot_df Out[2]: Vendedor Juan Pedro Fecha 2022-01-01 100 200 2022-01-02 150 250 2022-01-03 120 180 <p>2.- Pivot m\u00faltiple: si queremos ver las ventas totales por vendedor y por fecha, y adem\u00e1s queremos desglosar las ventas por producto, podemos hacer lo siguiente:</p> In\u00a0[3]: Copied! <pre>pivot_df = df.pivot(index=['Fecha', 'Producto'], columns='Vendedor', values='Ventas')\npivot_df\n</pre> pivot_df = df.pivot(index=['Fecha', 'Producto'], columns='Vendedor', values='Ventas') pivot_df Out[3]: Vendedor Juan Pedro Fecha Producto 2022-01-01 A 100.0 NaN B NaN 200.0 2022-01-02 A 150.0 NaN B NaN 250.0 2022-01-03 A 120.0 NaN B NaN 180.0 In\u00a0[4]: Copied! <pre>import pandas as pd\n\ndatos = {\n    'Fecha': ['2022-01-01', '2022-01-01', '2022-01-02', '2022-01-02', '2022-01-03', '2022-01-03'],\n    'Vendedor': ['Juan', 'Pedro', 'Juan', 'Pedro', 'Juan', 'Pedro'],\n    'Producto': ['A', 'B', 'A', 'B', 'A', 'B'],\n    'Ventas': [100, 200, 150, 250, 120, 180]\n}\n\ndf = pd.DataFrame(datos)\n</pre> import pandas as pd  datos = {     'Fecha': ['2022-01-01', '2022-01-01', '2022-01-02', '2022-01-02', '2022-01-03', '2022-01-03'],     'Vendedor': ['Juan', 'Pedro', 'Juan', 'Pedro', 'Juan', 'Pedro'],     'Producto': ['A', 'B', 'A', 'B', 'A', 'B'],     'Ventas': [100, 200, 150, 250, 120, 180] }  df = pd.DataFrame(datos)  <p>1.- Pivot_table simple: si queremos ver las ventas totales por vendedor y por fecha, podemos hacer lo siguiente:</p> In\u00a0[5]: Copied! <pre>pivot_df = df.pivot_table(index='Fecha', columns='Vendedor', values='Ventas', aggfunc='sum')\npivot_df\n</pre> pivot_df = df.pivot_table(index='Fecha', columns='Vendedor', values='Ventas', aggfunc='sum') pivot_df Out[5]: Vendedor Juan Pedro Fecha 2022-01-01 100 200 2022-01-02 150 250 2022-01-03 120 180 <p>2.- Pivot_table con agregaci\u00f3n m\u00faltiple: si queremos ver la suma y el promedio de ventas por vendedor y por fecha, podemos hacer lo siguiente:</p> In\u00a0[6]: Copied! <pre>pivot_df = df.pivot_table(index='Fecha', columns='Vendedor', values='Ventas', aggfunc=['sum', 'mean'])\npivot_df\n</pre> pivot_df = df.pivot_table(index='Fecha', columns='Vendedor', values='Ventas', aggfunc=['sum', 'mean']) pivot_df Out[6]: sum mean Vendedor Juan Pedro Juan Pedro Fecha 2022-01-01 100 200 100 200 2022-01-02 150 250 150 250 2022-01-03 120 180 120 180 <p>3.- Pivot_table con margen: si queremos ver la suma de ventas por vendedor, por fecha y por el total, podemos hacer lo siguiente:</p> In\u00a0[7]: Copied! <pre>pivot_df = df.pivot_table(index='Fecha', columns='Vendedor', values='Ventas', aggfunc='sum', margins=True)\npivot_df\n</pre> pivot_df = df.pivot_table(index='Fecha', columns='Vendedor', values='Ventas', aggfunc='sum', margins=True) pivot_df Out[7]: Vendedor Juan Pedro All Fecha 2022-01-01 100 200 300 2022-01-02 150 250 400 2022-01-03 120 180 300 All 370 630 1000 <p>Observaci\u00f3n: Las principales diferencias entre <code>pivot</code> y <code>pivot_table</code> son:</p> <ul> <li><p>La funci\u00f3n <code>pivot</code> solo funciona con DataFrames que tienen una \u00fanica columna de valores que se pueden utilizar como la columna de valores de salida en el DataFrame resultante, mientras que la funci\u00f3n <code>pivot_table</code> puede trabajar con m\u00faltiples columnas de valores y aplicar operaciones de agregaci\u00f3n en esas columnas. Por lo tanto, la funci\u00f3n <code>pivot_table</code> es m\u00e1s vers\u00e1til.</p> </li> <li><p>La funci\u00f3n <code>pivot</code> solo se puede utilizar para reorganizar un DataFrame, mientras que la funci\u00f3n <code>pivot_table</code> tambi\u00e9n puede realizar operaciones de agregaci\u00f3n en los valores correspondientes a cada combinaci\u00f3n de valores de \u00edndice y columnas. Por lo tanto, la funci\u00f3n <code>pivot_table</code> es m\u00e1s adecuada para tareas m\u00e1s avanzadas de an\u00e1lisis de datos.</p> </li> <li><p>La funci\u00f3n <code>pivot</code> es m\u00e1s simple y tiene una sintaxis m\u00e1s concisa, mientras que la funci\u00f3n <code>pivot_table</code> es m\u00e1s compleja y tiene una sintaxis m\u00e1s detallada. Por lo tanto, si solo necesita reorganizar los datos y no necesita realizar operaciones de agregaci\u00f3n, la funci\u00f3n <code>pivot</code> puede ser m\u00e1s f\u00e1cil de usar.</p> </li> </ul> In\u00a0[8]: Copied! <pre>import pandas as pd\n\ndatos = {'Nombre': ['Ana', 'Juan', 'Pedro'],\n         'Edad': [25, 30, 35],\n         'Ingreso_2019': [2000, 3000, 4000],\n         'Ingreso_2020': [2200, 3200, 4200]}\n\ndf = pd.DataFrame(datos)\ndf\n</pre> import pandas as pd  datos = {'Nombre': ['Ana', 'Juan', 'Pedro'],          'Edad': [25, 30, 35],          'Ingreso_2019': [2000, 3000, 4000],          'Ingreso_2020': [2200, 3200, 4200]}  df = pd.DataFrame(datos) df Out[8]: Nombre Edad Ingreso_2019 Ingreso_2020 0 Ana 25 2000 2200 1 Juan 30 3000 3200 2 Pedro 35 4000 4200 In\u00a0[9]: Copied! <pre># aplicar comando melt\ndf_melt = pd.melt(\n    df, \n    id_vars=['Nombre', 'Edad'], \n    value_vars=['Ingreso_2019', 'Ingreso_2020'], \n    var_name='A\u00f1o',\n    value_name='Ingreso'\n)\n\ndf_melt\n</pre> # aplicar comando melt df_melt = pd.melt(     df,      id_vars=['Nombre', 'Edad'],      value_vars=['Ingreso_2019', 'Ingreso_2020'],      var_name='A\u00f1o',     value_name='Ingreso' )  df_melt Out[9]: Nombre Edad A\u00f1o Ingreso 0 Ana 25 Ingreso_2019 2000 1 Juan 30 Ingreso_2019 3000 2 Pedro 35 Ingreso_2019 4000 3 Ana 25 Ingreso_2020 2200 4 Juan 30 Ingreso_2020 3200 5 Pedro 35 Ingreso_2020 4200 <p>2.- Ejemplo Complejo - relaciones no \u00fanicas: separar correctamente la columna \"ingreso\" y \"edad\".</p> In\u00a0[10]: Copied! <pre>import pandas as pd\n\ndatos = {'id': ['001', '002', '003'],\n         'Nombre': ['Juan', 'Ana', 'Pedro'],\n         'Edad_2019': [25, 32, 28],\n         'Edad_2020': [26, 33, 29],\n         'Edad_2021': [27, 34, 30],\n         'Salario_2019': [2500, 3200, 2800],\n         'Salario_2020': [2700, 3400, 2900],\n         'Salario_2021': [2900, 3600, 3000]}\n\ndf = pd.DataFrame(datos)\ndf\n</pre> import pandas as pd  datos = {'id': ['001', '002', '003'],          'Nombre': ['Juan', 'Ana', 'Pedro'],          'Edad_2019': [25, 32, 28],          'Edad_2020': [26, 33, 29],          'Edad_2021': [27, 34, 30],          'Salario_2019': [2500, 3200, 2800],          'Salario_2020': [2700, 3400, 2900],          'Salario_2021': [2900, 3600, 3000]}  df = pd.DataFrame(datos) df Out[10]: id Nombre Edad_2019 Edad_2020 Edad_2021 Salario_2019 Salario_2020 Salario_2021 0 001 Juan 25 26 27 2500 2700 2900 1 002 Ana 32 33 34 3200 3400 3600 2 003 Pedro 28 29 30 2800 2900 3000 In\u00a0[12]: Copied! <pre># caso 01: edad\ncols_1 = ['id', 'Nombre', 'Edad_2019', 'Edad_2020', 'Edad_2021']\ndf1 = df[cols_1]\ndf1.columns = ['id', 'Nombre', '2019', '2020', '2021']\ndf_melt_01 = pd.melt(df1, id_vars=['id', 'Nombre'], var_name='Fecha', value_name='Edad')\n\n# caso 02: salario\ncols_2 = ['id', 'Nombre', 'Salario_2019','Salario_2020', 'Salario_2021']\ndf2 = df[cols_2]\ndf2.columns = ['id', 'Nombre', '2019', '2020', '2021']\ndf_melt_02 = pd.melt(df2, id_vars=['id', 'Nombre'], var_name='Fecha', value_name='Salario')\n\n\n# juntar informacion\ndf_melt = df_melt_01.merge(df_melt_02,on = ['id','Nombre','Fecha'])\ndf_melt\n</pre> # caso 01: edad cols_1 = ['id', 'Nombre', 'Edad_2019', 'Edad_2020', 'Edad_2021'] df1 = df[cols_1] df1.columns = ['id', 'Nombre', '2019', '2020', '2021'] df_melt_01 = pd.melt(df1, id_vars=['id', 'Nombre'], var_name='Fecha', value_name='Edad')  # caso 02: salario cols_2 = ['id', 'Nombre', 'Salario_2019','Salario_2020', 'Salario_2021'] df2 = df[cols_2] df2.columns = ['id', 'Nombre', '2019', '2020', '2021'] df_melt_02 = pd.melt(df2, id_vars=['id', 'Nombre'], var_name='Fecha', value_name='Salario')   # juntar informacion df_melt = df_melt_01.merge(df_melt_02,on = ['id','Nombre','Fecha']) df_melt Out[12]: id Nombre Fecha Edad Salario 0 001 Juan 2019 25 2500 1 002 Ana 2019 32 3200 2 003 Pedro 2019 28 2800 3 001 Juan 2020 26 2700 4 002 Ana 2020 33 3400 5 003 Pedro 2020 29 2900 6 001 Juan 2021 27 2900 7 002 Ana 2021 34 3600 8 003 Pedro 2021 30 3000"},{"location":"pandas/033_pivot_melt/#pivot-y-melt","title":"Pivot y Melt\u00b6","text":"<p>Dentro del mundo de los dataframe (o datos tabulares) existen dos formas de presentar la naturaleza de los datos: formato wide y formato long.</p> <p>Por ejemplo, el conjunto de datos Zoo Data Set presenta las caracter\u00edsticas de diversos animales, de los cuales presentamos las primeras 5 columnas.</p> animal_name hair feathers eggs milk antelope 1 0 0 1 bear 1 0 0 1 buffalo 1 0 0 1 catfish 0 0 1 0 <p>La tabla as\u00ed presentada se encuentra en wide format, es decir, donde los valores se extienden a trav\u00e9s de las columnas.</p> <p>Ser\u00eda posible representar el mismo contenido anterior en long format, es decir, donde los mismos valores se indicaran a trav\u00e9s de las filas:</p> <p>|animal_name|characteristic|value| |-----------|----|--------| |antelope|hair |1| |antelope|feathers|0| |antelope|eggs|0| |antelope|milk|1| |...|...|...|...|..| |catfish|hair |0| |catfish|feathers|0| |catfish|eggs|1| |catfish|milk|0|</p> <p></p>"},{"location":"pandas/033_pivot_melt/#formato-long-a-wide","title":"Formato long a wide\u00b6","text":"<p>El pivoteo de una tabla corresponde al paso de una tabla desde el formato long al formato wide. T\u00edpicamente esto se realiza para poder comparar los valores que se obtienen para alg\u00fan registro en particular, o para utilizar algunas herramientas de visualizaci\u00f3n b\u00e1sica que requieren dicho formato.</p> <p>En Pandas se utiliza los comandos <code>pivot</code> y <code>pivot_table</code>.</p>"},{"location":"pandas/033_pivot_melt/#pivot","title":"pivot\u00b6","text":"<p>La funci\u00f3n <code>pivot</code> se utiliza para transformar los datos de formato largo a formato ancho en funci\u00f3n de los valores \u00fanicos en una columna determinada. Esta funci\u00f3n toma tres argumentos: <code>index</code>, <code>columns</code>, y <code>values</code>.</p> <ul> <li><code>index</code> se utiliza para especificar la(s) columna(s) que se utilizar\u00e1n como el \u00edndice en el DataFrame resultante</li> <li><code>columns</code> se utiliza para especificar la columna que se utilizar\u00e1 como las columnas en el DataFrame resultante</li> <li><code>values</code> se utiliza para especificar la columna que se utilizar\u00e1 como los valores para completar el DataFrame resultante.</li> </ul> <p>Supongamos que tenemos un conjunto de datos que contiene informaci\u00f3n sobre las ventas de una empresa, con las siguientes columnas: \"Fecha\", \"Vendedor\", \"Producto\" y \"Ventas\".</p>"},{"location":"pandas/033_pivot_melt/#pivot_table","title":"pivot_table\u00b6","text":"<p>La funci\u00f3n <code>pivot_table</code> tambi\u00e9n se utiliza para transformar los datos de formato largo a formato ancho, pero con la capacidad adicional de realizar operaciones de agregaci\u00f3n en los valores correspondientes a cada combinaci\u00f3n de valores de \u00edndice y columna. Esta funci\u00f3n toma muchos argumentos, pero los m\u00e1s importantes son: <code>index</code>, <code>columns</code>, y <code>values</code> como en la funci\u00f3n <code>pivot</code>. Adem\u00e1s, <code>pivot_table</code> tambi\u00e9n tiene un argumento <code>aggfunc</code> que especifica la operaci\u00f3n de agregaci\u00f3n que se aplicar\u00e1 a los valores. Por defecto, el valor de <code>aggfunc</code> es <code>mean</code>, pero puede especificarse una variedad de operaciones como <code>sum</code>, <code>count</code>, <code>max</code>, <code>min</code>, <code>std</code>, <code>var</code>, y muchas m\u00e1s.</p>"},{"location":"pandas/033_pivot_melt/#formato-wide-a-long","title":"Formato wide a long\u00b6","text":"<p>El despivotear una tabla corresponde al paso de una tabla desde el formato wide al formato long.</p> <p>Se reconocen dos situaciones:</p> <ol> <li>El valor indicado para la columna es \u00fanico, y s\u00f3lo se requiere definir correctamente las columnas.</li> <li>El valor indicado por la columna no es \u00fanico, y se requiere una iteraci\u00f3n m\u00e1s profunda.</li> </ol> <p>Para despivotear un dataframe en Pandas, utilizaremos el comando <code>melt</code>.</p>"},{"location":"pandas/033_pivot_melt/#melt","title":"Melt\u00b6","text":"<p>La funci\u00f3n <code>melt</code> en Pandas es una herramienta \u00fatil para transformar un DataFrame de formato ancho a formato largo. La funci\u00f3n toma como entrada un DataFrame con una o m\u00e1s columnas que se identifican como identificadores (o \"id_vars\" en ingl\u00e9s), y las convierte en una o m\u00e1s columnas de valor (o \"value_vars\" en ingl\u00e9s).</p> <p>La sintaxis b\u00e1sica de la funci\u00f3n melt es la siguiente:</p> <pre>pd.melt(\n    df,\n    id_vars=['Columna1', 'Columna2'], \n    value_vars=['Columna3', 'Columna4'],\n    var_name='NuevaColumna1', \n    value_name='NuevaColumna2'\n)\n</pre> <p>donde:</p> <ul> <li><code>df</code>: es el DataFrame que se va a fundir.</li> <li><code>id_vars</code>: son las columnas del DataFrame que se van a conservar como identificadores.</li> <li><code>value_vars</code>: son las columnas que se van a fundir en una sola columna.</li> <li><code>var_name</code>: es el nombre de la columna que contendr\u00e1 los nombres de las columnas fundidas.</li> <li><code>value_name</code>: es el nombre de la columna que contendr\u00e1 los valores de las columnas fundidas.</li> </ul> <p>1.- Ejemplo Sencillo - relaciones \u00fanicas: separar correctamente la columna \"ingreso\".</p>"},{"location":"pandas/034_ejemplo_practico/","title":"Ejemplo Pr\u00e1ctico 02","text":"<p>Esta semana revisaremos datos del \u00cdndice de Libertad de Prensa que confecciona cada a\u00f1o la asociaci\u00f3n de Reporteros Sin Fronteras.</p> In\u00a0[1]: Copied! <pre>import numpy as np \nimport pandas as pd\n\nfrom os import listdir\nfrom os.path import isfile, join\n</pre> import numpy as np  import pandas as pd  from os import listdir from os.path import isfile, join In\u00a0[2]: Copied! <pre># codigo\npath_codigo = \"https://raw.githubusercontent.com/fralfaro/python_data_manipulation/main/docs/pandas/data/libertad_prensa_codigo.csv\"\ndf_codigos = pd.read_csv(path_codigo)\ndf_codigos.head()\n</pre> # codigo path_codigo = \"https://raw.githubusercontent.com/fralfaro/python_data_manipulation/main/docs/pandas/data/libertad_prensa_codigo.csv\" df_codigos = pd.read_csv(path_codigo) df_codigos.head() Out[2]: codigo_iso pais 0 AFG Afghanist\u00e1n 1 AGO Angola 2 ALB Albania 3 AND Andorra 4 ARE Emiratos \u00c1rabes Unidos In\u00a0[3]: Copied! <pre># libertad de prensa 01\npath_codigo = \"https://raw.githubusercontent.com/fralfaro/python_data_manipulation/main/docs/pandas/data/\"\ndf_anio1 = pd.read_csv(path_codigo+\"libertad_prensa_01.csv\")\ndf_anio1.head()\n</pre> # libertad de prensa 01 path_codigo = \"https://raw.githubusercontent.com/fralfaro/python_data_manipulation/main/docs/pandas/data/\" df_anio1 = pd.read_csv(path_codigo+\"libertad_prensa_01.csv\") df_anio1.head() Out[3]: codigo_iso anio indice ranking 0 AFG 2001 35.5 59.0 1 AGO 2001 30.2 50.0 2 ALB 2001 NaN NaN 3 AND 2001 NaN NaN 4 ARE 2001 NaN NaN In\u00a0[4]: Copied! <pre># libertad de prensa 02\ndf_anio2 = pd.read_csv(path_codigo+\"libertad_prensa_02.csv\")\ndf_anio2.head()\n</pre> # libertad de prensa 02 df_anio2 = pd.read_csv(path_codigo+\"libertad_prensa_02.csv\") df_anio2.head() Out[4]: codigo_iso anio indice ranking 0 AFG 2012 37.36 112.0 1 AGO 2012 37.80 114.0 2 ALB 2012 30.88 87.0 3 AND 2012 6.82 152.0 4 ARE 2012 33.49 98.0 <p>El objetivo es tratar de obtener la mayor informaci\u00f3n posible de este conjunto de datos. Para cumplir este objetivo debe resolver las siguientes problem\u00e1ticas:</p> <ol> <li>Lo primero ser\u00e1 juntar toda la informaci\u00f3n en un solo archivo, para ello necesitamos seguir los siguientes pasos:</li> </ol> <ul> <li>a) Crear el archivo df_anio, que contenga la informaci\u00f3n de libertad_prensa_01.csv y  libertad_prensa_02.csv. Luego, normalice el nombre de las columnas a min\u00fascula.</li> <li>b) Encuentre y elimine el dato que esta duplicado en el archivo df_codigo.</li> <li>c) Crear el archivo df que junte la informaci\u00f3n del archivo df_anio con df_codigo por la columna codigo_iso.</li> </ul> <p>Hint: Para juntar por anio ocupe la funci\u00f3n pd.concat. Para juntar informaci\u00f3n por columna ocupe pd.merge.</p> In\u00a0[5]: Copied! <pre># creamos el dataframe con la informaci\u00f3n de todos los a\u00f1os\ndf_anio = pd.concat([df_anio1,df_anio2])\n\n# cambiamos los nombres de las columnas de df_anio a min\u00fasculas\ndf_anio.columns = df_anio.columns.str.lower()\n\n# imprimir resultados\ndf_anio.head()\n</pre> # creamos el dataframe con la informaci\u00f3n de todos los a\u00f1os df_anio = pd.concat([df_anio1,df_anio2])  # cambiamos los nombres de las columnas de df_anio a min\u00fasculas df_anio.columns = df_anio.columns.str.lower()  # imprimir resultados df_anio.head() Out[5]: codigo_iso anio indice ranking 0 AFG 2001 35.5 59.0 1 AGO 2001 30.2 50.0 2 ALB 2001 NaN NaN 3 AND 2001 NaN NaN 4 ARE 2001 NaN NaN In\u00a0[6]: Copied! <pre># eliminamos el dato repetido en df_codigos\n\nprint(\"Total duplicados antes\")\nprint(df_codigos[\"codigo_iso\"].value_counts().loc[lambda x: x&gt;1])\n\ndf_codigos = df_codigos.drop_duplicates('codigo_iso')\n\nprint(\"\\nTotal duplicados despues\")\nprint(df_codigos[\"codigo_iso\"].value_counts().loc[lambda x: x&gt;1])\n</pre> # eliminamos el dato repetido en df_codigos  print(\"Total duplicados antes\") print(df_codigos[\"codigo_iso\"].value_counts().loc[lambda x: x&gt;1])  df_codigos = df_codigos.drop_duplicates('codigo_iso')  print(\"\\nTotal duplicados despues\") print(df_codigos[\"codigo_iso\"].value_counts().loc[lambda x: x&gt;1]) <pre>Total duplicados antes\nZWE    2\nName: codigo_iso, dtype: int64\n\nTotal duplicados despues\nSeries([], Name: codigo_iso, dtype: int64)\n</pre> In\u00a0[7]: Copied! <pre># juntar informacion\n\ndf = df_anio.merge(df_codigos,on = 'codigo_iso' )\ndf.head()\n</pre> # juntar informacion  df = df_anio.merge(df_codigos,on = 'codigo_iso' ) df.head() Out[7]: codigo_iso anio indice ranking pais 0 AFG 2001 35.50 59.0 Afghanist\u00e1n 1 AFG 2002 40.17 78.0 Afghanist\u00e1n 2 AFG 2003 28.25 49.0 Afghanist\u00e1n 3 AFG 2004 39.17 62.0 Afghanist\u00e1n 4 AFG 2005 44.25 67.0 Afghanist\u00e1n <ol> <li>Encontrar:<ul> <li>\u00bfCu\u00e1l es el n\u00famero de observaciones en el conjunto de datos?</li> <li>\u00bfCu\u00e1l es el n\u00famero de columnas en el conjunto de datos?</li> <li>Imprime el nombre de todas las columnas</li> <li>\u00bfCu\u00e1l es el tipo de datos de cada columna?</li> <li>Describir el conjunto de datos (hint: .describe())</li> </ul> </li> </ol> In\u00a0[8]: Copied! <pre># respuesta\n(n_obs, n_cols) = df.shape\nprint(f\"Hay {n_obs}  observaciones en el conjunto de datos\")\nprint(f\"Hay {n_cols} columnas en el conjunto de datos\")\n</pre> # respuesta (n_obs, n_cols) = df.shape print(f\"Hay {n_obs}  observaciones en el conjunto de datos\") print(f\"Hay {n_cols} columnas en el conjunto de datos\") <pre>Hay 3060  observaciones en el conjunto de datos\nHay 5 columnas en el conjunto de datos\n</pre> <ol> <li>Desarrolle una funci\u00f3n <code>resumen_df(df)</code> para encontrar el total de elementos distintos y vac\u00edos por columnas.</li> </ol> In\u00a0[9]: Copied! <pre># respuesta\ndef resumen_df(df):\n    \"\"\"\n    funcion resumen con elementos \n    distintos y vacios por columnas\n    \"\"\"\n    nombres = df.columns\n    \n    l1 = []\n    l2 = []\n    \n    for nombre in nombres:\n        pd_series = df[nombre]\n        # elementos distintos \n        l_unique = pd_series.unique()\n        # elementos vacios\n        l_vacios = pd_series[pd_series.isna()]\n        \n        l1.append(len(l_unique))\n        l2.append(len(l_vacios))\n        \n        \n    \n    result = pd.DataFrame({'nombres': nombres})\n    result['elementos_distintos'] = l1\n    result['elementos_vacios'] = l2\n    \n    return result\n</pre> # respuesta def resumen_df(df):     \"\"\"     funcion resumen con elementos      distintos y vacios por columnas     \"\"\"     nombres = df.columns          l1 = []     l2 = []          for nombre in nombres:         pd_series = df[nombre]         # elementos distintos          l_unique = pd_series.unique()         # elementos vacios         l_vacios = pd_series[pd_series.isna()]                  l1.append(len(l_unique))         l2.append(len(l_vacios))                            result = pd.DataFrame({'nombres': nombres})     result['elementos_distintos'] = l1     result['elementos_vacios'] = l2          return result In\u00a0[10]: Copied! <pre># retornar \nresumen_df(df)\n</pre> # retornar  resumen_df(df) Out[10]: nombres elementos_distintos elementos_vacios 0 codigo_iso 180 0 1 anio 17 0 2 indice 1551 396 3 ranking 194 223 4 pais 179 0 <ol> <li>Para los paises latinoamericano, encuentre por a\u00f1o  el pa\u00eds con mayor y menor <code>indice</code>.</li> </ol> <ul> <li>a) Mediante un ciclo for.</li> <li>b) Mediante un  groupby.</li> </ul> In\u00a0[11]: Copied! <pre># respuesta\n\namerica = ['ARG', 'ATG', 'BLZ', 'BOL', 'BRA', 'CAN', 'CHL', 'COL', 'CRI',\n       'CUB', 'DOM', 'ECU', 'GRD', 'GTM', 'GUY', 'HND', 'HTI', 'JAM',\n       'MEX', 'NIC', 'PAN', 'PER', 'PRY', 'SLV', 'SUR', 'TTO', 'URY',\n       'USA', 'VEN']\n\ndf_america = df.loc[lambda x: x.codigo_iso.isin(america)]\n</pre> # respuesta  america = ['ARG', 'ATG', 'BLZ', 'BOL', 'BRA', 'CAN', 'CHL', 'COL', 'CRI',        'CUB', 'DOM', 'ECU', 'GRD', 'GTM', 'GUY', 'HND', 'HTI', 'JAM',        'MEX', 'NIC', 'PAN', 'PER', 'PRY', 'SLV', 'SUR', 'TTO', 'URY',        'USA', 'VEN']  df_america = df.loc[lambda x: x.codigo_iso.isin(america)] In\u00a0[12]: Copied! <pre># ciclo for\n\ndct = dict()\n\nfor pais in america:\n    df_temp =df.loc[lambda x: x.codigo_iso == pais] \n    dct[pais] = (df_temp['indice'].max(),df_temp['indice'].min())\ndct\n</pre> # ciclo for  dct = dict()  for pais in america:     df_temp =df.loc[lambda x: x.codigo_iso == pais]      dct[pais] = (df_temp['indice'].max(),df_temp['indice'].min()) dct Out[12]: <pre>{'ARG': (35826.0, 11.33),\n 'ATG': (20.81, 20.81),\n 'BLZ': (27.5, 17.05),\n 'BOL': (35.38, 4.5),\n 'BRA': (34.03, 14.5),\n 'CAN': (16.53, 0.8),\n 'CHL': (26.24, 6.5),\n 'COL': (51.5, 35.5),\n 'CRI': (14.01, 3.83),\n 'CUB': (106.83, 63.81),\n 'DOM': (28.34, 6.75),\n 'ECU': (34.69, 5.5),\n 'GRD': (12.0, 12.0),\n 'GTM': (39.33, 16.5),\n 'GUY': (27.21, 10.5),\n 'HND': (51.13, 11.75),\n 'HTI': (42.13, 15.0),\n 'JAM': (12.73, 3.33),\n 'MEX': (53.63, 17.67),\n 'NIC': (35.53, 6.5),\n 'PAN': (32.95, 9.5),\n 'PER': (40.0, 9.5),\n 'PRY': (35.64, 7.17),\n 'SLV': (29.81, 5.75),\n 'SUR': (18.2, 6.0),\n 'TTO': (24.74, 1.0),\n 'URY': (17.43, 4.0),\n 'USA': (25.69, 4.0),\n 'VEN': (49.1, 23.0)}</pre> In\u00a0[13]: Copied! <pre># ciclo groupby\ndf_america.groupby('codigo_iso')['indice'].agg({max,min})\n</pre> # ciclo groupby df_america.groupby('codigo_iso')['indice'].agg({max,min}) Out[13]: max min codigo_iso ARG 35826.00 11.33 ATG 20.81 20.81 BLZ 27.50 17.05 BOL 35.38 4.50 BRA 34.03 14.50 CAN 16.53 0.80 CHL 26.24 6.50 COL 51.50 35.50 CRI 14.01 3.83 CUB 106.83 63.81 DOM 28.34 6.75 ECU 34.69 5.50 GRD 12.00 12.00 GTM 39.33 16.50 GUY 27.21 10.50 HND 51.13 11.75 HTI 42.13 15.00 JAM 12.73 3.33 MEX 53.63 17.67 NIC 35.53 6.50 PAN 32.95 9.50 PER 40.00 9.50 PRY 35.64 7.17 SLV 29.81 5.75 SUR 18.20 6.00 TTO 24.74 1.00 URY 17.43 4.00 USA 25.69 4.00 VEN 49.10 23.00 <ol> <li>Para cada pa\u00eds, muestre el indice m\u00e1ximo que alcanzo por anio. Para los datos nulos, rellene con el valor 0.</li> </ol> <p>Ejemplo:</p> <p>Hint: Utilice la funci\u00f3n pd.pivot_table.</p> In\u00a0[14]: Copied! <pre>df_pivot = df.pivot_table(\n    index=\"codigo_iso\", \n    columns=\"anio\",\n    values=\"indice\",\n    fill_value=0\n)\ndf_pivot\n</pre> df_pivot = df.pivot_table(     index=\"codigo_iso\",      columns=\"anio\",     values=\"indice\",     fill_value=0 ) df_pivot Out[14]: anio 2001 2002 2003 2004 2005 2006 2007 2008 2009 2012 2013 2014 2015 2017 2018 2019 codigo_iso AFG 35.5 40.17 28.25 39.17 44.25 56.50 59.25 54.25 51.67 37.36 37.07 37.44 37.75 39.46 37.28 36.55 AGO 30.2 28.00 26.50 18.00 21.50 26.50 29.50 36.50 28.50 37.80 36.50 37.84 39.89 40.42 38.35 34.96 ALB 0.0 6.50 11.50 14.17 18.00 25.50 16.00 21.75 21.50 30.88 29.92 28.77 29.92 29.92 29.49 29.84 AND 0.0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 6.82 6.82 19.87 19.87 21.03 22.21 24.63 ARE 0.0 37.00 50.25 25.75 17.50 20.25 14.50 21.50 23.75 33.49 36.03 36.73 36.73 39.39 40.86 43.63 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... WSM 0.0 0.00 0.00 0.00 0.00 0.00 0.00 0.00 33.00 23.84 22.02 22.32 18.80 16.41 16.69 18.25 YEM 34.8 41.83 48.00 46.25 54.00 56.67 59.00 83.38 82.13 69.22 67.26 66.36 67.07 65.80 62.23 61.66 ZAF 7.5 3.33 5.00 6.50 11.25 13.00 8.00 8.50 12.00 24.56 23.19 22.06 21.92 20.12 20.39 22.19 ZMB 26.8 23.25 29.75 23.00 22.50 21.50 15.50 26.75 22.00 27.93 30.89 34.35 35.08 36.48 35.36 36.38 ZWE 48.3 45.50 67.50 64.25 50.00 62.00 54.00 46.50 39.50 38.12 39.19 39.19 40.41 41.44 40.53 42.23 <p>180 rows \u00d7 16 columns</p>"},{"location":"pandas/034_ejemplo_practico/#ejemplo-practico-02","title":"Ejemplo Pr\u00e1ctico 02\u00b6","text":""},{"location":"pandas/034_ejemplo_practico/#diccionario-de-datos","title":"Diccionario de datos\u00b6","text":"Variable Clase Descripci\u00f3n codigo_iso caracter C\u00f3digo ISO del pa\u00eds pais caracter Pa\u00eds anio entero A\u00f1o del resultado indice entero Puntaje \u00cdndice Libertad de Prensa (menor puntaje = mayor libertad de prensa) ranking entero Ranking Libertad de Prensa"},{"location":"pandas/034_ejemplo_practico/#fuente-original-y-adaptacion","title":"Fuente original y adaptaci\u00f3n\u00b6","text":"<p>Los datos fueron extra\u00eddos de The World Bank. La fuente original es Reporteros sin Fronteras.</p> <p>Por otro lado, estos archivos han sido modificado intencionalmente para ocupar todo lo aprendido en clases. A continuaci\u00f3n, una breve descripci\u00f3n de cada uno de los data frames:</p> <ul> <li>libertad_prensa_codigo.csv: contiene la informaci\u00f3n codigo_iso/pais. Existe un c\u00f3digo que tiene dos valores.</li> <li>libertad_prensa_01.csv: contiene la informaci\u00f3n pais/anio/indice/ranking (parte_01). Los nombres de las columnas estan en may\u00fascula.</li> <li>libertad_prensa_02.csv: contiene la informaci\u00f3n pais/anio/indice/ranking (parte_02). Los nombres de las columnas estan en may\u00fascula.</li> </ul>"},{"location":"pandas/intro/","title":"Manipulaci\u00f3n de Datos\ud83d\udcda Table of Contents:","text":""},{"location":"visualization/011_intro/","title":"Introducci\u00f3n","text":"In\u00a0[1]: { \"tags\": [ \"hide-input\" ] } Copied! <pre>from IPython.display import display_html\n\ndef display_side_by_side(*args):\n    html_str = ''\n    for df in args:\n        html_str += df.to_html()\n        html_str += '&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;'\n    display_html(\n        html_str.replace('table','table style=\"display:inline\"'), \n        raw=True\n    )\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos del cuarteto de Anscombe\nanscombe = sns.load_dataset(\"anscombe\")\n\n# Dividir los datos en cuatro conjuntos seg\u00fan el valor de \"dataset\"\nds1 = anscombe[anscombe['dataset'] == 'I']\nds2 = anscombe[anscombe['dataset'] == 'II']\nds3 = anscombe[anscombe['dataset'] == 'III']\nds4 = anscombe[anscombe['dataset'] == 'IV']\n\n# Mostrar estadisticas para cada conjunto\nprint(\"Estadisticas Basicas:\\n\")\nx=\" \"\nprint(f\"{10*x}Dataset I {13*x}Dataset II\")\ndisplay_side_by_side(ds1.describe(),ds2.describe())\nprint()\nprint(f\"{10*x}Dataset III {13*x}Dataset IV\")\ndisplay_side_by_side(ds3.describe(),ds4.describe())\n\n# Mostrar  correlaciones para cada conjunto\nprint(\"Correlaciones:\\n\")\n\nprint(f\"{5*x}Dataset I {10*x}Dataset II {10*x}Dataset III {10*x}Dataset IV\")\ndisplay_side_by_side(ds1.corr(),ds2.corr(),ds3.corr(),ds4.corr())\n\n\nprint(\"Graficos:\\n\")\n\n# Crear una figura con cuatro subplots\nfig, axs = plt.subplots(ncols=4, figsize=(16, 4))\n\n# Graficar cada conjunto de datos en su respectivo subplot\nsns.regplot(x='x', y='y', data=ds1, ax=axs[0], ci=None)\nsns.regplot(x='x', y='y', data=ds2, ax=axs[1], ci=None)\nsns.regplot(x='x', y='y', data=ds3, ax=axs[2], ci=None)\nsns.regplot(x='x', y='y', data=ds4, ax=axs[3], ci=None)\n\n# Agregar t\u00edtulos a los subplots\naxs[0].set_title('Dataset I')\naxs[1].set_title('Dataset II')\naxs[2].set_title('Dataset III')\naxs[3].set_title('Dataset IV')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> from IPython.display import display_html  def display_side_by_side(*args):     html_str = ''     for df in args:         html_str += df.to_html()         html_str += '\u00a0\u00a0\u00a0\u00a0'     display_html(         html_str.replace('table','table style=\"display:inline\"'),          raw=True     )  import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos del cuarteto de Anscombe anscombe = sns.load_dataset(\"anscombe\")  # Dividir los datos en cuatro conjuntos seg\u00fan el valor de \"dataset\" ds1 = anscombe[anscombe['dataset'] == 'I'] ds2 = anscombe[anscombe['dataset'] == 'II'] ds3 = anscombe[anscombe['dataset'] == 'III'] ds4 = anscombe[anscombe['dataset'] == 'IV']  # Mostrar estadisticas para cada conjunto print(\"Estadisticas Basicas:\\n\") x=\" \" print(f\"{10*x}Dataset I {13*x}Dataset II\") display_side_by_side(ds1.describe(),ds2.describe()) print() print(f\"{10*x}Dataset III {13*x}Dataset IV\") display_side_by_side(ds3.describe(),ds4.describe())  # Mostrar  correlaciones para cada conjunto print(\"Correlaciones:\\n\")  print(f\"{5*x}Dataset I {10*x}Dataset II {10*x}Dataset III {10*x}Dataset IV\") display_side_by_side(ds1.corr(),ds2.corr(),ds3.corr(),ds4.corr())   print(\"Graficos:\\n\")  # Crear una figura con cuatro subplots fig, axs = plt.subplots(ncols=4, figsize=(16, 4))  # Graficar cada conjunto de datos en su respectivo subplot sns.regplot(x='x', y='y', data=ds1, ax=axs[0], ci=None) sns.regplot(x='x', y='y', data=ds2, ax=axs[1], ci=None) sns.regplot(x='x', y='y', data=ds3, ax=axs[2], ci=None) sns.regplot(x='x', y='y', data=ds4, ax=axs[3], ci=None)  # Agregar t\u00edtulos a los subplots axs[0].set_title('Dataset I') axs[1].set_title('Dataset II') axs[2].set_title('Dataset III') axs[3].set_title('Dataset IV')  # Mostrar el gr\u00e1fico plt.show() <pre>Estadisticas Basicas:\n\n          Dataset I              Dataset II\n</pre> x y count 11.000000 11.000000 mean 9.000000 7.500909 std 3.316625 2.031568 min 4.000000 4.260000 25% 6.500000 6.315000 50% 9.000000 7.580000 75% 11.500000 8.570000 max 14.000000 10.840000 x y count 11.000000 11.000000 mean 9.000000 7.500909 std 3.316625 2.031657 min 4.000000 3.100000 25% 6.500000 6.695000 50% 9.000000 8.140000 75% 11.500000 8.950000 max 14.000000 9.260000 <pre>\n          Dataset III              Dataset IV\n</pre> x y count 11.000000 11.000000 mean 9.000000 7.500000 std 3.316625 2.030424 min 4.000000 5.390000 25% 6.500000 6.250000 50% 9.000000 7.110000 75% 11.500000 7.980000 max 14.000000 12.740000 x y count 11.000000 11.000000 mean 9.000000 7.500909 std 3.316625 2.030579 min 8.000000 5.250000 25% 8.000000 6.170000 50% 8.000000 7.040000 75% 8.000000 8.190000 max 19.000000 12.500000 <pre>Correlaciones:\n\n     Dataset I           Dataset II           Dataset III           Dataset IV\n</pre> x y x 1.000000 0.816421 y 0.816421 1.000000 x y x 1.000000 0.816237 y 0.816237 1.000000 x y x 1.000000 0.816287 y 0.816287 1.000000 x y x 1.000000 0.816521 y 0.816521 1.000000 <pre>Graficos:\n\n</pre> In\u00a0[2]: { \"tags\": [ \"hide-input\" ] } Copied! <pre>import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Crear un DataFrame con los datos\ndata = {'Grupo': ['Grupo 1', 'Grupo 2', 'Grupo 3'], \n        'Tasa de \u00e9xito': [0.9, 0.85, 0.7], \n        'N\u00famero de casos': [100, 200, 300]}\ndf = pd.DataFrame(data)\n\n# Calcular la tasa de \u00e9xito general\ngeneral_success_rate = df['Tasa de \u00e9xito'].mean()\nprint('Tasa de \u00e9xito general:', general_success_rate)\n\n# Graficar los datos\nfig, ax = plt.subplots()\ndf.plot(x='Grupo', y='Tasa de \u00e9xito', kind='bar', ax=ax)\nax.axhline(y=general_success_rate, color='r', linestyle='--')\nax.set_ylabel('Tasa de \u00e9xito')\nax.set_title('Paradoja de Simpson')\nplt.show()\n</pre> import pandas as pd import matplotlib.pyplot as plt  # Crear un DataFrame con los datos data = {'Grupo': ['Grupo 1', 'Grupo 2', 'Grupo 3'],          'Tasa de \u00e9xito': [0.9, 0.85, 0.7],          'N\u00famero de casos': [100, 200, 300]} df = pd.DataFrame(data)  # Calcular la tasa de \u00e9xito general general_success_rate = df['Tasa de \u00e9xito'].mean() print('Tasa de \u00e9xito general:', general_success_rate)  # Graficar los datos fig, ax = plt.subplots() df.plot(x='Grupo', y='Tasa de \u00e9xito', kind='bar', ax=ax) ax.axhline(y=general_success_rate, color='r', linestyle='--') ax.set_ylabel('Tasa de \u00e9xito') ax.set_title('Paradoja de Simpson') plt.show() <pre>Tasa de \u00e9xito general: 0.8166666666666668\n</pre> <p>Otro ejemplo ser\u00eda aplicar un modelo de regresi\u00f3n l\u00edneal al conjunto de datos completos y luego aplicarlo al conjunto de datos separado por categor\u00edas.</p> In\u00a0[3]: { \"tags\": [ \"hide-input\" ] } Copied! <pre>import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n# Generate 'random' data\nnp.random.seed(0)\nX = 2.5 * np.random.randn(100) + 1.5   # Array of 100 values with mean = 1.5, stddev = 2.5\nres = 0.5 * np.random.randn(100)       # Generate 100 residual terms\ny = 2 + 0.3 * X + res                  # Actual values of Y\n\n# Create pandas dataframe to store our X and y values\nds1 = pd.DataFrame({\n    'x': X+10,\n    'y': y+10}\n).assign(label = 'Dataset I')\n\nds2 = pd.DataFrame({\n    'x': X,\n    'y': y}\n).assign(label = 'Dataset II')\n\ndf = pd.concat([ds1,ds2])\n</pre> import pandas as pd import numpy as np from matplotlib import pyplot as plt  # Generate 'random' data np.random.seed(0) X = 2.5 * np.random.randn(100) + 1.5   # Array of 100 values with mean = 1.5, stddev = 2.5 res = 0.5 * np.random.randn(100)       # Generate 100 residual terms y = 2 + 0.3 * X + res                  # Actual values of Y  # Create pandas dataframe to store our X and y values ds1 = pd.DataFrame({     'x': X+10,     'y': y+10} ).assign(label = 'Dataset I')  ds2 = pd.DataFrame({     'x': X,     'y': y} ).assign(label = 'Dataset II')  df = pd.concat([ds1,ds2]) In\u00a0[4]: { \"tags\": [ \"hide-input\" ] } Copied! <pre>print(\"Grafico para todo el conjunto de datos\")\nsns.lmplot (x='x', y='y',  data=df,   ci=None)\nplt.show()\n</pre> print(\"Grafico para todo el conjunto de datos\") sns.lmplot (x='x', y='y',  data=df,   ci=None) plt.show() <pre>Grafico para todo el conjunto de datos\n</pre> In\u00a0[5]: { \"tags\": [ \"hide-input\" ] } Copied! <pre>print(\"Grafico para los grupos por separados\")\nsns.lmplot (x='x', y='y', data=df,    hue='label', ci=None)\nplt.show()\n</pre> print(\"Grafico para los grupos por separados\") sns.lmplot (x='x', y='y', data=df,    hue='label', ci=None) plt.show() <pre>Grafico para los grupos por separados\n</pre> In\u00a0[6]: { \"tags\": [ \"hide-input\" ] } Copied! <pre># Pie chart, where the slices will be ordered and plotted counter-clockwise:\nlabels = 'Frogs', 'Hogs', 'Dogs', 'Logs'\nsizes = [15, 30, 45, 10]\nexplode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')\n\nfig1, ax1 = plt.subplots(figsize=(8, 8))\nax1.pie(\n    sizes,\n    explode=explode,\n    labels=labels,\n    autopct='%1.1f%%',\n    shadow=True,\n    startangle=90\n)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()\n</pre> # Pie chart, where the slices will be ordered and plotted counter-clockwise: labels = 'Frogs', 'Hogs', 'Dogs', 'Logs' sizes = [15, 30, 45, 10] explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'Hogs')  fig1, ax1 = plt.subplots(figsize=(8, 8)) ax1.pie(     sizes,     explode=explode,     labels=labels,     autopct='%1.1f%%',     shadow=True,     startangle=90 ) ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.  plt.show() In\u00a0[7]: { \"tags\": [ \"hide-input\" ] } Copied! <pre>np.random.seed(42)\nN = 31\nx = np.arange(N)\ny1 = 80 + 20 *x / N + 5 * np.random.rand(N)\ny2 = 75 + 25 *x / N + 5 * np.random.rand(N)\nfig, axs = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(16,8))\n\naxs[0][0].plot(x, y1, 'ok')\naxs[0][0].plot(x, y2, 'sk')\n\naxs[0][1].plot(x, y1, 'ob')\naxs[0][1].plot(x, y2, 'or')\n\naxs[1][0].plot(x, y1, 'ob')\naxs[1][0].plot(x, y2, '*k')\n\naxs[1][1].plot(x, y1, 'sr')\naxs[1][1].plot(x, y2, 'ob')\n\nplt.show()\n</pre> np.random.seed(42) N = 31 x = np.arange(N) y1 = 80 + 20 *x / N + 5 * np.random.rand(N) y2 = 75 + 25 *x / N + 5 * np.random.rand(N) fig, axs = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(16,8))  axs[0][0].plot(x, y1, 'ok') axs[0][0].plot(x, y2, 'sk')  axs[0][1].plot(x, y1, 'ob') axs[0][1].plot(x, y2, 'or')  axs[1][0].plot(x, y1, 'ob') axs[1][0].plot(x, y2, '*k')  axs[1][1].plot(x, y1, 'sr') axs[1][1].plot(x, y2, 'ob')  plt.show()"},{"location":"visualization/011_intro/#introduccion","title":"Introducci\u00f3n\u00b6","text":""},{"location":"visualization/011_intro/#introduccion","title":"Introducci\u00f3n\u00b6","text":"<p>Aprender sobre visualizaci\u00f3n es importante por varias razones:</p> <ul> <li><p>Comunicar informaci\u00f3n compleja de manera clara y efectiva: Al presentar datos de una manera visual, es m\u00e1s f\u00e1cil identificar patrones y tendencias, as\u00ed como tambi\u00e9n hacer comparaciones y contrastes. Esto es especialmente importante cuando se trabaja con grandes conjuntos de datos o cuando se trata de presentar informaci\u00f3n a un p\u00fablico diverso.</p> </li> <li><p>Descubrir informaci\u00f3n oculta o desconocida: A menudo, los datos pueden contener patrones o relaciones que no son obvios a simple vista, pero que pueden ser descubiertos mediante la exploraci\u00f3n y la visualizaci\u00f3n. La visualizaci\u00f3n tambi\u00e9n puede ayudar a identificar errores y anomal\u00edas en los datos, lo que puede ser importante para la toma de decisiones y la planificaci\u00f3n.</p> </li> <li><p>Mejorar la capacidad de an\u00e1lisis de datos: Al comprender c\u00f3mo presentar datos de manera efectiva, se puede desarrollar una mejor comprensi\u00f3n de los datos y las relaciones que existen entre ellos. Esto puede ayudar a tomar decisiones informadas basadas en datos y a identificar tendencias y oportunidades que de otra manera podr\u00edan haber pasado desapercibidas.</p> </li> </ul>"},{"location":"visualization/011_intro/#malos-graficos","title":"Malos Gr\u00e1ficos\u00b6","text":""},{"location":"visualization/011_intro/#buenos-graficos","title":"Buenos Gr\u00e1ficos\u00b6","text":""},{"location":"visualization/011_intro/#primeras-visualizaciones","title":"Primeras visualizaciones\u00b6","text":"<p>Campa\u00f1a de Napole\u00f3n a Mosc\u00fa (Charles Minard, 1889)</p> <p>Gr\u00e1fico que muestra el n\u00famero de las fuerzas francesas en su marcha hacia Mosc\u00fa y durante la retirada, por Charles Minard. Tambi\u00e9n contiene informaci\u00f3n ambiental como la temperatura por fecha.</p> <p></p> <p>Mapa del c\u00f3lera (John Snow, 1855)</p> <p>Gr\u00e1fico que muestra los casos de c\u00f3lera durante la epidemia en Londres de 1854 y Las cruces la ubicaci\u00f3n de las bombas de agua.</p> <p></p>"},{"location":"visualization/011_intro/#por-que-utilizar-graficos","title":"\u00bfPor qu\u00e9 utilizar gr\u00e1ficos?\u00b6","text":"<ul> <li><p>El 70 % de los receptores sensoriales del cuerpo humano est\u00e1 dedicado a la visi\u00f3n.</p> </li> <li><p>Cerebro ha sido entrenado evolutivamente para interpretar la informaci\u00f3n visual de manera masiva.</p> <p>\u201cThe eye and the visual cortex of the brain form a massively parallel processor that provides the highest bandwidth channel into human cognitive centers\u201d \u2014 Colin Ware, Information Visualization, 2004.</p> </li> </ul> <p>Nota: En lo siguientes ejemplos utilizaremos c\u00f3digo de <code>matplotlib</code> y <code>seaborn</code>, sin embargo, no entraremos en detalles debido a que cada una de estas librer\u00edas ser\u00e1 estudiada en los siguientes cap\u00edtulos.</p>"},{"location":"visualization/011_intro/#cuarteto-de-anscombe","title":"Cuarteto de ANSCOMBE\u00b6","text":"<p>El Cuarteto de Anscombe es un conjunto de cuatro conjuntos de datos que tienen las mismas estad\u00edsticas descriptivas (medias, varianzas, correlaciones y regresiones), pero que se ven muy diferentes cuando se visualizan. Fueron presentados por el estad\u00edstico Francis Anscombe en 1973 para demostrar la importancia de la visualizaci\u00f3n en el an\u00e1lisis de datos.</p> <p>Los cuatro conjuntos de datos consisten en pares de variables x e y, y cada conjunto representa un tipo diferente de relaci\u00f3n entre las variables. A simple vista, los cuatro conjuntos parecen tener distribuciones y relaciones completamente diferentes entre s\u00ed, pero cuando se analizan las estad\u00edsticas descriptivas, todas son id\u00e9nticas.</p>"},{"location":"visualization/011_intro/#paradoja-de-simpson","title":"Paradoja de Simpson\u00b6","text":"<p>La Paradoja de Simpson es un fen\u00f3meno en la visualizaci\u00f3n de datos que puede ocurrir cuando se analizan datos de diferentes subgrupos o categor\u00edas de una poblaci\u00f3n. La paradoja se produce cuando una tendencia o patr\u00f3n que aparece en cada subgrupo se invierte o desaparece cuando se combinan los datos de todos los subgrupos.</p> <p>Supongamos que tienes datos de la tasa de \u00e9xito de un tratamiento m\u00e9dico para tres grupos de pacientes: uno con edad joven, uno con edad media y uno con edad avanzada. Los datos se presentan en la siguiente tabla:</p> <p>|                 \t| Grupo 1 \t| Grupo 2 \t| Grupo 3 \t| |-----------------\t|---------\t|---------\t|---------\t| | Tasa de \u00e9xito   \t| 90%     \t| 85%     \t| 70%     \t| | N\u00famero de casos \t| 100     \t| 200     \t| 300     \t|</p> <p>En la tabla anterior, se puede observar que la tasa de \u00e9xito general del tratamiento es del 80%. Sin embargo, si se examina cada grupo de forma individual, la tasa de \u00e9xito para cada grupo es mayor en comparaci\u00f3n con el promedio general. Esto es un ejemplo de la Paradoja de Simpson.</p> <p>A continuaci\u00f3n se presenta un c\u00f3digo en Python que ilustra este ejemplo:</p>"},{"location":"visualization/011_intro/#teoria-de-visualizacion","title":"Teor\u00eda de visualizaci\u00f3n\u00b6","text":"<p>La teor\u00eda de visualizaci\u00f3n se refiere a la investigaci\u00f3n y el estudio de c\u00f3mo las personas procesan, interpretan y comprenden informaci\u00f3n visual. La visualizaci\u00f3n puede involucrar cualquier tipo de informaci\u00f3n que pueda ser representada visualmente, incluyendo gr\u00e1ficos, diagramas, mapas, fotograf\u00edas y videos.</p> <p>Algunos de los conceptos y principios importantes en la teor\u00eda de visualizaci\u00f3n incluyen:</p> <ul> <li><p>Percepci\u00f3n visual: C\u00f3mo procesamos y entendemos la informaci\u00f3n visual a trav\u00e9s de nuestros sentidos.</p> </li> <li><p>Cognici\u00f3n visual: C\u00f3mo procesamos y entendemos la informaci\u00f3n visual a trav\u00e9s de nuestros procesos mentales, como la atenci\u00f3n, la memoria y la toma de decisiones.</p> </li> <li><p>Dise\u00f1o visual: C\u00f3mo se pueden crear visualizaciones efectivas y atractivas para comunicar informaci\u00f3n de manera clara y efectiva.</p> </li> <li><p>Interactividad visual: C\u00f3mo las visualizaciones interactivas pueden ayudar a los usuarios a explorar y comprender mejor la informaci\u00f3n visual.</p> </li> </ul>"},{"location":"visualization/011_intro/#consejos-generales","title":"Consejos generales\u00b6","text":"<p>Noah Iliinsky es un experto en visualizaci\u00f3n de datos y ha identificado cuatro pilares fundamentales de la visualizaci\u00f3n.</p> <p>Estos pilares son:</p> <ul> <li><p>Contenido: El contenido se refiere a la informaci\u00f3n que se est\u00e1 visualizando. Para que la visualizaci\u00f3n sea efectiva, es importante tener una comprensi\u00f3n clara del contenido y c\u00f3mo se relaciona con el objetivo de la visualizaci\u00f3n.</p> </li> <li><p>Funci\u00f3n: La funci\u00f3n se refiere al prop\u00f3sito de la visualizaci\u00f3n. \u00bfQu\u00e9 se espera que haga la visualizaci\u00f3n? \u00bfDebe mostrar una tendencia, comparar datos o explorar patrones? Es importante tener en cuenta la funci\u00f3n de la visualizaci\u00f3n para asegurarse de que se est\u00e1 dise\u00f1ando de manera efectiva.</p> </li> <li><p>Forma: La forma se refiere a la apariencia visual de la visualizaci\u00f3n. Esto incluye cosas como el tipo de gr\u00e1fico o diagrama utilizado, la paleta de colores y la tipograf\u00eda. La forma debe ser coherente y legible para que la visualizaci\u00f3n sea f\u00e1cil de entender.</p> </li> <li><p>Audiencia: La audiencia se refiere a las personas que ver\u00e1n la visualizaci\u00f3n. La comprensi\u00f3n de la audiencia es esencial para determinar el nivel de detalle y complejidad adecuados para la visualizaci\u00f3n. La visualizaci\u00f3n debe ser accesible y comprensible para su audiencia objetivo.</p> </li> </ul> <p>Nota: Se recomienda ver el siguiente video para profundizar estos conceptos</p>"},{"location":"visualization/011_intro/#mas-aspectos-de-la-visualizacion","title":"M\u00e1s Aspectos de la Visualizaci\u00f3n\u00b6","text":""},{"location":"visualization/011_intro/#honestidad","title":"Honestidad\u00b6","text":"<p>El ojo humano no tiene la misma precisi\u00f3n al estimar distintas atribuciones:</p> <ul> <li>Largo: Bien estimado y sin sesgo, con un factor multiplicativo de 0.9 a 1.1.</li> <li>\u00c1rea: Subestimado y con sesgo, con un factor multiplicativo de 0.6 a 0.9.</li> <li>Volumen: Muy subestimado y con sesgo, con un factor multiplicativo de 0.5 a 0.8.</li> </ul> <p>Resulta inadecuado realizar gr\u00e1ficos de datos utilizando \u00e1reas o vol\u00famenes si no queda claro la atribuci\u00f3n utilizada. </p> <p>Una pseudo-excepci\u00f3n la constituyen los pie-chart o gr\u00e1ficos circulares, porque el ojo humano distingue bien \u00e1ngulos y segmentos de c\u00edrculo, y porque es posible indicar los porcentajes respectivos.</p>"},{"location":"visualization/011_intro/#priorizacion","title":"Priorizaci\u00f3n\u00b6","text":"<p>Dato m\u00e1s importante debe utilizar elemento de mejor percepci\u00f3n.</p>"},{"location":"visualization/011_intro/#percepcion","title":"Percepci\u00f3n\u00b6","text":"<p>No todos los elementos tienen la misma percepci\u00f3n a nivel del sistema visual. En particular, el color y la forma son elementos preatentivos: un color distinto o una forma distinta se reconocen de manera no conciente.</p> <p>Ejemplos de elementos preatentivos.</p> <p></p> <p></p> <p>El sistema visual humano puede estimar con precisi\u00f3n siguientes atributos visuales:</p> <ol> <li>Posici\u00f3n</li> <li>Largo</li> <li>Pendiente</li> <li>\u00c1ngulo</li> <li>\u00c1rea</li> <li>Volumen</li> <li>Color</li> </ol> <p>Utilice el atributo que se estima con mayor precisi\u00f3n cuando sea posible.</p>"},{"location":"visualization/011_intro/#colormaps","title":"Colormaps\u00b6","text":"<p>Puesto que la percepci\u00f3n del color tiene muy baja precisi\u00f3n, resulta inadecuado tratar de representar un valor num\u00e9rico con colores.</p> <ul> <li>\u00bfQu\u00e9 diferencia num\u00e9rica existe entre el verde y el rojo?</li> <li>\u00bfQue asociaci\u00f3n preexistente posee el color rojo, el amarillo y el verde?</li> <li>\u00bfCon cu\u00e1nta precisi\u00f3n podemos distinguir valores en una escala de grises?</li> </ul> <p></p>"},{"location":"visualization/011_intro/#python-landscape","title":"Python Landscape\u00b6","text":"<p>Para empezar, PyViz es un sitio web que se dedica a ayudar a los usuarios a decidir dentro de las mejores herramientas de visualizaci\u00f3n open-source implementadas en Python, dependiendo de sus necesidades y objetivos. Mucho de lo que se menciona en esta secci\u00f3n est\u00e1 en detalle en la p\u00e1gina web del proyecto PyViz.</p> <p>Algunas de las librer\u00edas de visualizaci\u00f3n de Python m\u00e1s conocidas son:</p> <p></p> <p>Este esquema es una adaptaci\u00f3n de uno presentado en la charla The Python Visualization Landscape realizada por Jake VanderPlas en la PyCon 2017.</p> <p>Cada una de estas librer\u00edas fue creada para satisfacer diferentes necesidades, algunas han ganado m\u00e1s adeptos que otras por uno u otro motivo. Tal como avanza la tecnolog\u00eda, estas librer\u00edas se actualizan o se crean nuevas, la importancia no recae en ser un experto en una, si no en saber adaptarse a las situaciones, tomar la mejor decicisi\u00f3n y escoger seg\u00fan nuestras necesidades y preferencias. Por ejemplo, <code>matplotlib</code> naci\u00f3 como una soluci\u00f3n para imitar los gr\u00e1ficos de <code>MATLAB</code> (puedes ver la historia completa aqu\u00ed), manteniendo una sintaxis similar y con ello poder crear gr\u00e1ficos est\u00e1ticos de muy buen nivel.</p> <p>Debido al \u00e9xito de <code>matplotlib</code> en la comunidad, nacen librer\u00edas basadas ella. Algunos ejemplos son:</p> <ul> <li><code>seaborn</code> se basa en <code>matp\u013aotlib</code> pero su nicho corresponde a las visualizaciones estad\u00edsticas.</li> <li><code>ggpy</code> una suerte de copia a <code>ggplot2</code> perteneciente al lenguaje de programaci\u00f3n <code>R</code>.</li> <li><code>networkx</code> visualizaciones de grafos.</li> <li><code>pandas</code> no es una librer\u00eda de visualizaci\u00f3n propiamente tal, pero utiliza a <code>matplotplib</code> como bakcned en los m\u00e9todos con tal de crear gr\u00e1ficos de manera muy r\u00e1pida, e.g. <code>pandas.DataFrame.plot.bar()</code></li> </ul> <p>Por otro lado, con tal de crear visualizaciones interactivas aparecen librer\u00edas basadas en <code>javascript</code>, algunas de las m\u00e1s conocidas en Python son:</p> <ul> <li><code>bokeh</code> tiene como objetivo proporcionar gr\u00e1ficos vers\u00e1tiles, elegantes e incluso interactivos, teniendo una gran performance con grandes datasets o incluso streaming de datos.</li> <li><code>plotly</code> visualizaciones interactivas que en conjunto a <code>Dash</code> (de la misma empresa) permite crear aplicaciones webs, similar a <code>shiny</code> de <code>R</code>.</li> <li><code>D3.js</code> a pesar de estar basado en <code>javascript</code> se ha ganado un lugar en el coraz\u00f3n de toda la comunidad, debido a la ilimitada cantidad de visualizaciones que son posibles de hacer, por ejemplo, la malla interactiva que hizo un estudiante de la UTFSM est\u00e1 hecha en <code>D3.js</code>.</li> </ul> <p>De las librer\u00edas m\u00e1s recientes est\u00e1 <code>Altair</code>, que consiste en visualizaciones declarativas (ya lo veremos en el pr\u00f3ximo laboratorio). Constru\u00edda sobre <code>Vega-Lite</code>, a su vez que est\u00e9 est\u00e1 sobre <code>Vega</code> y este finalmente sobre <code>D3.js</code>. <code>Altair</code> permite crear visualizaciones est\u00e1ticas e interactivas con pocas l\u00edneas de c\u00f3digo, sin embargo, al ser relativamente nueva, a\u00fan existen funcionalidades en desarrollo o que simplemente a\u00fan no existen en esta librer\u00eda pero en otras si.</p>"},{"location":"visualization/012_types/","title":"Tipos de Gr\u00e1ficos","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [10, 12, 15, 20, 22]\n\nplt.plot(x, y)\nplt.xlabel('Eje x')\nplt.ylabel('Eje y')\nplt.title('Gr\u00e1fico de l\u00edneas')\nplt.show()\n</pre> import matplotlib.pyplot as plt  x = [1, 2, 3, 4, 5] y = [10, 12, 15, 20, 22]  plt.plot(x, y) plt.xlabel('Eje x') plt.ylabel('Eje y') plt.title('Gr\u00e1fico de l\u00edneas') plt.show() In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [10, 12, 15, 20, 22]\n\nplt.scatter(x, y)\nplt.xlabel('Eje x')\nplt.ylabel('Eje y')\nplt.title('Diagrama de dispersi\u00f3n')\nplt.show()\n</pre> import matplotlib.pyplot as plt  x = [1, 2, 3, 4, 5] y = [10, 12, 15, 20, 22]  plt.scatter(x, y) plt.xlabel('Eje x') plt.ylabel('Eje y') plt.title('Diagrama de dispersi\u00f3n') plt.show() In\u00a0[3]: Copied! <pre>import matplotlib.pyplot as plt\n\nx = ['A', 'B', 'C', 'D', 'E']\ny = [100, 200, 150, 300, 250]\n\nplt.bar(x, y)\nplt.xlabel('Productos')\nplt.ylabel('Cantidad vendida')\nplt.title('Ventas por producto')\nplt.show()\n</pre> import matplotlib.pyplot as plt  x = ['A', 'B', 'C', 'D', 'E'] y = [100, 200, 150, 300, 250]  plt.bar(x, y) plt.xlabel('Productos') plt.ylabel('Cantidad vendida') plt.title('Ventas por producto') plt.show() In\u00a0[4]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear un conjunto de datos aleatorios con una distribuci\u00f3n normal\ndata = np.random.randn(10000)\n\n# Crear el histograma con 20 bins y color verde\nplt.hist(data, bins=20,edgecolor='black')\n\n# Agregar etiquetas y t\u00edtulo\nplt.xlabel('Valores')\nplt.ylabel('Frecuencia')\nplt.title('Histograma de valores aleatorios')\n\n# Mostrar el histograma\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear un conjunto de datos aleatorios con una distribuci\u00f3n normal data = np.random.randn(10000)  # Crear el histograma con 20 bins y color verde plt.hist(data, bins=20,edgecolor='black')  # Agregar etiquetas y t\u00edtulo plt.xlabel('Valores') plt.ylabel('Frecuencia') plt.title('Histograma de valores aleatorios')  # Mostrar el histograma plt.show() In\u00a0[5]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear una matriz aleatoria de 5x5\ndata = np.random.rand(5, 5)\n\n# Crear el heatmap con la funci\u00f3n imshow\nplt.imshow(data, cmap='Blues')\n\n# Agregar etiquetas y t\u00edtulo\nplt.colorbar()\nplt.xticks(range(5), ['A', 'B', 'C', 'D', 'E'])\nplt.yticks(range(5), ['1', '2', '3', '4', '5'])\nplt.xlabel('Columnas')\nplt.ylabel('Filas')\nplt.title('Heatmap de una matriz aleatoria')\n\n# Mostrar el heatmap\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear una matriz aleatoria de 5x5 data = np.random.rand(5, 5)  # Crear el heatmap con la funci\u00f3n imshow plt.imshow(data, cmap='Blues')  # Agregar etiquetas y t\u00edtulo plt.colorbar() plt.xticks(range(5), ['A', 'B', 'C', 'D', 'E']) plt.yticks(range(5), ['1', '2', '3', '4', '5']) plt.xlabel('Columnas') plt.ylabel('Filas') plt.title('Heatmap de una matriz aleatoria')  # Mostrar el heatmap plt.show() In\u00a0[6]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear un conjunto de datos aleatorios\ndata = np.random.normal(0, 1, 1000)\n\n# Crear el boxplot\nplt.boxplot(data)\n\n# Agregar etiquetas y t\u00edtulo\nplt.xlabel('Variable X')\nplt.ylabel('Valores')\nplt.title('Boxplot de un conjunto de datos aleatorios')\n\n# Mostrar el boxplot\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear un conjunto de datos aleatorios data = np.random.normal(0, 1, 1000)  # Crear el boxplot plt.boxplot(data)  # Agregar etiquetas y t\u00edtulo plt.xlabel('Variable X') plt.ylabel('Valores') plt.title('Boxplot de un conjunto de datos aleatorios')  # Mostrar el boxplot plt.show() <p>Con el diagrama de boxplot y el histograma, podemos analizar de mejor manera la distribuci\u00f3n de nuestra variable.</p> In\u00a0[7]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear un conjunto de datos aleatorios\ndata = np.random.normal(0, 1, 1000)\n\n# Crear una figura con dos subplots\nfig, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})\n\n# Crear el boxplot\nax_box.boxplot(data, vert=False)\n\n# Crear el histograma\nax_hist.hist(data, bins=10, edgecolor='black')\n\n# Agregar etiquetas y t\u00edtulo\nax_box.set(xlabel='Variable X', ylabel='Valores')\nax_hist.set(xlabel='Variable X', ylabel='Frecuencia')\nplt.suptitle('Boxplot con histograma')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear un conjunto de datos aleatorios data = np.random.normal(0, 1, 1000)  # Crear una figura con dos subplots fig, (ax_box, ax_hist) = plt.subplots(2, sharex=True, gridspec_kw={\"height_ratios\": (.15, .85)})  # Crear el boxplot ax_box.boxplot(data, vert=False)  # Crear el histograma ax_hist.hist(data, bins=10, edgecolor='black')  # Agregar etiquetas y t\u00edtulo ax_box.set(xlabel='Variable X', ylabel='Valores') ax_hist.set(xlabel='Variable X', ylabel='Frecuencia') plt.suptitle('Boxplot con histograma')  # Mostrar el gr\u00e1fico plt.show()"},{"location":"visualization/012_types/#tipos-de-graficos","title":"Tipos de Gr\u00e1ficos\u00b6","text":"<p>En estad\u00edstica, un gr\u00e1fico es una representaci\u00f3n visual de datos que permite resumir, analizar y comunicar informaci\u00f3n de manera efectiva. Los gr\u00e1ficos se utilizan ampliamente en estad\u00edstica para mostrar patrones, tendencias, distribuciones y relaciones entre variables.</p> <p>Algunos de los tipos de gr\u00e1ficos m\u00e1s comunes utilizados en estad\u00edstica incluyen:</p>"},{"location":"visualization/012_types/#grafico-de-linea","title":"Gr\u00e1fico de L\u00ednea\u00b6","text":"<p>Un gr\u00e1fico de l\u00edneas es un tipo de gr\u00e1fico que utiliza una o varias l\u00edneas para mostrar la relaci\u00f3n entre dos o m\u00e1s variables. Es com\u00fanmente utilizado en estad\u00edstica para representar datos num\u00e9ricos a lo largo de un eje horizontal y vertical, y para observar tendencias o cambios en los datos a lo largo del tiempo o de una escala continua.</p> <p>En un gr\u00e1fico de l\u00edneas, cada punto representa el valor de una variable en un momento determinado. Estos puntos se unen mediante una l\u00ednea, lo que permite visualizar la tendencia general de los datos. Adem\u00e1s, se pueden a\u00f1adir m\u00faltiples l\u00edneas en un mismo gr\u00e1fico para comparar diferentes series de datos y observar las diferencias en su comportamiento a lo largo del tiempo o de una escala continua.</p>"},{"location":"visualization/012_types/#grafico-de-dispersion","title":"Gr\u00e1fico de dispersi\u00f3n\u00b6","text":"<p>Un gr\u00e1fico de dispersi\u00f3n es un tipo de gr\u00e1fico que muestra la relaci\u00f3n entre dos variables num\u00e9ricas. En este tipo de gr\u00e1fico, cada punto en el eje horizontal representa un valor de la primera variable, y cada punto en el eje vertical representa un valor de la segunda variable. Los puntos se distribuyen en el gr\u00e1fico seg\u00fan los valores que tienen en ambas variables.</p> <p>Los gr\u00e1fico de dispersi\u00f3n son \u00fatiles para observar si existe una relaci\u00f3n entre dos variables y c\u00f3mo se relacionan entre s\u00ed. Si los puntos est\u00e1n agrupados de manera que forman una l\u00ednea o una curva, esto sugiere una relaci\u00f3n entre las dos variables. Si los puntos est\u00e1n dispersos aleatoriamente, esto sugiere que no hay una relaci\u00f3n clara entre las dos variables.</p>"},{"location":"visualization/012_types/#grafico-de-barras","title":"Gr\u00e1fico de barras\u00b6","text":"<p>Un gr\u00e1fico de barras es un tipo de gr\u00e1fico utilizado para representar datos num\u00e9ricos mediante barras rectangulares, donde la longitud de cada barra representa la magnitud de la cantidad correspondiente. Este tipo de gr\u00e1fico es \u00fatil para comparar datos entre diferentes categor\u00edas o grupos.</p> <p>En un gr\u00e1fico de barras, cada barra representa una categor\u00eda o grupo, y la altura o longitud de la barra representa el valor num\u00e9rico de la cantidad que se est\u00e1 midiendo. Las barras pueden ser horizontales o verticales, dependiendo de la preferencia del usuario o de la forma en que se ajuste mejor a los datos.</p>"},{"location":"visualization/012_types/#histograma","title":"Histograma\u00b6","text":"<p>Un histograma es un tipo de gr\u00e1fico utilizado en estad\u00edstica para representar la distribuci\u00f3n de frecuencia de un conjunto de datos num\u00e9ricos. En un histograma, los datos se dividen en rangos o intervalos (tambi\u00e9n conocidos como \"bins\" o \"clases\"), y se cuenta cu\u00e1ntas veces aparece un valor dentro de cada rango. Estas frecuencias se representan mediante barras rectangulares, donde la altura de cada barra representa la frecuencia de los valores en ese rango.</p> <p>Los histogramas son \u00fatiles para visualizar la distribuci\u00f3n de frecuencias de un conjunto de datos, lo que permite identificar patrones, tendencias y valores at\u00edpicos. Tambi\u00e9n se pueden utilizar para comparar la distribuci\u00f3n de diferentes conjuntos de datos.</p>"},{"location":"visualization/012_types/#heatmap","title":"Heatmap\u00b6","text":"<p>Un heatmap (mapa de calor en espa\u00f1ol) es un tipo de gr\u00e1fico que utiliza colores para representar la magnitud de una variable en una matriz o tabla de datos. En un heatmap, cada celda de la matriz se colorea en funci\u00f3n de su valor, de tal manera que los valores m\u00e1s altos se representan con colores m\u00e1s intensos y los valores m\u00e1s bajos con colores m\u00e1s suaves.</p> <p>Los heatmaps son especialmente \u00fatiles para visualizar grandes cantidades de datos en forma de matrices, ya que permiten identificar patrones, tendencias y valores at\u00edpicos de manera m\u00e1s eficiente que si se utilizaran tablas num\u00e9ricas. Por ejemplo, se pueden utilizar para visualizar patrones de tr\u00e1fico en una red de computadoras, o para mostrar la correlaci\u00f3n entre distintas variables en un conjunto de datos.</p>"},{"location":"visualization/012_types/#boxplot","title":"Boxplot\u00b6","text":"<p>Un boxplot (tambi\u00e9n conocido como diagrama de caja y bigotes) es una herramienta gr\u00e1fica utilizada para representar la distribuci\u00f3n de un conjunto de datos num\u00e9ricos a trav\u00e9s de su cuartil, valores m\u00ednimos y m\u00e1ximos, y outliers (datos extremos).</p> <p>El boxplot se dibuja a partir de cinco estad\u00edsticas descriptivas de los datos:</p> <ul> <li>El m\u00ednimo (valor m\u00e1s peque\u00f1o)</li> <li>El primer cuartil (Q1) que representa el valor donde el 25% de los datos son menores y el 75% son mayores.</li> <li>La mediana (Q2), que representa el valor donde el 50% de los datos son menores y el 50% son mayores.</li> <li>El tercer cuartil (Q3) que representa el valor donde el 75% de los datos son menores y el 25% son mayores.</li> <li>El m\u00e1ximo (valor m\u00e1s grande).</li> </ul> <p>El boxplot consta de una caja que se extiende desde el primer al tercer cuartil, con una l\u00ednea en la caja que representa la mediana. Los \"bigotes\" se extienden desde la caja hasta los valores m\u00ednimo y m\u00e1ximo, excluyendo los outliers (datos at\u00edpicos), que se grafican como puntos fuera de los bigotes.</p> <p></p>"},{"location":"visualization/021_matplotlib/","title":"Matplotlib","text":""},{"location":"visualization/021_matplotlib/#matplotlib","title":"Matplotlib\u00b6","text":""},{"location":"visualization/021_matplotlib/#visualizacion-imperativa","title":"Visualizaci\u00f3n Imperativa\u00b6","text":"<p>Este paradigma se focaliza en las instrucciones recibidas, ya que no abstrae las operaciones o codificaciones visuales. Algunas de sus caracter\u00edsticas son:</p> <ul> <li>Se especifica C\u00f3mo se debe hacer algo.</li> <li>Se deben especificar manualmente los pasos del trazado.</li> <li>Especificaci\u00f3n y ejecuci\u00f3n entrelazadas.</li> </ul> <p>Coloquialmente se puede entender como que se debe decidir pixel a pixel lo que se desea mostrar.</p>"},{"location":"visualization/021_matplotlib/#acerca-de-matplotlib","title":"Acerca de Matplotlib\u00b6","text":"<p>Matplotlib es una biblioteca para la generaci\u00f3n de gr\u00e1ficos a partir de datos contenidos en listas o arrays en el lenguaje de programaci\u00f3n Python y su extensi\u00f3n matem\u00e1tica NumPy. Proporciona una API, pylab, dise\u00f1ada para recordar a la de MATLAB.</p> <p>En matplotlib todo est\u00e1 organizado en una jerarqu\u00eda:</p> <ul> <li><p>En la parte superior se encuentra el m\u00f3dulo <code>matplotlib.pyplot</code>. En este nivel, se utilizan funciones simples para agregar elementos de trazado (l\u00edneas, im\u00e1genes, texto, etc.) a los ejes actuales en la figura actual.</p> </li> <li><p>El siguiente nivel en la jerarqu\u00eda es el primer nivel de la interfaz orientada a objetos, en la que pyplot se usa solo para algunas funciones, como la creaci\u00f3n de figuras, y el usuario crea y realiza un seguimiento expl\u00edcito de los objetos de figuras y ejes. En este nivel, el usuario usa pyplot para crear figuras, y a trav\u00e9s de esas figuras, se pueden crear uno o m\u00e1s objetos de ejes.</p> </li> </ul>"},{"location":"visualization/021_matplotlib/#componentes-de-un-grafico","title":"Componentes de un gr\u00e1fico\u00b6","text":""},{"location":"visualization/021_matplotlib/#figure","title":"Figure\u00b6","text":"<p>Es la visualizaci\u00f3n completa. Figure realiza un seguimiento de todos los Axes hijos y el Canvas. Una figura puede tener cualquier n\u00famero de Axes, pero para ser \u00fatil debe tener al menos uno.</p> <p>La forma m\u00e1s f\u00e1cil de crear una nueva Figure es con pyplot:</p> <pre>fig = plt.figure()  # an empty figure with no axes\n\nfig, ax_lst = plt.subplots(2, 2)  # a figure with a 2x2 grid of Axes\n</pre>"},{"location":"visualization/021_matplotlib/#axes","title":"Axes\u00b6","text":"<p>Esto es lo que se puede pensar como 'un gr\u00e1fico', es la regi\u00f3n de la imagen con el espacio de datos. Un Figure dada puede contener muchos Axes, pero un objeto Axe dado solo puede estar en un Figure. Axes contiene dos (o tres en el caso de 3D) objetos Axis que se ocupan de los l\u00edmites de datos. Cada Axe tiene un t\u00edtulo, una etiqueta para el eje horizonal y una etiqueta para el eje vertical.</p> <p>La clase Axes y sus funciones son el punto de entrada principal para trabajar con la interfaz orientada a objetos.</p>"},{"location":"visualization/021_matplotlib/#axis","title":"Axis\u00b6","text":"<p>Corresponden a los ejes, algo as\u00ed como l\u00edneas rectas. Se encargan de establecer los l\u00edmites del gr\u00e1fico y generar los ticks (las marcas en el eje) y los ticklabels (strings que etiquetan los ticks).</p>"},{"location":"visualization/021_matplotlib/#referencias","title":"Referencias\u00b6","text":"<ol> <li>Gallery-matplotlib</li> </ol>"},{"location":"visualization/022_lineplot/","title":"Line Plots","text":"In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [1, 4, 2, 5, 3]\n\nplt.plot(x, y)\nplt.show()\n</pre> import matplotlib.pyplot as plt  x = [1, 2, 3, 4, 5] y = [1, 4, 2, 5, 3]  plt.plot(x, y) plt.show() <p>En este ejemplo, se est\u00e1n trazando dos listas de valores, <code>x</code> e <code>y</code>, donde los valores de x representan los puntos en el eje x y los valores de y representan los puntos en el eje <code>y</code>. La funci\u00f3n <code>plot</code> se utiliza para trazar los puntos en un gr\u00e1fico de l\u00ednea.</p> <p>Puede personalizar el gr\u00e1fico de l\u00ednea de varias formas, incluyendo la elecci\u00f3n del color y estilo de l\u00ednea. Por ejemplo, puede usar la cadena de formato <code>'ro-'</code> para dibujar puntos rojos interconectados con una l\u00ednea s\u00f3lida:</p> In\u00a0[4]: Copied! <pre>import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [1, 4, 2, 5, 3]\n\nplt.plot(x, y, 'ro-')\nplt.show()\n</pre> import matplotlib.pyplot as plt  x = [1, 2, 3, 4, 5] y = [1, 4, 2, 5, 3]  plt.plot(x, y, 'ro-') plt.show() <p>Tambi\u00e9n puede agregar etiquetas de eje y un t\u00edtulo al gr\u00e1fico utilizando las funciones <code>xlabel</code>, <code>ylabel</code> y <code>title</code>:</p> In\u00a0[5]: Copied! <pre>import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [1, 4, 2, 5, 3]\n\nplt.plot(x, y, 'ro-')\nplt.xlabel('Eje X')\nplt.ylabel('Eje Y')\nplt.title('Gr\u00e1fico de l\u00ednea')\nplt.show()\n</pre> import matplotlib.pyplot as plt  x = [1, 2, 3, 4, 5] y = [1, 4, 2, 5, 3]  plt.plot(x, y, 'ro-') plt.xlabel('Eje X') plt.ylabel('Eje Y') plt.title('Gr\u00e1fico de l\u00ednea') plt.show() <p>Matplotlib tambi\u00e9n le permite trazar varias l\u00edneas en un solo gr\u00e1fico utilizando la funci\u00f3n <code>plot</code> varias veces. Puede usar la funci\u00f3n <code>legend</code> para agregar una leyenda que indique qu\u00e9 l\u00ednea representa cada conjunto de datos:</p> In\u00a0[6]: Copied! <pre>import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny1 = [1, 4, 2, 5, 3]\ny2 = [3, 1, 4, 2, 6]\n\nplt.plot(x, y1, 'ro-', label='Conjunto de datos 1')\nplt.plot(x, y2, 'bs-', label='Conjunto de datos 2')\nplt.xlabel('Eje X')\nplt.ylabel('Eje Y')\nplt.title('Gr\u00e1fico de l\u00ednea')\nplt.legend()\nplt.show()\n</pre> import matplotlib.pyplot as plt  x = [1, 2, 3, 4, 5] y1 = [1, 4, 2, 5, 3] y2 = [3, 1, 4, 2, 6]  plt.plot(x, y1, 'ro-', label='Conjunto de datos 1') plt.plot(x, y2, 'bs-', label='Conjunto de datos 2') plt.xlabel('Eje X') plt.ylabel('Eje Y') plt.title('Gr\u00e1fico de l\u00ednea') plt.legend() plt.show() <p>En este ejemplo, se est\u00e1n trazando dos conjuntos de datos, <code>y1</code> y <code>y2</code>, y se ha agregado una leyenda que indica qu\u00e9 conjunto de datos representa cada l\u00ednea.</p>"},{"location":"visualization/022_lineplot/#line-plots","title":"Line Plots\u00b6","text":"<p>Los gr\u00e1ficos de l\u00ednea (line plot) son una de las formas m\u00e1s comunes de visualizar datos. Quiz\u00e1s la m\u00e1s simple de todas las gr\u00e1ficas es la visualizaci\u00f3n de una sola funci\u00f3n $y = f(x)$.</p>"},{"location":"visualization/023_scatterplot/","title":"Scatter Plots","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\n\nx = [1, 2, 3, 4, 5]\ny = [1, 4, 2, 5, 3]\n\nplt.scatter(x, y)\nplt.show()\n</pre> import matplotlib.pyplot as plt  x = [1, 2, 3, 4, 5] y = [1, 4, 2, 5, 3]  plt.scatter(x, y) plt.show() <ol> <li>Gr\u00e1fico de dispersi\u00f3n con diferentes colores y tama\u00f1os de puntos: En este ejemplo, cada punto se traza con un tama\u00f1o y color diferente. La lista de colores especifica el color de cada punto, mientras que la matriz de tama\u00f1os especifica el tama\u00f1o de cada punto.</li> </ol> In\u00a0[7]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nx = [1, 2, 3, 4, 5]\ny = [1, 4, 2, 5, 3]\ncolors = ['red', 'green', 'blue', 'orange', 'purple']\nsizes = np.array([10, 50, 100, 150, 200])\n\nplt.scatter(x, y, s=sizes, c=colors)\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  x = [1, 2, 3, 4, 5] y = [1, 4, 2, 5, 3] colors = ['red', 'green', 'blue', 'orange', 'purple'] sizes = np.array([10, 50, 100, 150, 200])  plt.scatter(x, y, s=sizes, c=colors) plt.show() <ol> <li>Gr\u00e1fico de dispersi\u00f3n con diferentes formas de punto: En este ejemplo, se han generado 50 puntos de datos aleatorios y se han dividido en 10 grupos de 5 puntos cada uno.</li> </ol> In\u00a0[9]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nx = np.random.rand(50)\ny = np.random.rand(50)\nshapes = ['o', 's', 'd', '*', '+', 'x', 'p', 'h', 'v', '^'] # formas\n\nfor i in range(10):\n    xi = x[i*5:(i+1)*5]\n    yi = y[i*5:(i+1)*5]\n    plt.scatter(xi, yi, marker=shapes[i])\n\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  x = np.random.rand(50) y = np.random.rand(50) shapes = ['o', 's', 'd', '*', '+', 'x', 'p', 'h', 'v', '^'] # formas  for i in range(10):     xi = x[i*5:(i+1)*5]     yi = y[i*5:(i+1)*5]     plt.scatter(xi, yi, marker=shapes[i])  plt.show()"},{"location":"visualization/023_scatterplot/#scatter-plots","title":"Scatter Plots\u00b6","text":"<p>Un gr\u00e1fico de dispersi\u00f3n (scatter plot)  es un tipo de gr\u00e1fico que se utiliza para representar la relaci\u00f3n entre dos variables num\u00e9ricas. Matplotlib es una biblioteca de visualizaci\u00f3n de datos de Python que puede utilizarse para crear scatter plots.</p> <p>Aqu\u00ed hay algunos ejemplos de c\u00f3mo crear scatter plots con Matplotlib en Python:</p> <ol> <li>Gr\u00e1fico de dispersi\u00f3n simple: veamos el ejemplo m\u00e1s sencillo ocupando directamente el comando <code>plt.scatter</code>.</li> </ol>"},{"location":"visualization/024_barplot/","title":"Bar Plots","text":"<ol> <li>Gr\u00e1fico de barras verticales simples: En este ejemplo, se han utilizado las listas <code>labels</code> y <code>values</code> para representar los datos que se mostrar\u00e1n en el gr\u00e1fico. Se ha utilizado la funci\u00f3n <code>bar()</code> para crear el gr\u00e1fico de barras.</li> </ol> In\u00a0[3]: Copied! <pre>import matplotlib.pyplot as plt\n\nlabels = ['A', 'B', 'C', 'D', 'E']\nvalues = [10, 5, 8, 12, 6]\n\nplt.bar(labels, values)\nplt.xlabel('Categor\u00edas')\nplt.ylabel('Valores')\nplt.title('Gr\u00e1fico de barras')\nplt.show()\n</pre> import matplotlib.pyplot as plt  labels = ['A', 'B', 'C', 'D', 'E'] values = [10, 5, 8, 12, 6]  plt.bar(labels, values) plt.xlabel('Categor\u00edas') plt.ylabel('Valores') plt.title('Gr\u00e1fico de barras') plt.show() <ol> <li>Gr\u00e1fico de barras horizontales con colores personalizados: En este ejemplo, se ha utilizado la funci\u00f3n <code>barh()</code> para crear un gr\u00e1fico de barras horizontal. Los colores de las barras se han asignado al azar utilizando la funci\u00f3n <code>np.random.rand()</code>. Adem\u00e1s, se han agregado etiquetas de eje <code>y</code> un t\u00edtulo al gr\u00e1fico utilizando las funciones <code>xlabel()</code>, <code>ylabel()</code> y <code>title()</code>.</li> </ol> In\u00a0[5]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nlabels = ['A', 'B', 'C', 'D', 'E']\nvalues = [10, 5, 8, 12, 6]\ncolors = ['blue','red','green','yellow','black']\n\nplt.barh(labels, values, color=colors)\nplt.xlabel('Valores')\nplt.ylabel('Categor\u00edas')\nplt.title('Gr\u00e1fico de barras')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  labels = ['A', 'B', 'C', 'D', 'E'] values = [10, 5, 8, 12, 6] colors = ['blue','red','green','yellow','black']  plt.barh(labels, values, color=colors) plt.xlabel('Valores') plt.ylabel('Categor\u00edas') plt.title('Gr\u00e1fico de barras') plt.show() <ol> <li>Gr\u00e1fico de barras agrupadas con varias series de datos: En este ejemplo, se han utilizado dos listas de valores (<code>men_means</code> y <code>women_means</code>) para representar dos series de datos que se mostrar\u00e1n en el gr\u00e1fico. Se han utilizado las funciones <code>bar()</code> y <code>subplots()</code> para crear un gr\u00e1fico de barras agrupadas con dos series de datos. Adem\u00e1s, se han agregado etiquetas de eje, un t\u00edtulo, leyendas y un eje x personalizado al gr\u00e1fico utilizando varias funciones de Matplotlib.</li> </ol> In\u00a0[6]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\nlabels = ['A', 'B', 'C', 'D', 'E']\nmen_means = [20, 35, 30, 35, 27]\nwomen_means = [25, 32, 34, 20, 25]\nind = np.arange(len(labels))\nwidth = 0.35\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(ind - width/2, men_means, width, label='Hombres')\nrects2 = ax.bar(ind + width/2, women_means, width, label='Mujeres')\n\nax.set_xlabel('Categor\u00edas')\nax.set_ylabel('Valores')\nax.set_title('Gr\u00e1fico de barras agrupadas')\nax.set_xticks(ind)\nax.set_xticklabels(labels)\nax.legend()\n\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  labels = ['A', 'B', 'C', 'D', 'E'] men_means = [20, 35, 30, 35, 27] women_means = [25, 32, 34, 20, 25] ind = np.arange(len(labels)) width = 0.35  fig, ax = plt.subplots() rects1 = ax.bar(ind - width/2, men_means, width, label='Hombres') rects2 = ax.bar(ind + width/2, women_means, width, label='Mujeres')  ax.set_xlabel('Categor\u00edas') ax.set_ylabel('Valores') ax.set_title('Gr\u00e1fico de barras agrupadas') ax.set_xticks(ind) ax.set_xticklabels(labels) ax.legend()  plt.show()"},{"location":"visualization/024_barplot/#bar-plots","title":"Bar Plots\u00b6","text":"<p>Un gr\u00e1fico de Barras (bar plot) es una visualizaci\u00f3n que representa datos discretos utilizando barras rectangulares, donde la longitud de cada barra representa la magnitud de los datos. Los datos discretos pueden ser variables categ\u00f3ricas o variables num\u00e9ricas agrupadas en intervalos.</p>"},{"location":"visualization/025_histplot/","title":"Hist Plots","text":"<ol> <li>Histograma simple</li> </ol> In\u00a0[11]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear datos de ejemplo\nnp.random.seed(0)\ndatos = np.random.randn(1000)\n\n# Crear histograma\nplt.hist(datos, bins=30, color='blue', edgecolor='black')\nplt.xlabel('Valor')\nplt.ylabel('Frecuencia')\nplt.title('Histograma Simple')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear datos de ejemplo np.random.seed(0) datos = np.random.randn(1000)  # Crear histograma plt.hist(datos, bins=30, color='blue', edgecolor='black') plt.xlabel('Valor') plt.ylabel('Frecuencia') plt.title('Histograma Simple') plt.show() <ol> <li>Histograma con rango personalizado</li> </ol> In\u00a0[12]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear datos de ejemplo\nnp.random.seed(0)\ndatos = np.random.randn(1000)\n\n# Crear histograma con rango personalizado\nplt.hist(datos, bins=30, range=(-3, 3), color='green', edgecolor='black')\nplt.xlabel('Valor')\nplt.ylabel('Frecuencia')\nplt.title('Histograma con rango personalizado')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear datos de ejemplo np.random.seed(0) datos = np.random.randn(1000)  # Crear histograma con rango personalizado plt.hist(datos, bins=30, range=(-3, 3), color='green', edgecolor='black') plt.xlabel('Valor') plt.ylabel('Frecuencia') plt.title('Histograma con rango personalizado') plt.show() <ol> <li>Histograma con m\u00faltiples conjuntos de datos</li> </ol> In\u00a0[10]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear datos de ejemplo\nnp.random.seed(0)\ndatos1 = np.random.randn(1000)\ndatos2 = np.random.randn(1000) + 2\n\n# Crear histograma con m\u00faltiples conjuntos de datos\nplt.hist([datos1, datos2], bins=40, color=['blue', 'orange'], edgecolor='black', label=['Datos 1', 'Datos 2'])\nplt.legend()\nplt.xlabel('Valor')\nplt.ylabel('Frecuencia')\nplt.title('Histograma con m\u00faltiples conjuntos de datos')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear datos de ejemplo np.random.seed(0) datos1 = np.random.randn(1000) datos2 = np.random.randn(1000) + 2  # Crear histograma con m\u00faltiples conjuntos de datos plt.hist([datos1, datos2], bins=40, color=['blue', 'orange'], edgecolor='black', label=['Datos 1', 'Datos 2']) plt.legend() plt.xlabel('Valor') plt.ylabel('Frecuencia') plt.title('Histograma con m\u00faltiples conjuntos de datos') plt.show()  <p>En este ejemplo, se han creado dos conjuntos de datos de ejemplo (<code>datos1</code> y <code>datos2</code>) utilizando la funci\u00f3n <code>randn()</code> de NumPy. Luego se ha utilizado la funci\u00f3n <code>hist()</code> para crear el histograma con m\u00faltiples conjuntos de datos, especificando la lista de conjuntos de datos en lugar de un solo conjunto de datos y agregando una etiqueta de leyenda para cada conjunto de datos utilizando el par\u00e1metro <code>label</code>. La leyenda se muestra utilizando la funci\u00f3n <code>legend()</code>.</p> In\u00a0[13]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear datos de ejemplo\nnp.random.seed(0)\nx = np.random.randn(1000)\ny = np.random.randn(1000)\n\n# Crear histograma bidimensional\nplt.hist2d(x, y, bins=30, cmap='Blues')\nplt.colorbar()\nplt.xlabel('Variable X')\nplt.ylabel('Variable Y')\nplt.title('Histograma bidimensional de ejemplo')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear datos de ejemplo np.random.seed(0) x = np.random.randn(1000) y = np.random.randn(1000)  # Crear histograma bidimensional plt.hist2d(x, y, bins=30, cmap='Blues') plt.colorbar() plt.xlabel('Variable X') plt.ylabel('Variable Y') plt.title('Histograma bidimensional de ejemplo') plt.show() <p>En este ejemplo, se han creado dos conjuntos de datos de ejemplo (<code>x</code> e <code>y</code>) utilizando la funci\u00f3n <code>randn()</code> de NumPy. Luego se ha utilizado la funci\u00f3n <code>hist2d()</code> para crear el histograma bidimensional, especificando el n\u00famero de bins en 30 y la paleta de colores en 'Blues'. Tambi\u00e9n se ha agregado una barra de color para la leyenda utilizando la funci\u00f3n colorbar(), y se han agregado etiquetas de eje y un t\u00edtulo al gr\u00e1fico utilizando las funciones <code>xlabel()</code>, <code>ylabel()</code> y <code>title()</code>.</p> <p>Veamos m\u00e1s ejemplos:</p> <ol> <li>Histograma bidimensional con hex\u00e1gonos</li> </ol> In\u00a0[15]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear datos de ejemplo\nnp.random.seed(0)\nx = np.random.randn(1000)\ny = np.random.randn(1000)\n\n# Crear histograma bidimensional con hex\u00e1gonos\nplt.hexbin(x, y, gridsize=30, cmap='Greens')\nplt.colorbar()\nplt.xlabel('Variable X')\nplt.ylabel('Variable Y')\nplt.title('Histograma bidimensional con hex\u00e1gonos de ejemplo')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear datos de ejemplo np.random.seed(0) x = np.random.randn(1000) y = np.random.randn(1000)  # Crear histograma bidimensional con hex\u00e1gonos plt.hexbin(x, y, gridsize=30, cmap='Greens') plt.colorbar() plt.xlabel('Variable X') plt.ylabel('Variable Y') plt.title('Histograma bidimensional con hex\u00e1gonos de ejemplo') plt.show()  <ol> <li>Histograma bidimensional con rango personalizado</li> </ol> In\u00a0[16]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear datos de ejemplo\nnp.random.seed(0)\nx = np.random.randn(1000)\ny = np.random.randn(1000)\n\n# Crear histograma bidimensional con rango personalizado\nplt.hist2d(x, y, bins=30, range=[[-3, 3], [-3, 3]], cmap='Reds')\nplt.colorbar()\nplt.xlabel('Variable X')\nplt.ylabel('Variable Y')\nplt.title('Histograma bidimensional con rango personalizado de ejemplo')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear datos de ejemplo np.random.seed(0) x = np.random.randn(1000) y = np.random.randn(1000)  # Crear histograma bidimensional con rango personalizado plt.hist2d(x, y, bins=30, range=[[-3, 3], [-3, 3]], cmap='Reds') plt.colorbar() plt.xlabel('Variable X') plt.ylabel('Variable Y') plt.title('Histograma bidimensional con rango personalizado de ejemplo') plt.show()"},{"location":"visualization/025_histplot/#hist-plots","title":"Hist Plots\u00b6","text":""},{"location":"visualization/025_histplot/#histograma-univariado","title":"Histograma univariado\u00b6","text":"<p>Para crear un histograma en Matplotlib en Python, se puede utilizar la funci\u00f3n <code>hist()</code>. Esta funci\u00f3n toma como argumento el conjunto de datos a graficar y permite personalizar el n\u00famero de <code>bins</code>, <code>color</code>, <code>range</code>, entre otros.</p>"},{"location":"visualization/025_histplot/#histograma-bidimensional","title":"Histograma bidimensional\u00b6","text":"<p>Un histograma bidimensional (gr\u00e1fico de densidad de dos dimensiones) es una representaci\u00f3n gr\u00e1fica de la distribuci\u00f3n de frecuencia de dos variables continuas. En Python, se puede crear un histograma bidimensional utilizando la funci\u00f3n <code>hist2d()</code> de la librer\u00eda Matplotlib. Esta funci\u00f3n toma como argumentos los dos conjuntos de datos a graficar y permite personalizar el n\u00famero de bins, color, rango, entre otros. Aqu\u00ed hay un ejemplo b\u00e1sico de c\u00f3mo crear un histograma bidimensional en Matplotlib:</p>"},{"location":"visualization/026_heatmap/","title":"Heat Map","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear datos de ejemplo\nnp.random.seed(0)\ndata = np.random.randn(10, 10)\n\n# Crear mapa de calor\nplt.imshow(data, cmap='coolwarm')\nplt.colorbar()\nplt.title('Mapa de calor de ejemplo')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear datos de ejemplo np.random.seed(0) data = np.random.randn(10, 10)  # Crear mapa de calor plt.imshow(data, cmap='coolwarm') plt.colorbar() plt.title('Mapa de calor de ejemplo') plt.show() <p>En este ejemplo, se ha creado una matriz de 10x10 de datos de ejemplo utilizando la funci\u00f3n <code>randn()</code> de NumPy. Luego, se ha utilizado la funci\u00f3n <code>imshow()</code> para mostrar la matriz de datos como un mapa de calor en la escala de colores <code>\"coolwarm\"</code>. Se ha agregado una barra de color con el comando <code>colorbar()</code> y se ha agregado un t\u00edtulo con el comando <code>title()</code>.</p> <p>Veamos m\u00e1s ejemplos:</p> <ol> <li>Mapa de calor con valores num\u00e9ricos</li> </ol> In\u00a0[6]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear datos de ejemplo\nnp.random.seed(0)\ndata = np.random.randn(10, 10)\n\n# Crear mapa de calor con valores num\u00e9ricos\nfig, ax = plt.subplots()\nim = ax.imshow(data, cmap='coolwarm')\ncbar = ax.figure.colorbar(im, ax=ax)\ncbar.ax.set_ylabel('Valor num\u00e9rico', rotation=-90, va=\"bottom\")\nax.set_title('Mapa de calor con valores num\u00e9ricos')\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear datos de ejemplo np.random.seed(0) data = np.random.randn(10, 10)  # Crear mapa de calor con valores num\u00e9ricos fig, ax = plt.subplots() im = ax.imshow(data, cmap='coolwarm') cbar = ax.figure.colorbar(im, ax=ax) cbar.ax.set_ylabel('Valor num\u00e9rico', rotation=-90, va=\"bottom\") ax.set_title('Mapa de calor con valores num\u00e9ricos') plt.show()  <ol> <li>Mapa de calor con anotaciones de texto</li> </ol> In\u00a0[10]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Crear datos de ejemplo\nnp.random.seed(0)\ndata = np.random.randn(10, 10)\n\n# Crear mapa de calor con anotaciones de texto\nfig, ax = plt.subplots()\nim = ax.imshow(data, cmap='coolwarm')\ncbar = ax.figure.colorbar(im, ax=ax)\ncbar.ax.set_ylabel('Valor num\u00e9rico', rotation=-90, va=\"bottom\")\nax.set_title('Mapa de calor con anotaciones de texto')\nfor i in range(data.shape[0]):\n    for j in range(data.shape[1]):\n        text = ax.text(j, i, '{:.1f}'.format(data[i, j]),\n                       ha=\"center\", va=\"center\", color=\"black\")\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Crear datos de ejemplo np.random.seed(0) data = np.random.randn(10, 10)  # Crear mapa de calor con anotaciones de texto fig, ax = plt.subplots() im = ax.imshow(data, cmap='coolwarm') cbar = ax.figure.colorbar(im, ax=ax) cbar.ax.set_ylabel('Valor num\u00e9rico', rotation=-90, va=\"bottom\") ax.set_title('Mapa de calor con anotaciones de texto') for i in range(data.shape[0]):     for j in range(data.shape[1]):         text = ax.text(j, i, '{:.1f}'.format(data[i, j]),                        ha=\"center\", va=\"center\", color=\"black\") plt.show()"},{"location":"visualization/026_heatmap/#heat-map","title":"Heat Map\u00b6","text":"<p>En Matplotlib, se puede crear un mapa de calor (\"heatmap\") mediante el uso de la funci\u00f3n <code>imshow()</code> para mostrar una matriz de valores como una imagen en color. El mapa de calor es una forma efectiva de visualizar datos 2D en una escala de colores.</p> <p>Aqu\u00ed hay un ejemplo de c\u00f3mo crear un mapa de calor en Matplotlib en Python:</p>"},{"location":"visualization/027_boxplot/","title":"Boxplot","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Generar un conjunto de datos aleatorios\ndata = np.random.normal(size=100)\n\n# Crear el box plot\nfig, ax = plt.subplots()\nax.boxplot(data)\n\n# Agregar etiquetas y t\u00edtulo\nax.set_title('Box plot simple')\nax.set_xlabel('Datos')\nax.set_ylabel('Valores')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Generar un conjunto de datos aleatorios data = np.random.normal(size=100)  # Crear el box plot fig, ax = plt.subplots() ax.boxplot(data)  # Agregar etiquetas y t\u00edtulo ax.set_title('Box plot simple') ax.set_xlabel('Datos') ax.set_ylabel('Valores')  # Mostrar el gr\u00e1fico plt.show() <ul> <li>Box plot con varias distribuciones:</li> </ul> In\u00a0[2]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Generar tres conjuntos de datos aleatorios\ndata1 = np.random.normal(0, 1, 100)\ndata2 = np.random.normal(3, 1, 100)\ndata3 = np.random.normal(5, 1, 100)\n\n# Crear el box plot con tres distribuciones\nfig, ax = plt.subplots()\nax.boxplot([data1, data2, data3])\n\n# Agregar etiquetas y t\u00edtulo\nax.set_title('Box plot con varias distribuciones')\nax.set_xlabel('Conjuntos de datos')\nax.set_ylabel('Valores')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Generar tres conjuntos de datos aleatorios data1 = np.random.normal(0, 1, 100) data2 = np.random.normal(3, 1, 100) data3 = np.random.normal(5, 1, 100)  # Crear el box plot con tres distribuciones fig, ax = plt.subplots() ax.boxplot([data1, data2, data3])  # Agregar etiquetas y t\u00edtulo ax.set_title('Box plot con varias distribuciones') ax.set_xlabel('Conjuntos de datos') ax.set_ylabel('Valores')  # Mostrar el gr\u00e1fico plt.show() <ul> <li>Box plot horizontal con etiquetas personalizadas:</li> </ul> In\u00a0[3]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Generar dos conjuntos de datos aleatorios\ndata1 = np.random.normal(0, 1, 100)\ndata2 = np.random.normal(3, 1, 100)\n\n# Crear el box plot horizontal\nfig, ax = plt.subplots()\nax.boxplot([data1, data2], vert=False, labels=['Distribuci\u00f3n 1', 'Distribuci\u00f3n 2'])\n\n# Agregar etiquetas y t\u00edtulo\nax.set_title('Box plot horizontal con etiquetas personalizadas')\nax.set_xlabel('Valores')\nax.set_ylabel('Conjuntos de datos')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Generar dos conjuntos de datos aleatorios data1 = np.random.normal(0, 1, 100) data2 = np.random.normal(3, 1, 100)  # Crear el box plot horizontal fig, ax = plt.subplots() ax.boxplot([data1, data2], vert=False, labels=['Distribuci\u00f3n 1', 'Distribuci\u00f3n 2'])  # Agregar etiquetas y t\u00edtulo ax.set_title('Box plot horizontal con etiquetas personalizadas') ax.set_xlabel('Valores') ax.set_ylabel('Conjuntos de datos')  # Mostrar el gr\u00e1fico plt.show()"},{"location":"visualization/027_boxplot/#boxplot","title":"Boxplot\u00b6","text":"<p>Un boxplot (tambi\u00e9n conocido como diagrama de caja y bigotes) es una herramienta gr\u00e1fica utilizada para representar la distribuci\u00f3n de un conjunto de datos num\u00e9ricos a trav\u00e9s de su cuartil, valores m\u00ednimos y m\u00e1ximos, y outliers (datos extremos).</p> <p>Aqu\u00ed te presento algunos ejemplos de box plots con Matplotlib en Python:</p> <ul> <li>Box plot simple con un conjunto de datos:</li> </ul>"},{"location":"visualization/031_seaborn/","title":"Seaborn","text":"In\u00a0[1]: Copied! <pre># librerias\n \nimport os\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns \npd.set_option('display.max_columns', 500)  # Ver m\u00e1s columnas de los dataframes\n\n# Ver gr\u00e1ficos de matplotlib en jupyter notebook/lab\n%matplotlib inline\n</pre> # librerias   import os import numpy as np import pandas as pd  import matplotlib.pyplot as plt import seaborn as sns  pd.set_option('display.max_columns', 500)  # Ver m\u00e1s columnas de los dataframes  # Ver gr\u00e1ficos de matplotlib en jupyter notebook/lab %matplotlib inline In\u00a0[2]: Copied! <pre># cargar datos\niris_df = pd.read_csv(\n    \"https://raw.githubusercontent.com/fralfaro/MAT281_2022/main/docs/lectures/data_manipulation/visualization/data/iris.csv\"\n    \n)\niris_df.columns = ['sepalLength',\n                  'sepalWidth',\n                  'petalLength',\n                  'petalWidth',\n                  'species']\n\niris_df.head()\n</pre> # cargar datos iris_df = pd.read_csv(     \"https://raw.githubusercontent.com/fralfaro/MAT281_2022/main/docs/lectures/data_manipulation/visualization/data/iris.csv\"      ) iris_df.columns = ['sepalLength',                   'sepalWidth',                   'petalLength',                   'petalWidth',                   'species']  iris_df.head()  Out[2]: sepalLength sepalWidth petalLength petalWidth species 0 5.1 3.5 1.4 0.2 setosa 1 4.9 3.0 1.4 0.2 setosa 2 4.7 3.2 1.3 0.2 setosa 3 4.6 3.1 1.5 0.2 setosa 4 5.0 3.6 1.4 0.2 setosa <p>El ejemplo cl\u00e1sico consiste en graficar sepalWidth versus petalLength y colorear por especie.</p> <p>Imperativo</p> <p>En <code>matplotlib</code> ser\u00eda algo as\u00ed:</p> In\u00a0[3]: Copied! <pre>color_map = dict(zip(iris_df[\"species\"].unique(), \n                     [\"blue\", \"green\", \"red\"]))\n\nplt.figure(figsize=(10, 6))\n\nfor species, group in iris_df.groupby(\"species\"):\n    plt.scatter(group[\"petalLength\"], \n                group[\"sepalWidth\"],\n                color=color_map[species],\n                alpha=0.3,\n                edgecolor=None,\n                label=species,\n               )\n    \nplt.legend(frameon=True, title=\"species\")\nplt.xlabel(\"petalLength\")\nplt.ylabel(\"sepalWidth\")\nplt.show()\n</pre> color_map = dict(zip(iris_df[\"species\"].unique(),                       [\"blue\", \"green\", \"red\"]))  plt.figure(figsize=(10, 6))  for species, group in iris_df.groupby(\"species\"):     plt.scatter(group[\"petalLength\"],                  group[\"sepalWidth\"],                 color=color_map[species],                 alpha=0.3,                 edgecolor=None,                 label=species,                )      plt.legend(frameon=True, title=\"species\") plt.xlabel(\"petalLength\") plt.ylabel(\"sepalWidth\") plt.show() <p>Declarativo</p> <p>En <code>seaborn</code> ser\u00eda algo as\u00ed:</p> In\u00a0[4]: Copied! <pre>sns.set(rc={'figure.figsize':(10,8)})\n\nsns.scatterplot(\n        x='petalLength',\n        y='sepalWidth',\n        data=iris_df,\n        hue='species',\n        palette = ['blue', 'green', 'red']\n    \n)\nplt.show()\n</pre> sns.set(rc={'figure.figsize':(10,8)})  sns.scatterplot(         x='petalLength',         y='sepalWidth',         data=iris_df,         hue='species',         palette = ['blue', 'green', 'red']      ) plt.show()"},{"location":"visualization/031_seaborn/#seaborn","title":"Seaborn\u00b6","text":""},{"location":"visualization/031_seaborn/#visualizacion-declarativa","title":"Visualizaci\u00f3n Declarativa\u00b6","text":"<p>Es un paradigma de visualizaci\u00f3n en donde se busca preocuparse de los datos y sus relaciones, m\u00e1s que en detalles sin mayor importancia. Algunas caracter\u00edsticas son:</p> <ul> <li>Se especifica lo que se desea hacer.</li> <li>Los detalles se determinan autom\u00e1ticamente.</li> <li>Especificaci\u00f3n y Ejecuci\u00f3n est\u00e1n separadas.</li> </ul> <p>A modo de resumen, se refiere a construir visualizaciones a partir de los siguientes elementos:</p> <ul> <li>Data</li> <li>Transformation</li> <li>Marks</li> <li>Encoding</li> <li>Scale</li> <li>Guides</li> </ul> <p>Diferencias entre enfoques</p> Imperativa Declarativa Especificar c\u00f3mo se debe hacer algo Especificar qu\u00e9 se quiere hacer Especificaci\u00f3n y ejecuci\u00f3n entrelazadas Separar especificaci\u00f3n de ejecuci\u00f3n Colocar un c\u00edrculo rojo aqu\u00ed y un c\u00edrculo azul ac\u00e1 Mapear <code>x</code> como posici\u00f3n e <code>y</code> como el color <p>Ejemplo</p> <p>El Iris dataset es un conjunto de datos que contine una  muestras de tres especies de Iris (Iris setosa, Iris virginica e Iris versicolor). Se midi\u00f3 cuatro rasgos de cada muestra: el largo y ancho del s\u00e9palo y p\u00e9talo, en cent\u00edmetros.</p> <p>Este ejemplo  servir\u00e1 para mostrar una de las mayores diferencias entre una visualizaci\u00f3n imperativa (como <code>matplotlib</code>) versus una declarativa (como <code>seaborn</code>).</p> <p></p>"},{"location":"visualization/031_seaborn/#acerca-de-seaborn","title":"Acerca de Seaborn\u00b6","text":"<p><code>Matplotlib</code> ha demostrado ser una herramienta de visualizaci\u00f3n incre\u00edblemente \u00fatil y popular, pero incluso los usuarios entusiastas admitir\u00e1n que a menudo deja mucho que desear. Hay varias quejas v\u00e1lidas sobre Matplotlib que a menudo surgen:</p> <ul> <li><p>Antes de la versi\u00f3n 2.0, los valores predeterminados de Matplotlib no son exactamente las mejores opciones. Se bas\u00f3 en MATLAB alrededor de 1999, y esto a menudo se nota.</p> </li> <li><p>La API de Matplotlib es de nivel relativamente bajo. Es posible realizar una visualizaci\u00f3n estad\u00edstica sofisticada, pero a menudo requiere mucho c\u00f3digo repetitivo. Matplotlib fue anterior a Pandas en m\u00e1s de una d\u00e9cada y, por lo tanto, no est\u00e1 dise\u00f1ado para su uso con Pandas DataFrames. Para visualizar datos de un Pandas DataFrame, debe extraer cada Serie y, a menudo, concatenarlas juntas en el formato correcto. Ser\u00eda mejor tener una biblioteca de trazado que pueda usar inteligentemente las etiquetas de DataFrame en un trazado.</p> </li> </ul> <p>Una respuesta a estos problemas es <code>Seaborn</code>. Seaborn proporciona una API sobre Matplotlib que ofrece opciones sensatas para el estilo de trazado y los valores predeterminados de color, define funciones simples de alto nivel para tipos de trazado estad\u00edsticos comunes, y se integra con la funcionalidad proporcionada por Pandas DataFrames.</p>"},{"location":"visualization/032_lineplot/","title":"Line Plots","text":"In\u00a0[1]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\ntips = sns.load_dataset(\"tips\")\n\n# Crear el gr\u00e1fico de l\u00ednea\nsns.lineplot(x=\"total_bill\", y=\"tip\", data=tips)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos tips = sns.load_dataset(\"tips\")  # Crear el gr\u00e1fico de l\u00ednea sns.lineplot(x=\"total_bill\", y=\"tip\", data=tips)  # Mostrar el gr\u00e1fico plt.show() <ol> <li>Gr\u00e1fico de l\u00ednea con m\u00faltiples l\u00edneas</li> </ol> In\u00a0[2]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\nfmri = sns.load_dataset(\"fmri\")\n\n# Crear el gr\u00e1fico de l\u00ednea con m\u00faltiples l\u00edneas\nsns.lineplot(x=\"timepoint\", y=\"signal\", hue=\"region\", data=fmri)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos fmri = sns.load_dataset(\"fmri\")  # Crear el gr\u00e1fico de l\u00ednea con m\u00faltiples l\u00edneas sns.lineplot(x=\"timepoint\", y=\"signal\", hue=\"region\", data=fmri)  # Mostrar el gr\u00e1fico plt.show() <ol> <li>Gr\u00e1fico de l\u00ednea con estilo personalizado:</li> </ol> In\u00a0[3]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\nfmri = sns.load_dataset(\"fmri\")\n\n# Crear el gr\u00e1fico de l\u00ednea con estilo personalizado\nsns.lineplot(x=\"timepoint\", y=\"signal\", hue=\"region\", style=\"event\", data=fmri,\n             markers=True, dashes=False)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos fmri = sns.load_dataset(\"fmri\")  # Crear el gr\u00e1fico de l\u00ednea con estilo personalizado sns.lineplot(x=\"timepoint\", y=\"signal\", hue=\"region\", style=\"event\", data=fmri,              markers=True, dashes=False)  # Mostrar el gr\u00e1fico plt.show() <ul> <li>Gr\u00e1fico de l\u00ednea con bandas de confianza:</li> </ul> In\u00a0[6]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\nfmri = sns.load_dataset(\"fmri\")\n\n# Crear el gr\u00e1fico de l\u00ednea con bandas de confianza\nsns.lineplot(x=\"timepoint\", y=\"signal\", hue=\"region\", err_style=\"bars\", ci=95, data=fmri)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos fmri = sns.load_dataset(\"fmri\")  # Crear el gr\u00e1fico de l\u00ednea con bandas de confianza sns.lineplot(x=\"timepoint\", y=\"signal\", hue=\"region\", err_style=\"bars\", ci=95, data=fmri)  # Mostrar el gr\u00e1fico plt.show()"},{"location":"visualization/032_lineplot/#line-plots","title":"Line Plots\u00b6","text":"<p><code>lineplot</code> es una funci\u00f3n en la biblioteca de visualizaci\u00f3n de datos Seaborn en Python que se utiliza para crear gr\u00e1ficos de l\u00ednea.</p> <p>La funci\u00f3n lineplot toma varios argumentos, incluidos los datos que se van a graficar (<code>data</code>), el eje X (<code>x</code>), el eje Y (<code>y</code>) y los colores (<code>hue</code>) que se pueden utilizar para distinguir diferentes categor\u00edas en los datos.</p> <p>Aqu\u00ed hay algunos ejemplos de c\u00f3mo crear gr\u00e1ficos de l\u00ednea con Seaborn en Python:</p> <ol> <li>Gr\u00e1fico de l\u00ednea b\u00e1sico</li> </ol>"},{"location":"visualization/033_scatterplot/","title":"Scatter Plots","text":"In\u00a0[1]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\ntips = sns.load_dataset(\"tips\")\n\n# Crear el gr\u00e1fico de dispersi\u00f3n\nsns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos tips = sns.load_dataset(\"tips\")  # Crear el gr\u00e1fico de dispersi\u00f3n sns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips)  # Mostrar el gr\u00e1fico plt.show() <ol> <li>Gr\u00e1fico de dispersi\u00f3n con color por categor\u00eda:</li> </ol> In\u00a0[2]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\niris = sns.load_dataset(\"iris\")\n\n# Crear el gr\u00e1fico de dispersi\u00f3n con color por categor\u00eda\nsns.scatterplot(x=\"sepal_length\", y=\"petal_length\", hue=\"species\", data=iris)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos iris = sns.load_dataset(\"iris\")  # Crear el gr\u00e1fico de dispersi\u00f3n con color por categor\u00eda sns.scatterplot(x=\"sepal_length\", y=\"petal_length\", hue=\"species\", data=iris)  # Mostrar el gr\u00e1fico plt.show() <ol> <li>Gr\u00e1fico de dispersi\u00f3n con tama\u00f1o de punto personalizado:</li> </ol> In\u00a0[3]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\niris = sns.load_dataset(\"iris\")\n\n# Crear el gr\u00e1fico de dispersi\u00f3n con tama\u00f1o de punto personalizado\nsns.scatterplot(x=\"sepal_length\", y=\"petal_length\", size=\"sepal_width\", data=iris)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos iris = sns.load_dataset(\"iris\")  # Crear el gr\u00e1fico de dispersi\u00f3n con tama\u00f1o de punto personalizado sns.scatterplot(x=\"sepal_length\", y=\"petal_length\", size=\"sepal_width\", data=iris)  # Mostrar el gr\u00e1fico plt.show() <ol> <li>Gr\u00e1fico de dispersi\u00f3n con l\u00ednea de regresi\u00f3n:</li> </ol> In\u00a0[4]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\ntips = sns.load_dataset(\"tips\")\n\n# Crear el gr\u00e1fico de dispersi\u00f3n con l\u00ednea de regresi\u00f3n\nsns.regplot(x=\"total_bill\", y=\"tip\", data=tips)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos tips = sns.load_dataset(\"tips\")  # Crear el gr\u00e1fico de dispersi\u00f3n con l\u00ednea de regresi\u00f3n sns.regplot(x=\"total_bill\", y=\"tip\", data=tips)  # Mostrar el gr\u00e1fico plt.show()"},{"location":"visualization/033_scatterplot/#scatter-plots","title":"Scatter Plots\u00b6","text":"<p><code>scatterplot</code> es una funci\u00f3n en la biblioteca de visualizaci\u00f3n de datos Seaborn en Python que se utiliza para crear gr\u00e1ficos de dispersi\u00f3n. Los gr\u00e1ficos de dispersi\u00f3n son \u00fatiles para visualizar la relaci\u00f3n entre dos variables continuas en un gr\u00e1fico bidimensional.</p> <p>La funci\u00f3n <code>scatterplot</code> toma varios argumentos, incluidos los datos que se van a graficar (<code>data</code>), el eje X (<code>x</code>), el eje Y (<code>y</code>) y los colores (<code>hue</code>) que se pueden utilizar para distinguir diferentes categor\u00edas en los datos.</p> <p>Aqu\u00ed hay algunos ejemplos de c\u00f3mo crear gr\u00e1ficos de dispersi\u00f3n con Seaborn en Python:</p> <ol> <li>Gr\u00e1fico de dispersi\u00f3n b\u00e1sico:</li> </ol>"},{"location":"visualization/034_barplot/","title":"Bar Plots","text":"In\u00a0[19]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\ntips = sns.load_dataset(\"tips\")\n\n# Crear el gr\u00e1fico de barras - vertical\nsns.barplot(x=\"day\", y=\"total_bill\", data=tips,ci=None)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos tips = sns.load_dataset(\"tips\")  # Crear el gr\u00e1fico de barras - vertical sns.barplot(x=\"day\", y=\"total_bill\", data=tips,ci=None)  # Mostrar el gr\u00e1fico plt.show() In\u00a0[20]: Copied! <pre># Crear el gr\u00e1fico de barras - horizontal\nsns.barplot(x=\"total_bill\", y=\"day\", data=tips,ci=None)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> # Crear el gr\u00e1fico de barras - horizontal sns.barplot(x=\"total_bill\", y=\"day\", data=tips,ci=None)  # Mostrar el gr\u00e1fico plt.show() <ul> <li>Gr\u00e1fico de barras con colores codificados por una tercera variable:</li> </ul> In\u00a0[21]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\ntitanic = sns.load_dataset(\"titanic\")\n\n# Crear el gr\u00e1fico de barras con colores codificados por g\u00e9nero\nsns.barplot(x=\"class\", y=\"survived\", hue=\"sex\", data=titanic,ci=None)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos titanic = sns.load_dataset(\"titanic\")  # Crear el gr\u00e1fico de barras con colores codificados por g\u00e9nero sns.barplot(x=\"class\", y=\"survived\", hue=\"sex\", data=titanic,ci=None)  # Mostrar el gr\u00e1fico plt.show() <ol> <li>Gr\u00e1fico de barras con l\u00edneas de error:</li> </ol> In\u00a0[36]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\ndiamonds = sns.load_dataset(\"diamonds\")\n\n# Crear el gr\u00e1fico de barras con l\u00edneas de error\nsns.barplot(x=\"cut\", y=\"price\", data=diamonds, ci=95 )\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos diamonds = sns.load_dataset(\"diamonds\")  # Crear el gr\u00e1fico de barras con l\u00edneas de error sns.barplot(x=\"cut\", y=\"price\", data=diamonds, ci=95 )  # Mostrar el gr\u00e1fico plt.show() <ol> <li>Gr\u00e1fico de barras apiladas:</li> </ol> In\u00a0[34]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\ntitanic = sns.load_dataset(\"titanic\")\n\n# Crear el gr\u00e1fico de barras apiladas por g\u00e9nero y clase\nsns.barplot(x=\"class\", y=\"survived\", hue=\"sex\", data=titanic, estimator=sum,ci=None)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos titanic = sns.load_dataset(\"titanic\")  # Crear el gr\u00e1fico de barras apiladas por g\u00e9nero y clase sns.barplot(x=\"class\", y=\"survived\", hue=\"sex\", data=titanic, estimator=sum,ci=None)  # Mostrar el gr\u00e1fico plt.show()"},{"location":"visualization/034_barplot/#bar-plots","title":"Bar Plots\u00b6","text":"<p><code>barplot</code> es una funci\u00f3n en la biblioteca de visualizaci\u00f3n de datos Seaborn en Python que se utiliza para crear gr\u00e1ficos de barras. Los gr\u00e1ficos de barras son \u00fatiles para visualizar la distribuci\u00f3n de una variable categ\u00f3rica y comparar diferentes categor\u00edas en funci\u00f3n de una variable num\u00e9rica.</p> <p>La funci\u00f3n <code>barplot</code> toma varios argumentos, incluidos los datos que se van a graficar (<code>data</code>), la variable categ\u00f3rica (<code>x</code> o <code>y</code>) y la variable num\u00e9rica (<code>x</code> o <code>y</code> respectivamente) que se van a comparar.</p> <p>Aqu\u00ed hay algunos ejemplos de c\u00f3mo crear gr\u00e1ficos de barras con Seaborn en Python:</p> <ol> <li>Gr\u00e1fico de barras b\u00e1sico:</li> </ol>"},{"location":"visualization/035_histplot/","title":"Hist Plots","text":"<ol> <li>Histograma b\u00e1sico:</li> </ol> In\u00a0[1]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\ntips = sns.load_dataset(\"tips\")\n\n# Crear el histograma\nsns.histplot(x=\"total_bill\", data=tips)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos tips = sns.load_dataset(\"tips\")  # Crear el histograma sns.histplot(x=\"total_bill\", data=tips)  # Mostrar el gr\u00e1fico plt.show()  <ol> <li>Histograma con kde y l\u00edneas de referencia:</li> </ol> In\u00a0[2]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\niris = sns.load_dataset(\"iris\")\n\n# Crear el histograma con kde y l\u00edneas de referencia\nsns.histplot(x=\"petal_length\", data=iris, kde=True, stat=\"density\", linewidth=0)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos iris = sns.load_dataset(\"iris\")  # Crear el histograma con kde y l\u00edneas de referencia sns.histplot(x=\"petal_length\", data=iris, kde=True, stat=\"density\", linewidth=0)  # Mostrar el gr\u00e1fico plt.show()  <ol> <li>Histograma con m\u00faltiples categor\u00edas:</li> </ol> In\u00a0[3]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\ntitanic = sns.load_dataset(\"titanic\")\n\n# Crear el histograma con m\u00faltiples categor\u00edas\nsns.histplot(x=\"age\", hue=\"sex\", data=titanic, multiple=\"stack\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos titanic = sns.load_dataset(\"titanic\")  # Crear el histograma con m\u00faltiples categor\u00edas sns.histplot(x=\"age\", hue=\"sex\", data=titanic, multiple=\"stack\")  # Mostrar el gr\u00e1fico plt.show()  <ol> <li>Histograma con barra de densidad y l\u00ednea vertical para la media:</li> </ol> In\u00a0[5]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\ndiamonds = sns.load_dataset(\"diamonds\")\n\n# Crear el histograma con barra de densidad y l\u00ednea vertical para la media\nsns.histplot(x=\"price\", data=diamonds, kde=True, stat=\"density\")\nplt.axvline(x=diamonds[\"price\"].mean(), color='red', linestyle='--')\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos diamonds = sns.load_dataset(\"diamonds\")  # Crear el histograma con barra de densidad y l\u00ednea vertical para la media sns.histplot(x=\"price\", data=diamonds, kde=True, stat=\"density\") plt.axvline(x=diamonds[\"price\"].mean(), color='red', linestyle='--')  # Mostrar el gr\u00e1fico plt.show()  In\u00a0[1]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar datos de ejemplo\ntips = sns.load_dataset(\"tips\")\n\n# Crear un histograma bidimensional\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"hist\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar datos de ejemplo tips = sns.load_dataset(\"tips\")  # Crear un histograma bidimensional sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"hist\")  # Mostrar el gr\u00e1fico plt.show() <p>En este ejemplo, estamos cargando los datos de ejemplo <code>tips</code> de Seaborn y luego usamos la funci\u00f3n <code>jointplot()</code> para crear un histograma bidimensional de la columna <code>total_bill</code> en el eje x y la columna <code>tip</code> en el eje y.</p> <p>Tambi\u00e9n especificamos el par\u00e1metro <code>kind=\"hist\"</code> para indicar que queremos un histograma en lugar del gr\u00e1fico de dispersi\u00f3n predeterminado. Finalmente, usamos <code>plt.show()</code> para mostrar el gr\u00e1fico.</p> <p>Aqu\u00ed hay algunos ejemplos adicionales de c\u00f3mo crear histogramas bidimensionales en Seaborn en Python:</p> <ul> <li>Histograma de distribuci\u00f3n conjunta con ajuste de regresi\u00f3n:</li> </ul> In\u00a0[2]: Copied! <pre>import seaborn as sns\n\n# Cargar datos de ejemplo\ntips = sns.load_dataset(\"tips\")\n\n# Crear un histograma bidimensional con ajuste de regresi\u00f3n\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns  # Cargar datos de ejemplo tips = sns.load_dataset(\"tips\")  # Crear un histograma bidimensional con ajuste de regresi\u00f3n sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"reg\")  # Mostrar el gr\u00e1fico plt.show() <ul> <li>Histograma hexagonal:</li> </ul> In\u00a0[3]: Copied! <pre>import seaborn as sns\n\n# Cargar datos de ejemplo\ntips = sns.load_dataset(\"tips\")\n\n# Crear un histograma bidimensional hexagonal\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"hex\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns  # Cargar datos de ejemplo tips = sns.load_dataset(\"tips\")  # Crear un histograma bidimensional hexagonal sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"hex\")  # Mostrar el gr\u00e1fico plt.show() <ul> <li>Histograma de distribuci\u00f3n conjunta con KDE:</li> </ul> In\u00a0[4]: Copied! <pre>import seaborn as sns\n\n# Cargar datos de ejemplo\ntips = sns.load_dataset(\"tips\")\n\n# Crear un histograma bidimensional con KDE\nsns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"kde\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns  # Cargar datos de ejemplo tips = sns.load_dataset(\"tips\")  # Crear un histograma bidimensional con KDE sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"kde\")  # Mostrar el gr\u00e1fico plt.show()"},{"location":"visualization/035_histplot/#hist-plots","title":"Hist Plots\u00b6","text":""},{"location":"visualization/035_histplot/#histograma-univariado","title":"Histograma univariado\u00b6","text":"<p><code>histplot</code> es una funci\u00f3n de la biblioteca de visualizaci\u00f3n de datos Seaborn en Python que se utiliza para crear histogramas. Un histograma es una representaci\u00f3n gr\u00e1fica de la distribuci\u00f3n de una variable num\u00e9rica. La funci\u00f3n histplot toma una variable num\u00e9rica y divide los datos en <code>\"bins\"</code> (contenedores) para contar la cantidad de observaciones que caen en cada bin.</p> <p><code>histplot</code> es similar a la funci\u00f3n <code>distplot</code> de Seaborn, pero <code>histplot</code> es m\u00e1s flexible y eficiente.</p> <p>Aqu\u00ed hay algunos ejemplos de c\u00f3mo crear histogramas con Seaborn en Python utilizando la funci\u00f3n <code>histplot</code>:</p>"},{"location":"visualization/035_histplot/#histograma-bidimensional","title":"Histograma bidimensional\u00b6","text":"<p>Para crear un histograma bidimensional en Seaborn en Python, podemos usar la funci\u00f3n <code>jointplot()</code>.</p> <p>Aqu\u00ed hay un ejemplo de c\u00f3mo crear un histograma bidimensional en Seaborn usando la funci\u00f3n <code>jointplot()</code>:</p>"},{"location":"visualization/036_heatmap/","title":"Heat Map","text":"<ol> <li>Mapa de calor b\u00e1sico:</li> </ol> In\u00a0[1]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\nflights = sns.load_dataset(\"flights\")\nflights = flights.pivot(\"month\", \"year\", \"passengers\")\n\n# Crear el mapa de calor\nsns.heatmap(flights)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos flights = sns.load_dataset(\"flights\") flights = flights.pivot(\"month\", \"year\", \"passengers\")  # Crear el mapa de calor sns.heatmap(flights)  # Mostrar el gr\u00e1fico plt.show() <ol> <li>Mapa de calor con paleta de colores personalizada:</li> </ol> In\u00a0[2]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\nflights = sns.load_dataset(\"flights\")\nflights = flights.pivot(\"month\", \"year\", \"passengers\")\n\n# Crear el mapa de calor con paleta de colores personalizada\nsns.heatmap(flights, cmap=\"YlGnBu\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos flights = sns.load_dataset(\"flights\") flights = flights.pivot(\"month\", \"year\", \"passengers\")  # Crear el mapa de calor con paleta de colores personalizada sns.heatmap(flights, cmap=\"YlGnBu\")  # Mostrar el gr\u00e1fico plt.show() <ol> <li>Mapa de calor con anotaciones y etiquetas de ejes personalizadas:</li> </ol> In\u00a0[3]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\nflights = sns.load_dataset(\"flights\")\nflights = flights.pivot(\"month\", \"year\", \"passengers\")\n\n# Crear el mapa de calor con anotaciones y etiquetas de ejes personalizadas\nsns.heatmap(flights, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Month\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos flights = sns.load_dataset(\"flights\") flights = flights.pivot(\"month\", \"year\", \"passengers\")  # Crear el mapa de calor con anotaciones y etiquetas de ejes personalizadas sns.heatmap(flights, annot=True, fmt=\"d\", cmap=\"YlGnBu\") plt.xlabel(\"Year\") plt.ylabel(\"Month\")  # Mostrar el gr\u00e1fico plt.show() <ol> <li>Mapa de calor con barra de color personalizada y l\u00edmites de valores:</li> </ol> In\u00a0[4]: Copied! <pre>import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Cargar los datos\nflights = sns.load_dataset(\"flights\")\nflights = flights.pivot(\"month\", \"year\", \"passengers\")\n\n# Crear el mapa de calor con barra de color personalizada y l\u00edmites de valores\nsns.heatmap(flights, cmap=\"YlGnBu\", cbar_kws={\"label\": \"N\u00famero de pasajeros\"}, vmin=100, vmax=650)\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> import seaborn as sns import matplotlib.pyplot as plt  # Cargar los datos flights = sns.load_dataset(\"flights\") flights = flights.pivot(\"month\", \"year\", \"passengers\")  # Crear el mapa de calor con barra de color personalizada y l\u00edmites de valores sns.heatmap(flights, cmap=\"YlGnBu\", cbar_kws={\"label\": \"N\u00famero de pasajeros\"}, vmin=100, vmax=650)  # Mostrar el gr\u00e1fico plt.show()"},{"location":"visualization/036_heatmap/#heat-map","title":"Heat Map\u00b6","text":"<p><code>heatmap</code> es una funci\u00f3n de la biblioteca de visualizaci\u00f3n de datos Seaborn en Python que se utiliza para crear mapas de calor. Un mapa de calor es una representaci\u00f3n gr\u00e1fica de una matriz de datos en la que los valores se representan como colores. Es \u00fatil para visualizar datos num\u00e9ricos y para identificar patrones y relaciones entre variables.</p> <p>La funci\u00f3n <code>heatmap</code> toma una matriz de datos y la representa como un mapa de calor. Los valores en la matriz se asignan a un color que indica su magnitud. El mapa de calor se puede personalizar con diferentes paletas de colores, tama\u00f1os de figura, etiquetas de ejes, etc.</p> <p>Aqu\u00ed hay algunos ejemplos de c\u00f3mo crear mapas de calor con Seaborn en Python utilizando la funci\u00f3n <code> heatmap</code>:</p>"},{"location":"visualization/037_boxplot/","title":"Boxplot","text":"In\u00a0[1]: Copied! <pre>import seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\n</pre> import seaborn as sns import numpy as np import matplotlib.pyplot as plt In\u00a0[2]: Copied! <pre>## caso vertical\n\n# Cargar un conjunto de datos de ejemplo \ntips = sns.load_dataset(\"tips\")\n\n# Crear el boxplot con Seaborn\nsns.boxplot(y=\"total_bill\", data=tips)\n\n# Agregar t\u00edtulo y etiquetas de los ejes\nplt.title(\"Boxplot de total_bill por d\u00eda\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> ## caso vertical  # Cargar un conjunto de datos de ejemplo  tips = sns.load_dataset(\"tips\")  # Crear el boxplot con Seaborn sns.boxplot(y=\"total_bill\", data=tips)  # Agregar t\u00edtulo y etiquetas de los ejes plt.title(\"Boxplot de total_bill por d\u00eda\")  # Mostrar el gr\u00e1fico plt.show() In\u00a0[3]: Copied! <pre>## caso horizontal\n\n# Cargar un conjunto de datos de ejemplo\ntips = sns.load_dataset(\"tips\")\n\n# Crear el boxplot con Seaborn\nsns.boxplot(x=\"total_bill\", data=tips)\n\n# Agregar t\u00edtulo y etiquetas de los ejes\nplt.title(\"Boxplot de total_bill por d\u00eda\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> ## caso horizontal  # Cargar un conjunto de datos de ejemplo tips = sns.load_dataset(\"tips\")  # Crear el boxplot con Seaborn sns.boxplot(x=\"total_bill\", data=tips)  # Agregar t\u00edtulo y etiquetas de los ejes plt.title(\"Boxplot de total_bill por d\u00eda\")  # Mostrar el gr\u00e1fico plt.show() <ul> <li>Box-Plot para varias variables</li> </ul> In\u00a0[4]: Copied! <pre># Cargar un conjunto de datos de ejemplo\ntips = sns.load_dataset(\"tips\")\n\n# Crear el boxplot con Seaborn\nsns.boxplot( data=tips)\n\n# Agregar t\u00edtulo y etiquetas de los ejes\nplt.title(\"Boxplot de total_bill por d\u00eda\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> # Cargar un conjunto de datos de ejemplo tips = sns.load_dataset(\"tips\")  # Crear el boxplot con Seaborn sns.boxplot( data=tips)  # Agregar t\u00edtulo y etiquetas de los ejes plt.title(\"Boxplot de total_bill por d\u00eda\")  # Mostrar el gr\u00e1fico plt.show() <ul> <li>Box-Plot para una variable separada por categor\u00edas</li> </ul> In\u00a0[5]: Copied! <pre># Cargar un conjunto de datos de ejemplo\ntips = sns.load_dataset(\"tips\")\n\n# Crear el boxplot con Seaborn\nsns.boxplot(x=\"day\", y=\"total_bill\", data=tips)\n\n# Agregar t\u00edtulo y etiquetas de los ejes\nplt.title(\"Boxplot de total_bill por d\u00eda\")\nplt.xlabel(\"D\u00eda\")\nplt.ylabel(\"Total_bill\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> # Cargar un conjunto de datos de ejemplo tips = sns.load_dataset(\"tips\")  # Crear el boxplot con Seaborn sns.boxplot(x=\"day\", y=\"total_bill\", data=tips)  # Agregar t\u00edtulo y etiquetas de los ejes plt.title(\"Boxplot de total_bill por d\u00eda\") plt.xlabel(\"D\u00eda\") plt.ylabel(\"Total_bill\")  # Mostrar el gr\u00e1fico plt.show() <ul> <li>Boxplot con datos agrupados por una variable:</li> </ul> In\u00a0[6]: Copied! <pre># Cargar un conjunto de datos de ejemplo\ntips = sns.load_dataset(\"tips\")\n\n# Crear el boxplot con Seaborn\nsns.boxplot(x=\"day\", y=\"total_bill\", hue=\"sex\", data=tips)\n\n# Agregar t\u00edtulo y etiquetas de los ejes\nplt.title(\"Boxplot de total_bill por d\u00eda y g\u00e9nero\")\nplt.xlabel(\"D\u00eda\")\nplt.ylabel(\"Total_bill\")\n\n# Mostrar el gr\u00e1fico\nplt.show()\n</pre> # Cargar un conjunto de datos de ejemplo tips = sns.load_dataset(\"tips\")  # Crear el boxplot con Seaborn sns.boxplot(x=\"day\", y=\"total_bill\", hue=\"sex\", data=tips)  # Agregar t\u00edtulo y etiquetas de los ejes plt.title(\"Boxplot de total_bill por d\u00eda y g\u00e9nero\") plt.xlabel(\"D\u00eda\") plt.ylabel(\"Total_bill\")  # Mostrar el gr\u00e1fico plt.show()"},{"location":"visualization/037_boxplot/#boxplot","title":"Boxplot\u00b6","text":"<p>Un boxplot (tambi\u00e9n conocido como diagrama de caja y bigotes) es una herramienta gr\u00e1fica utilizada para representar la distribuci\u00f3n de un conjunto de datos num\u00e9ricos a trav\u00e9s de su cuartil, valores m\u00ednimos y m\u00e1ximos, y outliers (datos extremos).</p> <p>Aqu\u00ed te presento algunos ejemplos de box plots con Seaborn en Python:</p> <ul> <li>Box plot simple para una variable</li> </ul>"},{"location":"visualization/intro/","title":"Visualizaci\u00f3n de Datos\ud83d\udcda Table of Contents:","text":""}]}